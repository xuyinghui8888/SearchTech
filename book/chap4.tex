
\chapter{个性化搜索背后的核心技术}
\thispagestyle{empty}

\setlength{\fboxrule}{0pt}\setlength{\fboxsep}{0cm}
\noindent\shadowbox{
\begin{tcolorbox}[arc=0mm,colback=lightblue,colframe=darkblue,title=学习目标与要求]
%\kai\textcolor{darkblue}{1.~~强化学习．} \\ 

\end{tcolorbox}}
\setlength{\fboxrule}{1pt}\setlength{\fboxsep}{4pt} 

 随着网络的流行和互联网信息的爆炸性增长，如何从海量的信息中准确找到自己需要的信息成为了互联网发展面临的一大难题。传统的搜索引擎由于其通用性，对于相同的查询，所有用户得到的都是同样的结果，显然不能满足不同背景、不同目的和不同时期用户的个性化需求。在这个讲究个性和以人为本的时代，人性化的搜索引擎已经成为了时代的需求。

在淘宝的环境下，用户主要的目的就是购物。不同的用户个体在购物上更是天然就存在着很大的差异，这种差异可以反映在很多方面，有价格偏好、类目偏好、地域偏好、品质偏好等等。而我们要做的就是挖掘，理解用户的差异和不同需求，做出个性化的搜索体验，最终能够帮组用户在淘宝上购物。

个性化搜索最根本的目标是要根据用户的意图和喜好展示搜索结果页，抛弃目前这种千篇一律的展现方式。个性化体现了搜索系统的智能性，从提高用户体验方面加深了用户对淘宝的粘性。

进入正题之前首先谈一谈个性化方向后续需要关注的几个点，搜索个性化时至今日，已经成为
互联网网站的技术标配，虽然业界取得了一些成绩，但挑战仍然存在；

首先来看看为什么要作个性化，搜索中引入个性化的目的是什么
每天有 近30000个查询“连衣裙”的消费者，query + “user context” 的查询逻辑能够实现不同的消费群体看到不同商品投放结果，实现平台上人-货匹配在搜索流量上的个性化细分，比如说，“肥胖”的女性查询结果里面更多的展现宽松风格的商品，而消费能力高的消费者更多的展现高品位的大牌商品，从而达到流量投放效率的最大化；总而言之，目的是两个 ： 
a). 提升流量匹配效率：具体表现在购物路径上的效果指标；
b). 改善宽泛query下得流量集中性，提升宽泛query下不同人群看到的展示商品不同，而带来成交商品和点击商品的丰富性；
总而言之：对于广大消费者，由于个性化能够细分搜索意图，拟合个体偏好，有助于更快捷找到需求；

弄清楚了搜索个性化的目的，下面想来澄清几个问题：

1. 个性化并不是定制化

Customization：实现的境界是 You are what you say you are？ 或者说，平台按照系统理解的用户profile，并按照某种特定个性化规则去投放，即是，实现 you are what the system thinks you are. 对于针对用户的查询结果的信息展示是局限在explicit 的“feature”层面，比方说，按照购买力匹配规则，按照品牌偏好规则等等；定制化的好处的确能够在某种程度上带来强的个性化体验，但是带来的伤害也是不言而喻；
而Personalization是：根据用户行为所挖掘的偏好信息来进行展示商品的投放，即是，实现 you are what you click on and what you buy；对于针对用户的查询结果的商品展示是基于“内容和数据”层面；不去刻意的假设用户的行为是由于某个特定维度（人口统计类特征，偏好类特征，人群特征）造成的，消费者点击或成交行为的发生，是所有个性化信息的综合表现；为什么我在这里先提出这个问题，因为经常听到的很多关于，目前线上个性化效果不尽人意的反馈，在这里，也不去刻意回避我们自己的问题，个性化数据，模型的覆盖率，准确性和时效性等都需要进一步的优化和改进；然而，对于那些为了增强所谓的个性化体验而实行的规则式匹配逻辑，都是极其不科学的做法，对于消费者而言，他们需要的是找到一个符合他／她需求的商品，而个性化体验强弱与否并非是最终的目的，我相信的是，消费者不会因为我们预测到他的性别，购买力，偏好的品牌就做出点击或购买的决策，个性化是我们系统实现高效的【人－货】匹配效率的手段，并非是消费者的购物诉求；在这里也请从事个性化方面的运营，产品，甚至算法同学能时刻理解这点；

2. 不要陷入活跃/资深用户的悖论

正常的用户无论其活跃与否，都不会愿意浪费时间去填写所谓的友好的交互式表单来帮助系统去理解他们，从而得到更好的个性化体验；他们关注的是展示商品整体是否满足他们的需求，而不会去刻意的由于商品的某个维度匹配了他/她得某个偏好而做出最终的选择；这里列举一个曾经的产品设计，在搜索结果页，给出用户可以定制的个性化偏好交互界面，希望消费者能告诉我们他们的个性化profile，出发点是好的，结局大家懂的；

3. 个性化explore的重要性

随着个性化元素在搜索全链路的渗透，从query的个性化标注，海选的个性化召回，精排中的个性化排序因子，以及个性化rerank，个性化展示，使得最终呈现给用户的内容取决于系统底层根据用户历史行为所挖掘的个性化特征，人口统计学维度，兴趣点偏好维度，session级别实时特征，过度的”user specific historical behaviour driven“的个性化投放，会使得用户逐渐丧失对展示结果的新鲜感，并且视野变得越来越狭窄, 进而使得底层的用户数据模型丧失自我修复和自我扩展能力；因此一个完整的个性化体系，必须考虑explore机制的设计环节；

4. 个性化评估的方法论

要想推动个性化效果的正向迭代，首先需要建立起合理的效果评估体系；然而这仍然是一个很大的问题，学术界流行的准确率，召回率，F1值，AUC，RMSE，等都有很大的局限性，这一层面的评估，只能保证数据模型的正确性；而在实际工作中，这些指标上的不一定能保证线上效果的收益；因此我们需要第二层次的评估手段，来看个性化算法效果。实现个性化的投放效果，是系统层面的主动而为，而且并没有去引导消费者端在一次搜索看到展示结果后，做出选择。 因此在消费者不知情情况下，消费者的行为反馈可以用来作为个性化效果评估的一个手段。对于已经上线的个性化特征，需要部署相应的统计分析模块，在ABtest机制下，监控各个特征的覆盖率，以及覆盖流量下的点击率，转化率等；虽然无法直接统计到这些特征对于点击和转化带来的精确影响，但是通过追踪高权重user的体验 - 点击率，2跳率，转化率等，能够了解这些特征的影响趋势，及早发现问题；这里特别强调下，采用高权重user的行为数据来分析的原因是，高权重用户意味着是活跃用户，意味着行为丰富，而这类用户的个性化特征的表现会更有代表性；最后，我也来谈谈对于针对个性化效果的社会化评测的意见和想法，便于理解，就以用户购买力为例来讲讲，为了更好来把握该维度数据的有效性，经常利用的手段是社会化评测来给定一些查询下，看看展示结果里面展示商品的价格是否符合评测者的价格偏好，从表象上看，似乎没有问题，然而，这里面确有一个本质上的问题，我们限定了这些参与评测人得判断角度，只关注商品价格，并给出满意与否的结论，而在实际购物场景下，用户对于商品满意与否接受与否，并不是只限定在价格本身，因此这样的评测还是有一定的局限性；我个人的观点，还是去真实的模拟线上的判断环境，不去刻意要求消费者去关注某个固定的维度，只是给出site by site的结果，让用户判断哪边展示的商品更符合他的口味，当然，这不同site的展示结果的差异，背后只是某个维度的个性化带来的影响，这样去评测，才更加客观；总结一句话，就是众包评测的关键是，希望参与者能做出客观的反馈，不应该做任何主观性的引导；

5. 个性化体系对于系统和框架的影响

在搜索场景下实现个性化的效果，就需要去建模分析 【query-user-商品】三元组构成下得海量数据分析，数据是极端稀疏的，算法时间和空间的复杂性，都对于体统能很好的支持分布和并行的数据分析和建模能力提出了很高的要求；另外，用户偏好的时效性，也需要我们能够实现增量，实时计算能力，个性化的实施，使得传统引擎依赖的性能优化利器，cache机制无法施展手脚，因此对于引擎的创新性改造也提出了更高的要求；另外，个性化数据的挖掘都是存在不确定性的，如何来设计一套能够保证误差不会累积的算法体系，也就是说需要建立一套数据自我修复的实时反馈体系，来保证由消费者端实时获取的客观反馈数据参与到个性化投放环节来保证模型的自我修复能力快于数据误差的传播速度；这样才能保证数据产生的价值形成良性的循环，构成大数据生态体系；



个性化是一种解决“长尾需求”的方式，“长尾理论”说的是用户需求集中度越来越低，用户和用户之间不一样，
我们如何来区分这种不一样？ 个性化搜索就是融合推荐元素，以实现：用户个体需求主导的 “pull” 式搜索加
平台以数据驱动的方式对用户进行“push”式相关信息推送；


综述性的东西，@三桐，@公达

\section{用户肖像建模} 
	用户肖像是对用户全方位的描述，一般分为人群和偏好两种。我们通常说的用户人群，是指用户长期稳定属于的某一个群体，如男性、女性。而用户偏好，在淘宝中是指用户对某种商品的偏好，是会经常或实时变化的，如偏好欧美风格的女装。有的时候，用户人群和偏好又容易混在一起，例如用户是男性，是指他的真实性别是男性，而他可能会偶尔给老婆或者母亲购买女性服装，这时的实时偏好则会是女性商品。因此，性别这个维度，既包含了人群，也包含了偏好。当我们讨论长期性别时，指的是人群；当我们讨论实时性别时，指的是偏好。用户的年龄也是类似的。
	
	物以类聚，人以群分。不同的人群，在总体上有着不同的行为特点和购物需求。我们对用户的了解，是从他/她所属的人群开始的。人群可以按不同的维度划分，如性别、年龄、购买力、地域等。例如，在服饰行业中，男性用户更喜欢买男装，女性用户更喜欢买女装。这样，在用户搜索“T恤”时，我们可以根据他的性别展示更符合他偏好的结果。不同年龄段的用户的购物需求也会有明显的差异，例如穿衣风格或者手机款式。为了识别用户所属的人群，需要使用尽量多的数据。最基础的是用户注册的信息，不过这种信息有时并不准确。比如，用户注册时填的不准确，或者用户把账号长期给家人使用。所以还需要使用用户在网站上的行为数据来校正这些数据。这时会使用机器学习的方法，把用户肖像建模看成一个分类问题，使用各种来源的数据来预测用户所属的人群。
	
	在个性化搜索中，首先需要满足用户的基本体验，使用户看到的商品基本符合用户的需求，即至少不要看到不喜欢的商品。同时，用户也希望看到多样的不同款式的商品，在其中进行筛选。这种基本的商品集合，一般是通过商品的属性标签来表示的，如性别、款式、价格档位、年龄段等。因此，为了实现好的个性化搜索体验，必须准确的预估用户的偏好。预估用户偏好的方法分为三种：长期偏好，实时偏好，和人群偏好。淘宝上的活跃用户，在某些商品属性上有长期稳定的偏好，这时可以计算他们的长期偏好。当用户在购物的过程中，有些偏好还会随时发生变化，或者这次搜索和上次搜索的状态不同，比如刚刚发了年终奖，这时需要计算用户的实时偏好。对淘宝上的不活跃用户，长期没有行为或行为少的用户，用他的行为很难准确预估他的偏好，这时只能用他所属的人群来预估他的偏好。实际上，我们会把这3种偏好综合成一个，即某个维度上的综合偏好，这个综合偏好体现了最终个性化体验的效果。
	
	\subsection{性别}
	性别作为用户最重要的基本属性之一，必然是个性化考虑因素。对电子商务网站来讲，性别也是搜索和推荐系统决策因素之一。淘宝主要消费群体是女性，用户数据容易被女性行为主导，人气排序下表现尤为明显。性别个性化则是根据用户的性别影响排序，在用户query没有明确表明性别的情况下提前与用户性别相同的商品，旨在减少翻页次数or换query次数从而提高ctr。另外，如果用户能看到更多与其购买意图相关的商品，可能会提高成交转化率。
	
	\paragraph{商品的性别}
	
	为了利用性别影响排序，首先需要解决如何标记商品性别。商品的性别可通过类目或者属性来表现，而类目的性别表现又分为窄义性别和广义性别。窄义性别表现类目有服饰、鞋和包等，此类型只要提前相应类目或者类目下具有某些特征的商品即可；广义性别表现类目包括窄义类目和诸如手机、电脑、游戏币等隐含类别，该类型下商品的性别与类目无关，而是由商品本身的特征决定的，如颜色、风格等（与性别无明显关系），这类性别标签需要挖掘才能发现。
	
	\paragraph{用户性别模型}
	
	性别个性化另外一个重要的方面是如何预测用户性别。用户注册时的性别信息和支付宝实名认证都可以作为判断性别的依据，但考虑到用户可能填错以及实名认证用户少、甚至有账号被同时多个用户使用的情况，我们不能直接应用这些信息。个性化用到的性别必须有物理性别与淘宝性别之分，所以必须建立一套合理的性别预测方案。
	
	\paragraph{建模}
	
	这里，我们直接使用LogisticRegression模型，预测用户为男性还是女性。训练目标是购买商品类目的性别和身份证性别一致的，即购买过类目性别和身份证性别都为男性，才认为是男性。
	
	 \begin{figure}[h]
		\centering
		\includegraphics[width=0.8\linewidth]{"fig/sex_model"}
		\caption{性别模型训练流程}
		\label{fig:sex_model}
	\end{figure}

	\paragraph{特征}
	\begin{itemize}
	\item{分别15个女性、男性倾向类目的点击总数}
	\item{分别15个女性、男性倾向类目的购买总数}
	\item{强女性类目点击天数}
	\item{强男性类目点击天数}
	\item{总点击天数}
	\item{强女性类目购买天数}
	\item{强男性类目购买天数}
	\item{总购买天数}
	\item{女性倾向类目点击次数占比}
	\item{男性倾向类目点击次数占比}
	\item{点击占比熵}
	\item{女性倾向类目购买次数占比}
	\item{男性倾向类目购买次数占比}
	\item{购买占比熵}
	\item{强女性、男性类目类目点击天数差占有点击天数的比例}
	\item{强女性、男性类目类目购买天数差占有购买天数的比例}
	\end{itemize}

	\paragraph{效果}
	
	最终效果，总体召回率：86\%，总体准确率：94\%。
	
	\begin{table}
		\centering
		\caption{性别准确率}
		\begin{tabular}
			{|l|l|l|l|l|l|}
			\hline
			新版&样本数&预测男&预测女&召回率&准确率\\
			\hline
			真实男&1380636&1192135&73080&86.3\%&93.4\%\\
			\hline
			真实女&1353568&84840&1156177&85.4\%&94.1\%\\
			\hline
		\end{tabular}
		\label{性别准确率}
	\end{table}

	\subsection{年龄}
	
	\paragraph{用户年龄}
	
	用户年龄的识别可以简单的使用身份证上的生日计算年龄。但由于家庭账号，或者代买的情况存在，直接使用身份证上的年龄也可能不完全准确，这时可以使用在某些能反映年龄的商品上的行为，来修正身份证的年龄。例如，经常买“中老年女装”的人，可能年龄较大。具体的做法和性别类似，这里就不再详述了。
	
	从业务上来说，在电商场景下似乎更加关注用户所处的年龄段，而不一定需要细化到年龄值的信息，使用年龄段的数据可以确定用户的其他属性，比如学历，职业，人生阶段等特征，进而在的用户画像、推荐、个性化搜索、反作弊识别等方面提供有力的数据支持。我们一般把用户的年龄分为如下7个阶段：
	
	\begin{itemize}
		\item{0-18岁：未成年}
		\item{18-22岁：大学生}
		\item{22-25岁：研究生/刚参加工作}
		\item{25-30岁：轻熟期}
		\item{30-35岁：成熟期}
		\item{35-50岁：中年}
		\item{50岁-：中老年}
	\end{itemize}

	当然，这种划分方式并不是唯一的，也不是固定的，只是尽量反映当代用户心理和购物需求的不同。
	
	\paragraph{商品年龄段}	
	
	用户年龄识别准确，还需要商品年龄才能完成用户-商品的加权，这就涉及到商品年龄打标的问题，首先我们分析了商品在不同行业下的年龄区分度，发现年龄只在服饰、鞋包类目下区分度较高，其他行业如3C数码等区分度很小。淘宝服饰行业商品中有些是注明了年龄段的，但存在以下几个问题：
	
	1. 年龄缺失
	
	2. 年龄填写错误
	
	3. 年龄填写多个年龄段
	
	为了解决这个问题，我们需要来提升商品年龄打标的覆盖率，我们可用的商品特征有商品的图片、标题、属性等，这里我们以商品pv下标题分词、属性分词后的数量大于一定阈值的结果作为特征，最终选出大约15w特征，通过softmax模型来预测商品年龄，基于label的预测准确率约60\%，label上下一档都设定为正确的准确率的大于90\%，而我们的生效逻辑是为用户年龄上下一档的商品加权，所以基于softmax的年龄模型效果已经可以达到我们的要求。如果需要继续提升准确率还可以考虑：加入商品图像信息，用active learning的方式标注错分样本，解决代买（中年人给孩子和长辈代买的最多）、用户年龄不准导致商品年龄label不准等问题。 
	
	\subsection{购买力}
	
	前面提到了，每个用户在很多方面都是有自己独特的偏好，而购买力就是最明显的一个方面。高帅富和屌丝对商品的价格和品质有完全不同的需求。同样是搜索“T恤”，高帅富需要的是面料材质好的品牌货；而屌丝需要的是100元3件还包邮的大路货。这种需要的差异就是我们需要做个性化购买力的原因。
	
	\paragraph{商品的价格档}
	
	为了便于在业务中分析各种数据，可以将用户的购买力分成几个档次（如1~7档），档次越高表示用户的购买力越大。用户的购物行为中可以很方便的体现购买力。这时需要先确定商品的价格档。在不同类目下，不同的价格代表了不同的购买力，比如在200元的T恤是比较高端了，但200元的手机是非常低端的手机，所以我们首先需要计算每个类目下各个购买力档对应价格区间。将类目下所有宝贝的成交价格从低到高排序，然后按照20\%，20\%，20\%，15\%，10\%，10\%，5\%的比例划分成7档。对于每个宝贝，查询上面的类目成交价格分布表，看一下宝贝价格是在哪一档价格区间中，将这个宝贝打上购买力档的标签。
	
	\paragraph{用户购买力模型}
	
	我们使用了GBDT模型，训练用户的购买力。以未来搜索引导的成交在类目下的价格分档为目标，建立了一个多分类的模型。
	
	\paragraph{特征}
	
	\begin{itemize}
		\item{服饰类成交额、笔单价（衣）}
		\item{食品类成交额、笔单价（食）}
		\item{日用品开销（家居百货）}
		\item{是否有房+住房档次（住）}
		\item{装修档次（住）}
		\item{是否有车+车档次（行）}
		\item{酒店门票类开销（行）}
		\item{购买品牌、奢侈品}
		\item{职业}
		\item{教育程度}
		\item{年龄段}
		\item{手机型号}
		\item{资产等级}
		\item{好友关系}
	\end{itemize}

	\paragraph{跨类目购买力}
	
	在淘宝中，用户在很多类目的行为很少，如果只用这个类目的行为，很难准确预测购买力。所以可以使用协同过滤的思想，参考相关的有行为的类目的购买力，来预测少行为类目的购买力。
	
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.8\linewidth]{"fig/power_model"}
		\caption{跨类目购买力}
		\label{fig:power_model}
	\end{figure}

	通过大量的数据分析，可以计算任意两个类目之间购买力的相关性。越相关的类目，对预测类目的购买力贡献也越大。
	
	经过类目扩展之后，购买力的覆盖率可以显著提高。
	
	\subsection{地域}
	
	南方人认为豆腐脑是甜的，北方人认为豆腐脑是咸的。不同地域的用户，购物需求也会有很大的不同，比如很多大件商品、或者生鲜商品、本地生活服务等都只能在同省或者同城才能提供，而且即使是普通商品，距离越远运费也越高。不同地域的换季时间也有一定的差异，这也会提前反映到为换季准备的衣服上。通过天气的预测，可以预测用户的消费行为，这是一件神奇的事情。
	
	从大的范围来划分，可以分为南方、北方、东部、西部、中部。从小的范围来看，可以看用户所在的省、市、区。更细的粒度，是用户的生活轨迹，如家庭位置、工作位置、休闲娱乐位置等。
	
	目前能定位用户位置的信息源主要包括IP、LBS、WIFI以及物流收货地址等，这些数据源与用户结合便构成了一张地理信息网，如下图所示：
	
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.8\linewidth]{"fig/user_loc"}
		\caption{用户地域数据来源}
		\label{fig:user_loc}
	\end{figure}

	由于这些位置数据源表现形式及采集方式不一样，首先需要对这些位置数据源本身进行分析和挖掘，比如物流地址是用户的自然语言文本描述，随意不规范，需要对其进行结构化解析，去获取地址中的重要信息，包括省、市、区县以及路和门牌号等信息。另外，物流地址是用户自己描述，现实中是否真的存在也是很多业务应用中关注的焦点，因此还需要对物流地址进行有效性判断。目前地址结构化解析及有效性判断主要采用了文本挖掘中的相关技术去分析和挖掘，除此之外还有对地址进行类型划分及归一化等研究。而对于WIFI和IP主要是研究它们是否正常以及所属的类型（如：家庭WIFI/IP、公司WIFI/IP及公共WIFI/IP等）。同时，WIFI、IP、LBS以及文本地址虽然在空间位置描述方式不一样，但是他们之前是相互联系的，而且也有非常大的应用价值，比如地址中经纬度识别，这样就能从地图上更精准的定位到用户所在地。
	
	\subsection{职业}
	
	在用户肖像中，职业是不可或缺的一环。不同职业的用户，偏好的商品也是不同的。比如买衣服，学生、白领、公务员，他们的穿着风格也会不同。因此作为搜索引擎，也应该给他们更多合适的商品。
	
	我们怎么知道用户的职业呢？通过用户的注册信息肯定不行，没人会认真填写职业，而且职业也不是一定不变的。所以，最可能的方式就是用户的收货地址了。比如经常在“公司”地址收货的妹子，那就很可能是“公司职员”办公白领了，而经常在学校收货的妹子，那就很可能是可爱的“学生”MM了。
	
	我们把用户的职业分成下面几类：
	
	\begin{itemize}
	\item{学生：初高中、大中专及以上的学生群体}
	\item{教职工：幼儿园、初高中、大中专及以上的教工群体，包含教师和其他职工}
	\item{工人：“化工厂”、“化肥厂”，“焦化厂”等工厂工作者}
	\item{媒体从业者：“报社”、“电台”、“杂志社”、“制片厂”等媒体机构从业者}
	\item{金融从业者：“银行”、“证券“、”担保”等金融行业从业者}
	\item{医务人员：“医院“、”诊所“、”防疫站“等医疗场所工作人员}
	\item{公司职员：收货地址中包含“公司“、”写字楼“、”商务楼“、”科技大厦“等关键词的用户，但不包含上述”媒体从业者“、”工人“中提到的公司}
	\item{个体经营/服务人员：“便利店“、”奶茶店“等个体店面经营者，或者”营业厅“、”洗浴中心“、”美发沙龙“，”酒店宾馆“等娱乐行业从业者}
	\item{科研人员：“研究所“、”研究院“、”科研所“等场所研究人员}
	\item{公务员：“人民法院“、”地税局“、”国税局“等事业单位工作人员}
	\end{itemize}

	通过收货地址上的关键词匹配，我们可以识别一部分的用户职业。如果要识别更多用户，就需要用模型了。
	
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.8\linewidth]{"fig/user_zhiye"}
		\caption{用户职业模型}
		\label{fig:user_zhiye}
	\end{figure}

	首先，我们对于各个职业的用户均匀采样作为模型训练集；然后将用户在各个叶子类目下，浏览、收藏、加购、下单的行为数据，以及年龄和性别这两个基本属性作为特征输入，结合LR生成模型；最后，从规则标注用户中，再次采样与训练集不重合的用户作为测试集，可以计算出预测模型的平均准确率达到了80\%以上。
	
	\subsection{人群}
	
	有了上面提到的用户性别、年龄、购买力、地域、职业，就可以对用户人群有一个基本的定位，比如“都市网购达人轻熟女白领”。这样就可以把所有的用户划分成几十到几百个小的群体，每个人群会有一些特有的属性和购物偏好。更进一步的，还可以识别用户是否有房有车，是否结婚生子，以及是否是“数码达人”、“文艺青年”之类的，逐渐形成一个完整的用户画像。
	
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.8\linewidth]{"fig/user_pic"}
		\caption{用户画像}
		\label{fig:user_pic}
	\end{figure}
	

\section{匹配学习}
	\subsection{用户体验模型}
	\paragraph{意义}
	
	上一节讲了用户肖像的建模，是预测的用户单一维度的人群或者偏好。在实际的搜索排序中，是需要多个维度综合判断的，不同维度的重要程度也不一样。用户体验模型的目的就是把不同维度的人群数据和偏好结合起来，确定各个商品属性的影响因子，对每一个用户形成最终的用户体验分数。
	
	用户在搜索时，首先需要输入query，不同的query，需要的个性化体验是不同的。例如，搜“衣服”的时候，需要性别个性化，而搜“连衣裙”的时候则需要年龄、风格个性化。因此，首先需要识别query的类型，如行业、是否跨类目、是否包含品牌词等。然后，获取用户的人群和偏好信息，和商品的属性信息，对Query+User+Item的三元组数据建模，预估这时的用户满意度。
	
	\subsection{用户-商品CTR预估}
	\paragraph{背景}
	“个性化”在淘宝搜索中起着至关重要的作用，即让不同的用户看到最符合自己需求的商品。为了实现这个目标，最直接的方式就是预估商品到不同人群的ctr。当用户搜索时，使用这个分数排序，就可以把符合用户所属人群的商品优先展示。
	\paragraph{建模}
	
\subsection{序列匹配模型} 
1，前面三个章节我们递进的描述了用户与单个商品之间的匹配方式和模型。然而，上述方法均假设用户的购物行为之间是独立的——并不存在依赖、相关或序列关系。

举例来说，一个用户$U_1$2天内依次购买了以下商品：烤箱、面粉、奶油；另一个用户$U_2$半年内依次购买了孕妇衣、尿布和奶瓶。我们先考虑用户$U_1$，我们可以从他购买了烤箱和面粉2种商品推断他很可能想要做蛋糕（而这从每个单一买的商品都是很难推断的），因此也许需要奶油；再考虑用户$U_2$，我们可以从她依次购买了孕妇衣和尿布推断她很可能怀孕过并且已经生了小宝宝（从某一件来推荐会比较勉强），因此马上会需要奶瓶等婴儿用品。

从上面例子我们可以看出，用户的购物行为之间往往是存在高阶依赖关系的，即仅用户购买了一个商品集合$\{A, B, C\}$后，才会购买商品$D$；同时，用户的购物行为也会存在序列关系，即用户购买C，仅会在他依次购买了商品A和B之后。在这2种关系下，我们前3节使用的模型会很难捕捉这类规律。因此我们需要一种模型，能整体的考虑用户的行为历史（而不是将其行为拆分成一个一个的单独分析），进而推断他接下来的需求。

下面我们会首先介绍几种经典的序列模型以及带有记忆功能的模型，然后会详细介绍在淘宝搜索中，我们怎样使用这类模型做到用户与商品之间的序列匹配。

2，在机器学习的任务环境中，我们有大量的场景都是需要做一个序列预测和带有记忆的推断的。例如在query自动补全的场景下，我们需要根据用户输入的文字或者词序列来预测用户下一个最可能会输入的词语；又例如有这样一个问题，需要让机器在阅读了一整篇文章后，回答若干关于这个文章的问题。这类问题和场景下都需要模型具有一定的记忆能力，能在获取新信息的同时，记住部分老的信息。

A) 最常用而有效的方式是使用一个递归神经网络模型(RNN \cite{4,5})。正如其名字描述的，递归神经网络在隐层结构上存在一个循环，即当前隐层的输入是上一个隐层的输出以及当前的输入2项一起。由于每个隐层的信息都能递归的输入到下一个隐层中，因此会具有一定的记忆能力。如图\ref{fig:RNN}，我们将RNN按时间序列“打开”，可以看到前一时刻的隐层$S_{t-1}$和当前输入$X_t$会共同影响当前的隐层$S_{t}$。

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{"fig/RNN"}
	\caption{递归神经网络(RNN)示意图}
	\label{fig:RNN}
\end{figure}	

然而RNN存在的最大问题是“梯度消失和爆炸”问题\cite{6}。这是因为在神经网络进行反向传播(backpropagation)的时候，传播的梯度会是$w_{l,h}(t)$(递归网络的权重)的倍数；因此在递归层数较深的时候，梯度会消失掉(当$|w_{l,h}*y^{'}_{l}|<1$)或者爆炸(当$|w_{l,h}*y^{'}_{l}|>1$)。由于RNN存在“梯度消失和爆炸”问题，RNN的“记忆”只能是很短期的，并不具备长期的记忆。

B) 为了解决梯度消失和爆炸”问题，一种更为巧妙的递归网络结构LSTM(Long Short-Term Memory)cite{5}被设计了出来。在LSTM中，RNN中递归的隐层单元被一个存储单元(LSTMUnit)所替代，每个存储单元由一个输入门(InputGate)，一个输出门(OutputGate)和一个长期的内部的通过遗忘门(ForgetGate)更新的内部状态(Cell)相关联,如图\ref{fig:LSTM}。

\begin{figure}[h]
	\centering
	\includegraphics[width=0.3\linewidth]{"fig/LSTM"}
	\caption{LSTM(Long Short-Term Memory)示意图}
	\label{fig:LSTM}
\end{figure}

内部状态Cell可以可以理解为模型存储的长期记忆：每进行一次递归迭代的时候，Cell会通过遗忘门遗忘掉部分记忆，同时通过输入门决定当前输入有多少有效信息是需要被记住的，从而得到新的记忆。最终的输出通过当前新的记忆得到，由输出们决定新的记忆中哪些是当前需要的。在LSTM的反向传播过程中，不同于RNN中梯度是一个连乘的形式(由于链式法则)，可以转化成一个连加的形式，因此有效的避免了梯度的消失和爆炸，从而具备一定的长期记忆的能力。在基础的LSTM基础上，学者们提出了多种LSTM的变种，比如\cite{10}、GRU\cite{11}和 Clockwork RNN\cite{12},他们在计算性能上会有较大的差别，然而效果基本没太大差距\cite{13,14}。一个基本的LSTM更新公式如下：
\begin{eqnarray}
i_t &=& \sigma(W_{hi} * h_{t-1} + W_{xi} * x_t + b_i)
\\
f_t &=& \sigma(W_{hf} * h_{t-1} + W_{xf} * x_t + b_f)
\\
o_t &=& \sigma(W_{ho} * h_{t-1} + W_{xo} * x_to+ b_o)
\\
g_t &=& tanh(W_{hg} * h_{t-1} + W_{xg} * x_t + b_g)
\\
c_t &=& (f_t .* c_{t-1}) + (i_t .* g_t)
\\
h_t &=& o_t .* tanh(c_t)
\end{eqnarray}

C) 递归神经网络外主要能有效的处理“序列”相关的问题，因此被大量的用在NLP的问题中。除了RNN外，也有一些其他的模型有类似功能，例如神经图灵机(Neural Turing Machine, NTM\cite{7})和记忆神经网络(Memory Networks,MenNN\cite{8,9}),他们在不同场景下会比RNN“记住”更久远的信息，从而得到更好的效果。神经图灵机的主要思想是使用一个$M*N$的矩阵取存储一份长期记忆（这与LSTM是类似的，只是LSTM维护的是一个向量），该矩阵和一个神经网络共同进行学习和预测。记忆矩阵会通过选择性的读和写来进行迭代更新，同时由于每部分都是可微的，因此可以通过梯度下降法进行训练。NTM的基本工作原理如下图：

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\linewidth]{"fig/NTM"}
	\caption{Neural Turing Machine（NTM）示意图}
	\label{fig:NTM}
\end{figure}

记忆神经网络\cite{8}主要用在长期记忆的推断，网络会从一个长文本中自动的将重要的信息编码后记录下来。最后产出的模型能回答关于长文本的任何问题——根据问题从记忆中寻找相关内容，然后产生答案。一个经典的MemNN的预测过程由简单的4步组成：
\begin{itemize}
	\item[-] 将输入$x$编码成一个隐向量$I(x)$。
	\item[-] 更新记忆$m_i$，$m_i=G(m_i, I(x), m)$。即通过当前的隐向量，当前记忆，整体记忆，去更新记忆中的一块内容。
	\item[-] 通过当天的记忆内容和输入决定输出向量。$o = O(I(x),m)$
	\item[-] 最后将输出向量解析成最终的回答。$r = R(o)$
\end{itemize}
然而MemNN的一个问题在于并不能End-to-End的去学习，同时NTM和MemNN并没有关注输入的顺序信息。

3，在个性化搜索中，最为重要的是怎么去理解和认识一个淘宝的用户。除了用户的一些基本画像信息，我们拥有最为关键的、与其他平台不同的数据是用户在淘宝上的行为。由于用户在淘宝上的行为天然是一个长期的行为序列，因此很自然考虑使用RNN等序列模型取进行处理。一个最基础的模型结构如图\ref{fig:MULTI-LSTM}。

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\linewidth]{"fig/MULTI-LSTM"}
	\caption{淘宝序列匹配模型示意图}
	\label{fig:MULTI-LSTM}
\end{figure}

从图中我们可以看到网络主要由3大部分组成，分别是：1，首先得到用户的行为序列；2，将用户的行为序列经过一个带记忆的网络编码成隐向量H；3，将H通过多目标网络训练不同的目标。那么下面我们将从这三方面详细说明淘宝搜索中的序列匹配模型。

a)首先是用户序列部分。我们使用用户有过行为的商品序列作为用户的表示，每一个商品被embedding到一个128维的向量中，这个向量可以从word2vec的方法进行无监督学习得到，也可以从一个长期fine tune的深度神经网络得到。在获得商品表示的算法中，一个商品embedding前的编码主要包括商品ID、店铺、类目、价格信息。

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/Item_embedding"}
	\caption{商品embedding}
	\label{fig:Item_embedding}
\end{figure}

商品的embedding部分是在训练训练网络前提前训练好的，我们并没有将其放到训练序列的网络中，主要是因为ID特征十分稀疏，在一个LSTM的网络中，数据可能并不支持训练这么大规模的特征维度，从而影响模型的整体效果。然而这样的问题是，预训练得到的商品只包含了基本的商品特征，可能并不最适合当前的序列匹配网络。因此受transfer learning的启发，
向量经过embedding的商品向量并不是直接作为特征输入到LSTM或者MemNN中，而是根据商品的行为类型（点击、成交、收藏、加购）和来源经过不同的卷积核生成一个新的128维向量，然后输入到序列网络。这样既对用户的行为进行了区分，可以学习得到不同行为的重要性；同时对预训练得到的商品向量往新的目标上调整。

b)在得到用户的商品行为序列后，我们需要使用一个序列或者记忆模型，将序列编码成一个通用的用户状态H。这里我们对比了LSTM和End-to-end memory network\cite{9}。LSTM在上文中已经有过一些介绍，而一个End-to-end memory network与经典的memNN的区别在于它可以通过一个整体的网络去学习，基本的网络结构如图\ref{fig:end2end}。它首先将输入序列中的每一项同时映射成2个向量$m_i$和$c_i$，分别表示“输入记忆”和“输出记忆”。“输入记忆”决定序列中每一项的重要性$p_i$，$p_i$和和$c_i$相乘求和得到输出向量$o$。输出向量$o$和用户向量决定最终的答案$a$。LSTM使用一个记忆单元$Cell$去记忆历史信息；而End-to-end memory network正着重于将原始序列压缩，并自动挖掘序列中元素的重要性。我们使用两种方法在大量数据上进行了实验对比，从AUC来看LSTM会略优于End-to-end memory network，但是End-to-end memory network在计算速度上会远优于LSTM。
\begin{eqnarray}
c_i &=& \sigma(W_{c} * x_{i}
\\
m_i &=& \sigma(W_{m} * x_{i}
\\
p_i &=& Softmax(u^T m_i)
\\
o &=& \sum_{i}p_i c_i
\\
a &=& Softmax(W(o+u))
\end{eqnarray}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/end2end"}
	\caption{End-to-end memory network}
	\label{fig:end2end}
\end{figure}

c)在得到的用户的隐向量后，进行匹配是容易的，只需要一个不用太深的DNN网络对用户向量H和商品向量放到一起进行预测即可。但是为了学到更加鲁棒的网络结构，我们使用multi-task的相关技术\cite{16}建立了多个辅助目标共同学习。因为multi-task learning不是本章重点，因此不再详细介绍，下一小节会有相关对比结果。

4，本小节详细介绍序列匹配模型的离线实验以及在线效果。离线部分抽取淘宝搜索一周的用户行为日志，按用户随机分成5份，做交叉验证；在线部分使用的标准A/B Test,大于3-5\%的流量作为测试样本。基本结论如下：

a)对比序列模型和仅使用用户画像作为用户状态。使用序列模型的情况下，主目标匹配的AUC从0.62提升到0.68；辅助目标LTR的AUC从0.65提升到0.72；辅助目标价格档预测的准确率从29\%提升到41\%。

b)对比使用multi-task和不使用的情况下，匹配预测的准确率。在商品向量良好的情况下(使用DNN做pre-train)，AUC能从0.67提升到0.68,提升非常有限；但是在商品向量并不理想的情况下(使用word-to-vec初始化)，不使用multi-task方法的AUC只有0.56，使用后AUC提升到0.66，提升非常明显。

c)对比不用的商品输入向量表示，分别使用了DNN、word-to-vec以及DSSM去预学习一个商品向量，各自或组合作为序列的输入。word-to-vec向量表现的较差，而DNN以及DSSM的向量表现类似；多种向量concat到一起，结果与其中教优的比较一致。

d)在在线实验中，我们通过序列模型对用户的购买力进行了预估，同时对商品的CTR进行了预估。其中购买力的部分的覆盖率较使用前提升了50\%，准率率提升了30\%左右。CTR预估部分，在A/B Test中，使得覆盖人群的点击率提升了3\%左右。

\section{实时个性化模型}
   淘宝搜索对海量用户、卖家之间提供服务。希望用户能有更好的搜索体验的同时，期望卖家也能有更好销售。传统搜索引擎对全部用户展示相同的搜索结果，结果会按相关性、质量进行排序；而个性化搜索更专注于不同的个体，根据每个用户属性与偏好为其定制排序。这样带来的好处是多方面的：首先用户会拥有更好的搜索体验，能看到更多自己偏好的内容从而促进更多的交易；然后会为卖家带来更优质的用户，店铺会吸引更多目标人群；从流量上来看，在搜索流量一定的情况下，个性化能减少无效流量的产生，提高流量的使用效率。
   
  长期个性化在淘宝搜索上已经起着尤为重要的作用。然而存在的问题是，此类模型并不能及时的获取用户、店铺、商品的实时信息，因此在处理冷启动问题(新用户、新商品)、实时兴趣/属性变化等问题上，表现的并不理想。实际上，该类问题是大量存在的，因此我们需要一个实时的个性化排序模型，结合用户的长期与实时兴趣，结合商品的静态与动态属性，为用户提供更好的排序服务。
  
\subsection{整体框架} 
 在传统的推荐系统中，我们可以根据用户的历史购买记录为用户推荐商品以尽可能地促成下一次成交。在众多方法之中，矩阵分解（Matrix Factorization）凭借其对隐空间的建模、对稀疏数据的适应能力以及强大的拟合能力得到了广泛的关注，并在很多实际场景中得到验证，例如Netflix百万大奖赛。然而，搜索场景的特殊性必然使得我们直接套用传统的基于最小化平方损失（square loss）的MF模型的结果是悲观的，我们更关注的是序（rank），而不是某个绝对的偏好程度（preference level）。同时，我们注意到，用户群体的偏好也是实时变化的，如果突然某个时刻开始和你偏好相似的一批用户开始购买某个商品，我们希望能将这个变化及时捕捉到并实时地体现在对你的搜索排序结果中，即将这个商品尽可能排在结果页前面。因此，我们设计了一套针对排序优化的实时协同过滤框架，并在这个框架上设计和实现了2个算法。

  在传统的隐空间分解模型中，我们为每个用户i学习一个向量$U_i \in R^k$，为每一个商品j学习一个向量$V_j \in R^k$，此时模型对用户i在商品j上的预测为
 \begin{equation}\label{yij}
	\begin{split}
		\hat{y_{ij}} = U^T_i V_j
	\end{split}
\end{equation}
 
  针对不同的场景，我们可以设计不同的损失函数$l(y_{ij},\hat{y_{ij}})$去学习U和V。在实际搜索场景中，我们一般可以拿到更多的信息，例如用户相关的特征$x_i^u \in R^{d_u}$，和商品相关的特征$x_i^v \in R^{d_v}$，对这些信息的处理，通常的做法是分别利用用户特征和商品特征计算对应的相似度矩阵，并对其做特征值分解，用较大特征值对应的特征向量做basis去学习对应的U和V。然而，我们都知道特征值分解的复杂度是($n^3$)，对于我们的规模（千万级用户，亿级别的商品）来说是不可接受的。因此，我们使用了一种更直接的方式，令
 
     \begin{equation}\label{uv}
	\begin{split}
		&U_i = W_i^1 x_i^u,  W_i^1 \in R^{k \times d_u} \\
   		&V_j = W_j^2 x_j^v,  W_j^2 \in R^{k \times d_v}
	\end{split}
\end{equation}

		
此时，模型的预测值为

   \begin{equation}\label{uv2}
	\begin{split}
		\hat{y_{ij}} = & (W_i^1 x_i^u) W_j^2 x_j^v \\
      		                 = & (x_i^u)^T (W_i^1)^T W_j^2 x_j^v \\
		                 = & (x_i^u)^T W_{ij} x_j^v
	\end{split}
\end{equation}

其中$W_{ij}=(W_i^1) W_j^2$，等同于一个双线性模型（bilinear model）。我们对以上两种预测模型分别设计了2个算法，并都实现了离线的基于ODPS-GRAPH的BSP并行训练和基于淘宝实时计算平台PORA的在线异步并行训练。下文将分别对此进行介绍。
  
 \subsection{实时矩阵分解（Realtime Matrix Factorization for Ranking with Side Information）} 
 
 假设我们有m个用户和n个商品，除了上文提到的用户向量$U_i \in R^k$和向量$V_j \in R^k$外，我们还为每个商品j学习一个bias，$b_j \in R$。此时的模型预测更新为
 
    \begin{equation}\label{uv}
	\begin{split}
		\hat{y_{ij}} = b_j + U_i^T V_j
    	\end{split}
\end{equation}
	
在搜索排序中，我们更关注的是商品之间的顺序，而不是模型对偏好程度的预测值和真实值之间的平方误差或绝对值误差。从搜索日志中我们抽取训练三元组$D= \{(i, j, k)\}$，其中每一个三元组$(i, ,j, k)$表示用户i更偏好商品j，相比于商品k。对于这样的一个三元组，我们定义损失函数如下
    \begin{equation}\label{uv}
	\begin{split}
		l(y_{ij},y_{ik},\hat{y_{ij}},\hat{y_{ik}}) = max(y_{ij}-y_{ik}-(\hat{y_{ij}}-\hat{y_{ik}}), 0)
    	\end{split}
\end{equation}

 其中，$y_{ij}, y_{ik}$是用户在商品j和k上的真实偏好程度，例如对于一次搜索展现引导的行为，可以设置偏好程度为：成交>加购>收藏>点击>PV。注意这里我们引入了Hinge loss，目的是当我们的模型排序正确时不去做冗余的抑制。此外，我们还使用了已有的一份数据$W \in \{0,1\}^{n \times n}$，描述的是商品之间关于被购买行为的相似度矩阵。如果2个商品在被购买的行为上相似，那么它们在隐空间的向量应该是尽可能靠近的。因此，类似于经典的拉普拉斯特征映射（Laplacian Eigenmap），我们使用了一个正则项体现这项约束
     \begin{equation}\label{uv3}
	\begin{split}
		\Omega(V) = \sum_{m \ne n}||V_m-V_n||^2W_{mn}
    	\end{split}
\end{equation}
	
最后，我们需要优化的目标函数可以形式化为:

\begin{equation}\label{uv4}
	\begin{split}
		f(U, V, b) = & l(y_{ij},y_{ik},\hat{y_{ij}},\hat{y_{ik}}) +  \frac{\lambda_1}{2}||b||^2 +  \frac{\lambda_2}{2}(||U||^2+||V||^2)+ \frac{\lambda_3}{2}\Omega(V) \\
      		                 = & \sum_{i \in S} \sum_{(j,k) \in P_i} max(y_{ij}-y_{ik}-(b_j + U_i^T V_j-b_k - U_i^T V_k), 0) \\
		                 + & \frac{\lambda_1}{2}||B||^2 +  \frac{\lambda_2}{2}(||U||^2+||V||^2) \\
		                 + & \frac{\lambda_3}{2}\sum_{m \ne n}||V_m-V_n||^2W_{mn}
	\end{split}
\end{equation}

由于上述目标函数不像优化平方误差的矩阵分解，因此也无法使用ALS进行加速求解。我们使用随机梯度下降对以上目标函数进行求解。

通常来说，一个好的初始值将很大程度上加速学习的过程，因此，相比于从随机向量开始学习，我们更希望为线上的在线学习提供一份通过离线训练的解作为初值。然而，即使是离线训练，对千万级用户，亿级商品规模进行特定损失函数的矩阵分解，也是集团现有的算法无法满足的。因此，我们在ODPS-GRAPH上实现了我们的算法，其详细过程为

1，读入搜索日志，建立GRAPG节点。具体地，为每个用户和每个商品分别建立对应的节点，存储对应的隐向量，同时将用户相关的所有搜索展现点击购买记录存储在用户节点，每个商品节点不存储任何日志信息。此外，对每个商品，我们要额外为其添加指向购买过该商品的所有的用户的边

2，每个偶数超步内，所有的商品节点从用户节点接受发送过来的梯度，并用来更新自身的向量，同时将更新后最新的向量发送给所有相关用户节点。

3，每个奇数超步内，所有的用户节点从商品节点接受发送过来的最新商品向量，结合自己的用户向量和搜索日志，计算对相关用户向量和商品向量的梯度，最后更新自身向量，并将商品向量梯度发送给相关商品节点

整个过程如下图所示：

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\linewidth]{"fig/4_p_1"}
\end{figure}

我们将每轮迭代评估的每次搜索上的NDCG绘制出来如下图所示:

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\linewidth]{"fig/4_p_2"}
\end{figure}
  
  对于线上的在线学习部分，由于实时个性化的需求，我们需要当用户发生了一次行为之后，可以在几分钟之内更新到模型，并迅速影响到后续的搜索排序。因此，我们只在搜索实时计算平台PORA上实现了如下的基于parameter server的异步并行架构，每次用户行为日志被Log parser搜集后被送到某个gradient worker，计算在特定用户和商品上的梯度，并发送到存储在Hbase上的parameter server进行参数更新，并同时将最新的用户/商品向量同步到UPS和引擎正排上，实时影响线上排序效果。
  
\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\linewidth]{"fig/4_p_3"}
\end{figure}

\subsection{实时双线性模型（Realtime Matrix Factorization for Ranking with Side Information）} 
本节提出的实时双线性模型，是一个实时、pairwise、双线性模型。下面简要说明我们设计这样模型的原因。

  Why real-time？从商品角度上：①商品上架、下架是频繁的，新商品在长期个性化中没有特征，因此需要实时个性化处理；②同一线上商品的某些属性也是动态变化的，如图，即使热门商品的CTR也会随时间不断变化，因此长期属性不如实时准确（想象一下，春晚后某件主持人穿的礼服，以往排序下，搜索是排不出来的；但使用实时模型后，卖家上架后，大量用户搜索，该礼服能立刻排在前面）。从用户角度上：①用户的兴趣会变化的，长期兴趣并不永远是不变的；②新用户缺少信息；③同号用户的大量存在，不同用户共同使用同一账号会对长期个性化产生极大干扰
  
  \begin{figure}[h]
	\centering
	\includegraphics[width=0.5\linewidth]{"fig/4_p_4"}
\end{figure}

Why pairwise？不得不说，Piontwise的方法在搜索中会存在很大的问题，这主要是由于样本分布极不均匀造成的。例如，可以分析得到男性用户对女装的CTR反而大于对男装的CTR；这并不表示对男性个性化的时候需要出女装，而是由于男性用户搜女装的时候，目标是更明确的。Pairwise的方式能很好的解决该问题，它考虑的是pair间商品属性的差异，因此在商品属性相同的时候，参数不会更新。

  Why bilinear？用户在淘宝上的行为时丰富的，商品的属性也是丰富的，即使对冷启动的情况，我们也能获取用户的手机型号，ip等信息，商品的类目、价格等信息。在有这些信息的情况下，我们利用它们能使模型的结果更加准确。

定义U为全体用户，I为全部商品，用户反馈S表示implicit feedback，$S\subseteqq U \times I $

  ① 每个商品，Item($I \in R^C$)，由2部分组成，分别是静态特征（Static descriptors）和动态特征（Temporal characteristics）。前者包含价格、风格、性别等(d)，后者包含实时ctr、实时销量等。
  
  ② 每个用户，User($U \in R^D$)，同样由2部分组成，分别是特征(U)与用户ID(B)。
  
  ③ 行为，$r_{u,i}$（Interactive Feedback），其中$r_{u,i}$是0/1（实际上也可以是实数，这里只考虑0/1的implicit feedback）,表示用户u对商品i的偏好。

  我们排序的目标是对用户设置全部商品上的排序方案，$>_u \subset I^2$，其中$>_u $必须满足：
  \begin{equation}
\begin{split}
    \left\{
	\begin{aligned}
	& \forall i,j \in I: i != j && \Rightarrow i >_u j \vee j>_u i \\
	&  \forall i,j \in I:i >_u j \land j>_u i && i = j\\
	& \forall i,j \in I:i >_u j \land j>_u k && i >_u k 
	\end{aligned}
	\right.
\end{split}
\end{equation}

另外，我们定义$I_u^+ = \{i \in I:(u,i) \in S\}$为用户u点击的全部商品,$U_i^+ = \{u \in U:(u,i) \in S\}$为点击过商品i的全部用户。在bilinear model中，每个用户对商品的偏好表示为：
     \begin{equation}\label{uv3}
	\begin{split}
		s_{i,j} = \sum_{a=1}^C \sum_{b=1}^D U_{i,b}I_{j,a}W_{a,b} + \sum_{a=1}^C B_{i,a}I_{j,a}
    	\end{split}
\end{equation}

D和C分别表示用户和商品的特征维度，B表示每个用户ID在商品特征上的偏移。将用户的B看做自身feature的一个稀疏维度，那么考虑商品有静态和动态2类属性， 如下图所示，该模型可以看做是将用户feature的每个维度向item的每个维度做投影，然后在商品空间上做点乘，W表示投影矩阵。

  \begin{figure}[h]
	\centering
	\includegraphics[width=0.6\linewidth]{"fig/4_p_5"}
\end{figure}

有了上面表示后，我们需要用日志数据去fit我们的模型，根据贝叶斯公式，我们求一个最大后验估计(MAP)。假设所有参数表示为$\theta$，则后验分布为：
     \begin{equation}\label{uv3}
	\begin{split}
		p(\theta|>_u) \propto p(>_u|\theta)p(\theta)
    	\end{split}
\end{equation}

我们算法的目标是最大化该后验。在计算梯度公式后，简单的使用随机梯度下降法就能求解该问题，但是速度和精度并不理想。为此，我们尝试了使用bootstrap sampling方法和adaptive oversampling方法，最终采用的是后者。整个模型的训练也包括2部分，离线学习和在线学习。离线部分主要是学习bilinear部分中的矩阵W，这部分认为是稳定的，作为在线部分的初始值。在线部分主要是学习每个用户ID对应的属性偏好，捕捉用户当前的信息。学习方法类似上一节的矩阵分解模型，这里不再重复。

\subsection{实验与结果} 

我们实时个性化算法的目标是在淘宝搜索中提升用户的搜索体验，提高流量效率。从指标上表现为搜索的NDCG/MRR等指标，以及线上的CTR等指标。实时模型于7月底上线手淘无线，rank仍在调整权重中，但是线上真实的NDCG和MRR值已经可以获取。

  下图1是矩阵分解模型的线上NDCG变化曲线，图2是双线性模型的线上MRR变化曲线，日期相同。从结果上，我们可以看到，随着每天实时模型的运行，NDCG和MRR均能产生大幅的提升。这表示一天中，用户点击、成交的商品，在结果页中越来越靠前，即获得的排序能更贴近用户的兴趣。

 \begin{figure}[h]
	\centering
	\includegraphics[width=0.6\linewidth]{"fig/4_p_6"}
\end{figure}

 \begin{figure}[h]
	\centering
	\includegraphics[width=0.6\linewidth]{"fig/4_p_7"}
\end{figure}

下面2张图是一天的模型曲线，左图是矩阵分解的NDCG变化情况，右图是双线性模型的MRR变化情况。除了可以看出曲线的上升外，我们可以看到，矩阵分解模型直到每天结束仍未收敛到最优状态，曲线上升趋势依然明显；双线性模型在每天最后，曲线基本不会上升，甚至有略微下降。因此我们仍然需要对模型参数进行调整，例如前者应该加大学习率，后者则应有所降低。
\begin{figure}[tbp]
	\centering
	\subfigure[Recall rate of Price Level]{
		\begin{minipage}[b]{0.4\textwidth}
			\includegraphics[width=0.95\textwidth]{fig/4_p_8} 
		\end{minipage}
	}
	\subfigure[Precision of Price Level]{
		\begin{minipage}[b]{0.4\textwidth}
			\includegraphics[width=0.95\textwidth]{fig/4_p_9}
		\end{minipage}
	}                   
	\label{fig:Price}
\end{figure}

\section{排序学习}
	@元涵，@凌运， @龙楚
	

\section{展示学习}
	个性化展示 @席奈
	个性化短标题：@苏哲，@仁重 


\section{深度学习时代的排序模型优化 }

\subsection{用户行为建模} 
用户建模是搜索与推荐模型的核心技术。淘宝搜索排序算分的对象是 <user, query, item> 三元组，我们从样本特征表达的角度上来看，item是比较稠密而且稳定的部分，在大样本的环境下，大部分信息都能够被id embedding所表达，相反user是三者中比较稀疏的部分，所以对于user的描述，需要大量的泛化特征。从模型分类的角度上来看，用户与商品的静态特征作用在于增强模型的泛化性，而用户实时行为的引入与建模，可以大大增强样本之间的区分性，显著地提升模型的分类精度。我们把用户建模的过程看作是对用户的信息抽象和信息组织的过程。信息抽象方面我们不断地优化与丰富建模方式：1. user profile用来表征用户的静态属性信息；2. 偏好标签的挖掘，从行为上预测用户的一般性偏好；3. 实时行为建模，更细粒度的对当前请求下的兴趣刻画与描述。信息处理方面，我们从行为周期和行为内容方面对用户行为数据进行合理的组织：1. 从行为周期上，我们将行为序列划分成中短期和长期，分别使用不同的时间跨度，描述不同粒度的兴趣；2. 从行为内容维度上，直接行为反馈商品和曝光商品分别被用来显式和隐式的表达用户意图，与此同时，我们也将用户行为数据从传统的电商商品，延伸到一些泛内容信息； 



\subsection{大规模深度排序模型的实时更新与热启动} 

超大模型如何实现快速更新，我们探索了Multi-Layer Multi-Frequency的更新方法：


增量训练模式下，线上base模型已经训练了很多天的数据，新模型（加特征，改结构）如何快速恢复base模型的效果，一步就站在base模型巨人的肩膀上继续往上走，而不是慢慢训练苦苦追赶？我们实现一个成熟的解决方案，并且已经全面应用起来

\subsection{大规模深度学习模型的量化\&automL} 


\section{ 轻量排序融合框架 } 

工业级排序系统发展至今，单靠深度精排大模型已无法满足有所业务需求，大模型之后通常配备以效率为目标的离线/实时LTR（Learning-To-Rank）与重排序（Re-Rank），而纯业务驱动的沙盘调控、价格调节、新品与包邮置顶、打散与择优等策略再对排序结果施加影响。在AliExpress（AE）搜索排序系统中，上述若干子模型通常对排序分做加法和乘法来修改排序结果，从而实现其目标。典型地，最终排序分可以表示成
的形式；其中，子模型
利用加法/线性组合改变最终排序分，而子模型
利用乘法改变最终排序分；加法的影响尚且可控，而乘法的影响则牵一发而动全身。实际上，排序链路中常常面临多个子模型竞争最终排序结果的困境。倘若不加以限制，子模型彼此独立加分或乘分，排序分将很快膨胀，而各路子模型在最终排序结果中所占比重，也将混沌一团、无从分析。

从宏观上看，各路排序模型的目标可分为两类：效率驱动与业务驱动。深度精排、LTR、重排序等模型属于前者，而针对货品、卖家等等的流量调控与排序规则属于后者。一个自然的想法是，将效率驱动与业务驱动的子模型加分逻辑分开，凯撒的归凯撒，上帝的归上帝。业务驱动的子模型不是本文关注的重点，暂且按下不表。针对效率驱动的子模型，既然它们有着共同的目标，我们有理由相信，这些子模型对商品的排序有内在一致性；人为对排序分做加法或乘法，由于加数和乘数的超参数难以调节（例如，上文公式中的），超参数过大导致对应的子模型具有排他性，而过小则对应子模型的影响无法体现；商品排序的内在一致性被忽略或者破坏，从而让某几路子模型主导排序结果，其他子模型的贡献被抹去。

受社会学投票理论（Voting Theory）中的排序聚合（Rank Aggregation）方法启发，我们不再关注排序分，而是转向排序的顺序本身，根据商品在各个排序结果中的相对位置，获得各路子模型聚合后的排序结果。将子模型的排序结果看作是商品集合的一个置换（Permutation），商品的打分被忽略，只剩下彼此的顺序关系。给定一组置换[1]，通过定义置换之间的距离，排序聚合方法找到这组置换的平均值，把它当作聚合之后的排序。对应于投票理论，排序系统中的子模型相当于投票者，而商品相当于候选人；投票理论和排序系统的目标，都是要找到一组最优的最终排序，最大程度满足所有投票者/子模型的好恶。

然而，阿罗悖论（Arrow Paradox）证实，不存在一种投票制度能够满足所有标准[2]。因此，我们需要确定，各路子模型排序结果的合并中，哪些标准是必须遵守的，哪些标准是可以放弃的？例如，阿罗悖论中提及的非独裁标准，即，“不存在一个投票者，使得投票结果总是等同于他的排序”，在排序系统中显然可以放弃。经过文献调研与场景分析，本文主要考虑投票制度中的孔多塞标准（Condorcet Criterion），即，“如果一个候选人在成对比较里击败了所有候选人，则他一定排在第一位”。前人研究[3]表明，定义置换间的距离为逆序对（Discordant Pair）的个数，即，Kendall Tau距离[4]，可以得到满足孔多塞标准的投票结果，本文也将依照这一原则。

当下工业界也存在聚合多路子模型打分的排序模块，比如，协调（Ensemble）多路排序结果的LTR模型，以及着眼于全页面优化的重排序。与LTR相比，经典的排序聚合不需要监督信息，并且以整页PV（Page View）为单位优化目标。与重排序相比，经典的排序聚合不需要用户和商品特征；另外，排序聚合是针对上下游链路联合优化的尝试，目标是全链路指标最大化，而重排序的重点是商品候选集内排序的最优化。事实上，排序聚合与LTR、重排序完全可以共存，LTR可以作为排序聚合的一路子模型输入，而排序聚合可以作为重排序的上游，为重排序提供更加多样化的商品集合。以AE搜索排序系统为例，我们观察到，LTR模型对Top20商品的排序有优势，而精排大模型对Top20之后的商品排序效率更高，即，一个较优的策略是：Top20商品按照LTR模型打分排序，而Top20之后的商品按照精排大模型打分排序。现有的模型无法做到这一点。



\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{\protect\numberline{}{\hspace{-1.5em}参考文献}}
\markboth{参考文献}{参考文献}
\bibitem{1} 淘宝搜索全链路有效行为量化模型(UBM\&UCM), http://www.atatech.org/articles/38550
\bibitem{2} User Browsing Model的实现与应用, http://www.atatech.org/articles/23111
\bibitem{3} 搜索个性化介绍, http://www.atatech.org/articles/48548
\bibitem{4} Mikolov, T., Karafi´at, M., Burget, L., Cernock`y, J., Khudanpur, S.: Recurrent neural network based language model. J. Interspeech. 1045–1048 (2010)
\bibitem{5}  Hochreiter, S., Schmidhuber J.: Long short-term memory. J. Neural Computation. 9(8), 1735–1780 (1997)
\bibitem{6} Learning Long-Term Dependencies with Gradient Descent is Difficult
\bibitem{7} Graves, A., Wayne, G., Danihelka, I.: Neural Turing Machine. arXiv preprint:1410.5401v2 (2014)
\bibitem{8} Weston, J., Chopra, S., Bordes, A.: Memory Networks. C. International Conference on Learning Representations. arXiv:1410.3916 (2015)
\bibitem{9} Sukhbaatar, S., Szlam, A., Weston, J., Fergus, R.: End-To-End Memory Networks. J. Advances in Neural Information Processing Systems. 28, 2440–2448 (2015)
\bibitem{10} Gers, Felix A and Schmidhuber, J: Recurrent Nets that Time and Count. J. in IJCNN 2000
\bibitem{11} Cho, Kyunghyun and Van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshuai: Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation. arXiv preprint arXiv:1406.1078 (2014)
\bibitem{12} Koutnik, Jan and Greff, Klaus and Gomez, Faustino and Schmidhuber, Juergen: A Clockwork RNN. J. arXiv preprint arXiv:1402.3511 (2014)
\bibitem{13} Zaremba, Wojciech: An Empirical Exploration of Recurrent Network Architectures. in LMLR 2015
\bibitem{14} Greff, Klaus and Srivastava, Rupesh K and Koutnik, Jan and Steunebrink, Bas R and Schmidhuber, J: A search space odyssey. IEEE transactions on neural networks and learning systems (2016)
\bibitem{15} Misra, Ishan and Shrivastava, Abhinav and Gupta, Abhinav and Hebert, Martial: Cross-stitch networks for multi-task learning. CVPR (2016)
\end{thebibliography}

 
