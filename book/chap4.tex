
\chapter{个性化搜索背后的核心技术}
\thispagestyle{empty}

\setlength{\fboxrule}{0pt}\setlength{\fboxsep}{0cm}
\noindent\shadowbox{
\begin{tcolorbox}[arc=0mm,colback=lightblue,colframe=darkblue,title=学习目标与要求]
%\kai\textcolor{darkblue}{1.~~强化学习．} \\ 

\end{tcolorbox}}
\setlength{\fboxrule}{1pt}\setlength{\fboxsep}{4pt} 

综述性的东西，@三桐，@公达

\section{匹配学习}
	
\subsection{一阶人货匹配模型} 
	@公达 u2i，u2s，u2b 

\subsection{高阶人货匹配模型} 
	@公达 u2i2i，u2s2i，u2b2i 

\subsection{深度匹配模型} 

\subsection{序列匹配模型} 
1，前面三个章节我们递进的描述了用户与单个商品之间的匹配方式和模型。然而，上述方法均假设用户的购物行为之间是独立的——并不存在依赖、相关或序列关系。

举例来说，一个用户$U_1$2天内依次购买了以下商品：烤箱、面粉、奶油；另一个用户$U_2$半年内依次购买了孕妇衣、尿布和奶瓶。我们先考虑用户$U_1$，我们可以从他购买了烤箱和面粉2种商品推断他很可能想要做蛋糕（而这从每个单一买的商品都是很难推断的），因此也许需要奶油；再考虑用户$U_2$，我们可以从她依次购买了孕妇衣和尿布推断她很可能怀孕过并且已经生了小宝宝（从某一件来推荐会比较勉强），因此马上会需要奶瓶等婴儿用品。

从上面例子我们可以看出，用户的购物行为之间往往是存在高阶依赖关系的，即仅用户购买了一个商品集合$\{A, B, C\}$后，才会购买商品$D$；同时，用户的购物行为也会存在序列关系，即用户购买C，仅会在他依次购买了商品A和B之后。在这2种关系下，我们前3节使用的模型会很难捕捉这类规律。因此我们需要一种模型，能整体的考虑用户的行为历史（而不是将其行为拆分成一个一个的单独分析），进而推断他接下来的需求。

下面我们会首先介绍几种经典的序列模型以及带有记忆功能的模型，然后会详细介绍在淘宝搜索中，我们怎样使用这类模型做到用户与商品之间的序列匹配。

2，在机器学习的任务环境中，我们有大量的场景都是需要做一个序列预测和带有记忆的推断的。例如在query自动补全的场景下，我们需要根据用户输入的文字或者词序列来预测用户下一个最可能会输入的词语；又例如有这样一个问题，需要让机器在阅读了一整篇文章后，回答若干关于这个文章的问题。这类问题和场景下都需要模型具有一定的记忆能力，能在获取新信息的同时，记住部分老的信息。

最常用而有效的方式是使用一个递归神经网络模型(RNN \cite{4,5})。正如其名字描述的，递归神经网络在隐层结构上存在一个循环，即当前隐层的输入是上一个隐层的输出以及当前的输入2项一起。由于每个隐层的信息都能递归的输入到下一个隐层中，因此会具有一定的记忆能力。如图\ref{fig:RNN}，我们将RNN按时间序列“打开”，可以看到前一时刻的隐层$S_{t-1}$和当前输入$X_t$会共同影响当前的隐层$S_{t}$。

\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{"fig/RNN"}
	\caption{递归神经网络(RNN)示意图}
	\label{fig:RNN}
\end{figure}	

然而RNN存在的最大问题是“梯度消失和爆炸”问题。这是因为在神经网络进行反向传播(backpropagation)的时候，传播的梯度会是$w_{l,h}(t)$(递归网络的权重)的倍数；因此在递归层数较深的时候，梯度会消失掉(当$w_{l,h}(t)<1$)或者爆炸(当$w_{l,h}(t)>1$)。

3，序列模型具体在搜索场景的应用

4，结果展示
	
\section{排序学习}
	@元涵，@凌运， @龙楚
\subsection{}

\section{展示学习}
	个性化短标题：@苏哲，@仁重 

\section{模型参数优化} 
	@公达

\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{\protect\numberline{}{\hspace{-1.5em}参考文献}}
\markboth{参考文献}{参考文献}
\bibitem{1} 淘宝搜索全链路有效行为量化模型(UBM\&UCM), http://www.atatech.org/articles/38550
\bibitem{2} User Browsing Model的实现与应用, http://www.atatech.org/articles/23111
\bibitem{3} 搜索个性化介绍, http://www.atatech.org/articles/48548
\bibitem{4} Mikolov, T., Karafi´at, M., Burget, L., Cernock`y, J., Khudanpur, S.: Recurrent neural network based language model. J. Interspeech. 1045–1048 (2010)
\bibitem{5}  Hochreiter, S., Schmidhuber J.: Long short-term memory. J. Neural Computation. 9(8), 1735–1780 (1997)
\end{thebibliography}

 
