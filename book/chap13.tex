
\chapter{ 排序算法 }
\thispagestyle{empty}

\setlength{\fboxrule}{0pt}\setlength{\fboxsep}{0cm}
\noindent\shadowbox{
\begin{tcolorbox}[arc=0mm,colback=lightblue,colframe=darkblue,title=学习目标与要求]
%\kai\textcolor{darkblue}{1.~~强化学习．} \\ 

\end{tcolorbox}}
\setlength{\fboxrule}{1pt}\setlength{\fboxsep}{4pt} 

用户在淘宝输入关键词“手机”后，搜索引擎召回了几百万以上的标题中带有“手机”的商品，这些商品中有大家常见理解的手机，也有“手机壳”，“手机配件”，“手机充电器”等商品，找到真正的手机，是在第2章的搜索相关性中解决的问题。再接下来，真正的手机也是成千上万的，这些商品如何排序，取决于多种因素，分为个性化相关的（下一章讲述），与非个性化相关的。
本章主要讲述商品非个性化的排序因素，除比较传统的Query-Item的ctr以外。淘宝商品搜索排序与传统网页搜索对比，存在了很多不同的地方，这也决定了算法有很大的不同。首选用户所有的路径都在淘宝内部，可以拿到所有的数据，对其建模，再应用于各个环节。


\section{商品详情页满意度模型} 
\subsection{为什么需要详情页满意度}
用户在搜索上的整个购物路径大概包括搜索query，浏览SRP点击宝贝，浏览宝贝详情页，成交四个环节。我们要做的事情就是优化用户购物路径上的每个环节，让用户最终能够顺利成交。
\par 我们以前的工作主要围绕在上述购物路径上的两个环节：
\begin{enumerate}
\item 用户搜索query到宝贝点击，这一步我们通常用ctr（click through rate）来衡量，我们通过各种算法把点击率高的宝贝展现给用户来提升ctr。
\item 宝贝点击到成交，这一步我们通常用ipvr（ipv conversion rate）来衡量，我们通过各种算法把ipv转换率高的宝贝展现给用户来提升ipvr。
\end{enumerate}
粗看，上述两个工作好像已经覆盖了从最开始的搜索query到最后成交的整个路径，但细看就会发现，在ipvr这一步我们跳过了用户在宝贝详情页上的信息。那么我们是否应跳过这个环节，只看用户最终是否成交了呢？答案是否定的，因为成交还是非常稀疏的，这个稀疏性可以通过下面两组数据来体现：
\begin{enumerate}
\item ipvr只有2\%，即100个ipv只能换来2个成交，绝大部分ipv最终无法成交。这些没有成交的ipv没有区分度，都被认为是用户不满意的。
\item 一天有成交的宝贝有500万，30天有成交的宝贝有6000万，大部分宝贝30天都没有一笔成交；有成交的宝贝中，95\%++的宝贝成交也在10笔以下。
\end{enumerate}
通过上面两组数据可以看到如果仅用成交信息来选取优质宝贝显然是不够的。既然成交是不够的，那么用户在详情页上发生的信息是否够充分呢，是否能够反映用户对宝贝的满意程度呢？
\subsection{详情页信息}
详情页上的信息主要两类：
\begin{enumerate}
\item 详情页上控件的点击信息，比如下图中的红框中各种控件的点击信息都能捕捉到。
\end{enumerate}
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/xqy0.png"}
	\caption{}
	\label{fig:xqy0}
\end{figure}
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/xqy1.png"}
	\caption{}
	\label{fig:xqy1}
\end{figure}
​​​\par 相对于成交，详情页点击信息还是非常丰富的。一天搜索引导的详情页点击为2亿，而成交只有500万，详情页点击是成交的40倍，平均1个ipv有1.4个详情页点击。
\par 详情页行为除了丰富性，是否能反映用户的满意程度？我们假设用户如果成交，那么肯定是满意度的。我们来分析一下详情页上各种点击行为和成交的关系，是不是发现了详情页行为的ipv更有可能成交？
\par 每一种点击行为发生与否，后续的ipv转换率差异（红色是发了该行为的转换率，蓝色是没有发现该行为的转换率，总体的平均转换率为2\%）：
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/xqy2.png"}
	\caption{}
	\label{fig:xqy2}
\end{figure}
\par 可以看到，对于每一种详情页点击，ipv上发生了该行为的转换率都要高于没有发生该行为的概率，意思就是说用户在详情页上点了肯定是比没点好的，用户的点击也是有成本，不会没事瞎点。对于几个比较特殊的详情页点击，如“加入购物车”，“立刻购买”，后续的ipv转换率是非常高的。
\begin{itemize}
\item 详情页停留时间
\end{itemize}

\par 这个也非常直观，用户在详情页上花的时间越多，表明该详情页越能吸引用户。在互联网上，页面停留时间，网站停留时间也是各个网站非常关注的指标，用户在网站上花更多的时间意味着网站的黏性越高，意味着网站能够为用户提供了更有价值的内容和服务，相应的用户在网站上转化的机会也越多。
\par 但不幸的是我们并没有现成的详情页停留时间，进入详情页的时间是有日志记录的，但离开详情页的时间并没有记录，那么怎么得到用户在详情页的停留时间？首先我们看一下用户在搜索上的行为示意图：
​\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/xqy3.png"}
	\caption{}
	\label{fig:xqy3}
\end{figure}
​用户来到搜索，会有一个或者多个搜索意图，每一个搜索意图我们称之为一个搜索session，用户在一个session中会使用一个或者多个query来表达他的需求，同一个session内的不同query表达的需求主题上应该是类似的。用户搜索了query后，浏览系统返回給他的搜索结果，在结果页上点击他感兴趣的宝贝，进入宝贝详情页， 然后在详情页上发生各种点击动作。浏览完一个宝贝详情页后，继续点击，浏览下一个宝贝或者换一个query继续搜索。
\par 如果用户的行为完全是按照我们上面的设计，是一个串行的模式，那么按照session为key把用户的所有行为串起来，可以得到如下的行为时间序列：
​\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/xqy4.png"}
	\caption{}
	\label{fig:xqy4}
\end{figure}
​在这个时间序列中，我们可以计算出每一个详情页的停留时间：
\newline 宝贝1详情页停留时间= t4–t3
\newline 宝贝2详情页停留时间= t6–t5
\newline 宝贝3详情页停留时间=  ?  –t6，无法计算，session结尾点击。

​当然实际上有些用户的行为并不一定是串行的，比如用户可能会搜索了一个query后，连续打开多个详情页，再一个一个慢慢看。
​\par 对于每一个ipv我们都能计算出的页面停留时间，信息非常丰富。
\par 那么详情页停留是否能反映用户的满意度呢？同样我们来看一下详情页停留时间和转换率的关系：
​
​\par 上面的数据可以看出：
\begin{enumerate}
\item 停留时间越长，ipv转换率越高
\item 最前面的一个停留时间为-1的表示的是session结尾点击，可以看到，session结尾点击转换率非常高，符合预期。
\item 前面几段（0-5秒，5-10秒，10-15秒）的ipv转换率并没有完全单调递减，这个有可能就是前面说的当用户行为不是串行模型下产生的数据。
\end{enumerate}

\subsection{如何建模}
有了详情页点击信息，也有了详情页停留时间，下面说下如何使用这些信息来计算用户对一个ipv的满意程度。
\par 怎么样算是用户满意呢？我们模型的目标是什么？这是我们建模遇到的第一个问题。答案是我也不知道用户是否满意，我们并没有办法让用户显示的告诉我们他是否对满意，所以我们还是只能认为如果用户最终成交了，那么用户肯定是满意的，即我们的模型目标是这个ipv 最后是否成交，一个二分类问题。
\par 对于这个二分类问题，我们选取的是常用的逻辑回归模型。
\par 特征全为0/1特征（binary feature），对于详情页点击类特征，1表示ipv上发生了该类点击行为，0表示没有发生该类点击行为；对于停留时间特征，我们把连续的停留时间离散化成50档，停留时间落在某一档，则该档特征为1，其余档特征全为0.


\section{用户浏览模型\&用户点击满意度模型}  
用户在搜索上的整个购物路径大概包括搜索query，浏览SRP点击宝贝，浏览宝贝详情页，成交四个环节，搜索记录的日志数据在用户在整个搜索流程中的各个环节都存在一定的精度的损失，从输入Query到搜索结果的展示，再到后续的点击和成交，只有有效的PV才有可能获得点击，同理，也只有有效的IPV才能获得成交，而日志中记录了大量的无效PV及IPV，因此，我们的目标就是消除这些无效信息对模型的影响。
此外，手机端的搜索，由于搜索结果页信息过少，因此分析用户在详情页的行为显得更加必要。通过对用户在详情页的行为进行建模，区分出哪些点击是无效点击，哪些点击是有效点击是详情页满意度模型所需要达到的目标，而最终区分出来各种点击之后，我们需要将我们通过详情页满意度模型学得的有用信息作用于我们最终的cvr预估模型,如下图所示，我们通过UBM（User Browsing Model）和 UCM（User Click Model）来分别量化有效的pv和有效的点击。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.5\linewidth]{"fig/ubm2.png"}
	\caption{}
	\label{fig:ubm2}
\end{figure}


\subsection{UBM(用户浏览模型)}
搜索的日志提供了大量非常宝贵的相关性信息，然而日志中记录的pv信息与实际的pv与一定的差距，日志中记录的展现宝贝在实际上用户并不一定真的看到，排序的位置对用户是否点击也存在一定的影响。User Browsing Model(UBM) 旨在消除这些因素对ctr的影响，使得根据历史信息得到的ctr能更好的拟合宝贝原始的ctr。下图为各个位置的CTR的分布
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.5\linewidth]{"fig/ubm3.png"}
	\caption{}
	\label{fig:ubm3}
\end{figure}

UBM通过对用户行为数据的建模，构建出Query到宝贝历史CTR【History CTR】与（Query到宝贝展示概率【Examination】和Query到宝贝真实CTR【attractiveness】）这二者之间的关系。History CTR = Examination * attractiveness。
在后续的使用中，UBM得到的模型可以有两种使用方式：1)宝贝真实CTR【attractiveness】可以用于宝贝的CTR预估模型；2)宝贝的展示概率【Examination】可以用于修正宝贝预估模型中的目标。

考虑这样的场景，当一个用户输入一个query时，会由引擎返回给他一个结果列表，该用户从第一个结果开始按照排序结果的顺序进行浏览，对于每一个位置的结果，用户需要决定是否仔细查看这个结果，如果用户对该结果进行了一次点击，则说明当前结果对于用户具有一定的吸引力。从这个场景中我们可以看出，整个点击的行为串需要两次的判定，首先是“是否看到”(Examination)，接着是“是否点击”(attractiveness)。
UBM中假设用户是否看到的概率与排序的位置r以及距离上一次点击的距离d有关，之所以考虑距离上一次点击的距离是基于这样的假设：当用户看到一大串的不相关的结果时，用户更倾向于放弃此次搜索。此外，是否点击的概率则是由当前的query(q)与当前展示的结果(u)决定的，因此Examination和Attractiveness可以定义如下：
\begin{eqnarray}
P(a|u,q) &=& \alpha_{uq}^a(1-\alpha_{uq}^a)
\\
P(e|r,d) &=& \gamma_{rd}^e(1-\gamma_{rd}^e)
\end{eqnarray}
那么，一次点击行为序列则可以使用联合概率$P(c,a,e|u,q,d,r)$来表示：
\begin{equation}
\begin{aligned}
P(c,a,e|u,q,d,r) = P(c|a,e)P(e|r,d)P(a|u,q) \\
= P(c|a,e)\gamma_{rd}^e(1-\gamma_{rd})^{1-e}\alpha_{uq}^a(1-\alpha_{uq})^{1-a}
\end{aligned}
\end{equation}

为了计算一个观测组(c,u,q,d)，则需要分别考虑点击与否的情况，当c=1时，即当前发生一次点击，我们可以以此推断当前用户既看到了这条结果(e=1)，同时这条结果对用户有一定的吸引力(a=1)，与此相反，若当前没有发生点击，则说明当前结果用户没看到或者没有吸引力，形式化的表示以上两种情况如下：
\begin{eqnarray}
P(c=1|u,q,r,d) &=& \alpha_{uq}\gamma_{rd}
\\
P(c=0|u,q,r,d) &=& 1 - \alpha_{uq}\gamma_{rd}
\end{eqnarray}
\subsection{UCM(用户点击模型)}
用户在详情页的行为可以很好的反应出这次ipv的质量，例如：用户在进入详情页之后立刻点击了返回，那么用户这次点击可能成交的概率就相对较小，而如果用户进入详情页之后查看了大图，和卖家进行了旺旺交流，那么用户这次点击可能成交的概率就更大，我们则称后面这一次的点击的质量更高。
那么我们要怎么对这些行为进行建模呢？由于我们往往通过一次搜索是否引导成交衡量这次搜索是否满意，因此，我们对详情页行为进行建模时，也是以单次ipv是否最终有引导成交作为目标对详情页的各种行为进行建模。同时，除了用户在详情页的虚拟点击行为外。由于在无线的应用场景中，还有一个很重要的因素，即详情页的停留时间，pc上由于浏览器可以开多个tab，因此停留时间不好计算，而无线端由于其自身特点，我们能够更好的把停留时间这一维度的特征使用进来。下图为各种虚拟点击行为训练出来的权重分布，其中5,11,17这3个凸起的点分别对应加购，立即购买，和旺信三种虚拟点击的行为。 

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/ubm4.png"}
	\caption{}
	\label{fig:ubm4}
\end{figure}

 使用UCM对有效点击进行折算，最终得到的有效点击数如下面公式所示：
\begin{figure}[!h]
	\centering
	\includegraphics[width=1.0\linewidth]{"fig/ubm5.png"}
	\caption{}
	\label{fig:ubm5}
\end{figure}
 其中，
\begin{figure}[!h]
	\centering
	\includegraphics[width=1.0\linewidth]{"fig/ubm6.png"}
	\caption{}
	\label{fig:ubm6}
\end{figure}
参数W基于下面的目标函数使用LR进行求解：
\begin{figure}[!h]
	\centering
	\includegraphics[width=1.0\linewidth]{"fig/ubm7.png"}
	\caption{}
	\label{fig:ubm7}
\end{figure}

\subsection{模型融合}
使用UBM可以去除日志中记录的无效pv,而使用UCM可以预测出每一次ipv的质量，从而对每次点击做一次折算，消除无效点击，但是这些都不是我们最终的目标，我们要做的还是cvr预估,那我们如何将我们通过UCM以及UBM学得的有用信息最终作用于我们的预估模型中呢？对于这个问题，我们做了以下两个方面的尝试：
\subsubsection{UBM模型与UCM融合的统计版}
       从前面的描述中，我们可以很直接的看到，实际上我们使用UBM得到的结果即为用户真实看到的pv,而使用UCM得到的即为真正有效的点击，因此很容易想到的一种融合方式即为使用这两个模型的预测结果对日志中记录的pv和点击都做对应的折算，然后使用折算后的历史ctr作为宝贝的ctr作用于线上，使用这种简单的方式作为最初步的尝试，在ctr,转化率等上均有一定收益，也验证了模型融合的可行性。
\subsubsection{UBM模型与UCM融合模型版}
	过使用统计版验证有效性后，最终我们还是需要做模型的融合，需要解决的主要问题还是如何将我们使用UBM和UCM得到的有效信息应用到我们最终的预估模型中。传统的CVR预估模型中，在训练目标中使用pv作为负样本，点击与成交作为正样本，如前文描述中可以看出，由于日志中的pv和点击都是包含噪音数据的，这样自然会使得模型训练的目标本身就存在一定的偏差，而模型训练的目的实际上是无限的接近训练时的目标，但是如果目标本身存在偏差，那即使模型训练的再接近目标仍然无法达到最好的效果。在融合模型的过程中，我们实际上是使用前面两个模型的训练结果来作为最终预估模型的目标，这样做的好处在于通过消除目标中的有偏信息，修正模型的目标。提高模型训练优化能够达到的上界，使得预估模型的优化空间得到很好的提升。具体的融合方式如图所示:

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.5\linewidth]{"fig/ubm0.png"}
	\caption{}
	\label{fig:ubm0}
\end{figure}
	

 如图所示，我们保留了传统预估模型的基本框架，但同时我们需要把我们通过其他模型训练得到的有用的信息应用过来，我们的作用方式是，通过使用UBM和UCM的预测结果作为预估模型最终的训练目标来达到模型融合的效果。
\subsection{实验结果}
最终融合模型在线上的BTS效果在成交转化率这些相应指标上都得到了一定的收益,如下图所示:
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.5\linewidth]{"fig/ubm1.png"}
	\caption{}
	\label{fig:ubm1}
\end{figure}

分别使用三种方法与基准桶进行对比实验，方法一为统计版CVR，即直接使用历史30天的点击和成交信息作为宝贝的CVR预估的得分作用于线上，后两种方法为前文提到的UBM和详情页满意度模型融合的统计版和模型版，从对比数据中我们可以看出，我们最终的融合模型版相比纯统计版的CVR模型在转化率方面有较大的提升（与基准桶的gap由0.3\%提升至1.67\%），同时，由于我们结合的是详情页满意度的模型，因此我们最终的融合模型在CTR方面不如原始的统计版CVR模型，但是融合的模型主要是通过提升ipv转化率达到最终转化率提升的效果，从对比效果中可以看出，融合模型在IPV转化率上相比原始的CVR 模型也有很大的提升。



模型融合需要解决的主要问题还是如何将我们使用UBM和UCM得到的有效信息应用到我们最终的预估模型中。传统的CVR预估模型中，在训练目标中使用pv作为负样本，点击与成交作为正样本，如前文描述中可以看出，由于日志中的pv和点击都是包含噪音数据的，这样自然会使得模型训练的目标本身就存在一定的偏差，而模型训练的目的实际上是无限的接近训练时的目标，但是如果目标本身存在偏差，那即使模型训练的再接近目标仍然无法达到最好的效果。在融合模型的过程中，我们实际上是使用前面两个模型的训练结果来作为最终预估模型的目标，这样做的好处在于通过消除目标中的有偏信息，修正模型的目标。提高模型训练优化能够达到的上界，使得预估模型的优化空间得到很好的提升。具体的融合方式如图所示:

\subsection{相关文章}
\begin{itemize}
\item Modeling dwell time to predict click-level satisfaction 	Youngho Kim,	Ahmed Hassan,Ryen W. White,Imed Zitouni   WSDM 2014
\item A user browsing model to predict search engine click data from past observations 	Georges E. Dupret,Benjamin Piwowarski  SIGIR 2008
\item BBM: Bayesian Browsing Model from Petabyte-scale Data Chao Liu,Fan Guo,Christos Faloutsos KDD 2009
\item A Dynamic Bayesian Network Click Model for Web Search Ranking  Olivier Chapelle，Ya Zhang
\end{itemize}



\section{商品网络效应分}
\subsection{背景}

什么是商品的网络效应？
\par 简单讲，就是利用商品间的网络关系来对商品的质量做出评价。
\par 长期以来搜索更多关注用户到query到商品到成交的整个转化效率，衍生出CTR、CVR、详情页满意度等方向的产品，取得了重大的突破。随着用户行为越来越丰富，特别在无线上，用户可以很方便的通过点击行为在多个产品间跳转，完成他的购物。我们所采用的数据应该不仅仅来自于搜索，也需要使用来自于全网的用户行为链路。目前庞大的用户群体正在编织起这张巨型的商品关系大网，如何应用好商品关系网络，用于商品质量的评判，是我们需要进行探索的课题。

	
\subsection{产品策略}
基于全网的用户行为数据，用户在一个session内的一次购物行为，通常都是先浏览一些商品，最终选定一个商品进行购买。从浏览商品到最终购买商品，其实说明了用户对最终购买的商品的满意度高于最初浏览的商品。这个过程形成了一次有方向的投票行为。众多的用户的购物便形成了众多的投票，彼此交织在一起，成为一个商品间的关系网络。
\par 另外，i2i这个名词，我们并不陌生。根据用户的共点击、共成交行为构建起了商品的i2i的网络。i2i网络的建立缘于用户在一个session内，他所共同点击的商品，共同成交的商品具有一定的共性。这个共性可以是价格，可以是品牌，可以是品质，可以是一个调性，总之用户认为他们具有一定的相似性。我们也利用了i2i的商品的相似性特点来对商品的关联网络进行了进一步的扩展，使之能对更多的商品的质量加以描述。
\par 最终，网络建立起来，采用合适的图模型算法来对各个商品的质量做收敛的计算，得出商品的网络效应分。
\par 商品网络效应分的建立，有效的在全网范围内对商品的质量做出了更好的描述。也使搜索排序和外部产品的连接变得更为紧密和敏感。对于搜索的长期外部性价值都有重要的远期影响。


\subsection{技术实现}
\subsubsection{商品网络关系构建}
\paragraph{基础置信边}
\begin{enumerate}
\item 投票：某用户在一个session内分别点击了A、B，且只购买了B，此次行为构成pairwise组合，这个行为我们可以理解为A商品以自己的价值给B商品做了一次背书，我们将其抽象为A商品给B商品的一次投票。
\item 基础边：基础边是能反映商品间投票关系的有向边。
\item 置信边：某基础边A-->B在一个月内出现两次或两次以上我们称其为置信边，如下图所示
\end{enumerate}

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/nns0.png"}
	\caption{}
	\label{fig:nns0}
\end{figure}

置信边真实反映了用户行为，众多置信边构成的网络我们称为基础置信网络。
\paragraph{构建过程}
按天统计基础边的uv作为计数（已过滤炒信行为。另外，一条边在一天内无论多少人经历过，都只算一个uv），按月统计基础边的计数作为能否称为置信边的凭证（一条边若想上升成为置信边，需要在一个月内至少有2个这个的uv）。在基础置信网络中，我们将所有置信边的权重统一设为1。

\subsubsection{i2i扩展边}
\begin{enumerate}
\item 淘系商品的价值体系是分等级的，且单个商品价值在体系中等级是稳定的。
\item i2i关系判定的相似商品在价值体系中处于相同等级。
\item i2i扩展边：存在置信边A-->B，若B与M是相似商品，则存在i2i扩展边A-->M；若A与N是相似商品，则存在i2i扩展边N-->B。
\end{enumerate}
基于上述假设，我们做一个大胆猜想：存在一种i2i扩展边，它同样能够反映商品间的投票关系。而这样一种投票关系需要我们通过i2i的关系去发现。

\subsection{构建过程}
扩展边的权重（置信度）是我们需要着重考虑的。一个节点（商品）可能会有多条i2i扩展边，那么分配权重的依据就是相似节点与置信边节点的相似度，如果两者相似度高则对应扩展边权重也高。第i个相似节点的扩展边权重计算公式为：Wi=Ri/SUM(R)
以一个例子来说明问题：
存在置信边A-->B（红色边），若B与M、N是相似商品，相似度分别为r1，r2，则存在i2i扩展边A-->M和A-->N（绿色边），那么A-->M边的权重w1=r1/(r1+r2)，A-->N边的权重w2=r2/(r1+r2)，
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/nns1.png"}
	\caption{}
	\label{fig:nns1}
\end{figure}

\subsection{虚拟边}
\begin{enumerate}
\item 虚拟节点：假设存在的具备一定价值的节点。
\item 虚拟边：由虚拟节点指向真实节点的有向边，虚拟节点唯一指向一个真实节点。
\end{enumerate}
在网络中如果我们希望把节点（商品）本身的特征分数引入，则可以借助虚拟边。一个真实节点（商品）本身特征分数越高则射向它的虚拟边越多。

\subsubsection{构建过程}
根据我们待引入的特征分来分布虚拟边，例如，当我们要引入人气分，A节点人气分为1，B节点人气分为3，则有1条虚拟边射向A，3条虚拟边射向B，如下图所示：
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/nns2.png"}
	\caption{}
	\label{fig:nns2}
\end{figure}

\subsubsection{构建过程网络迭代}
使用PAI平台的pagerank算法进行100次迭代至网络基本收敛，产出节点（商品）的PR分数。


\section{基于用户实时点击序列的表征学习}

\subsection{项目背景}

在电商搜索中，个性化一直是业务致力追求的目标，以期通过为每位消费者呈现更精准、多元、个性化的商品来满足不同客户的浏览和购买需求，努力追求提升用户体验、促进消费升级、改善商业生态的多方共赢局面。基于这样的目标我们已经挖掘出许多诸如User2Item、User2Shop、User2Brand等一系列的个性化数据标签，本质上都是在学习如何从Item、Shop、Brand等不同维度对用户进行准确的刻画或表征，以便在搜索或者推荐场景下能够为用户提供个性化的结果呈现。随着深度学习的不断发展，模型自身的表征能力得到了巨大提升；同时随着系统的不断改进，Wide \& Deep、Online Learning等机器学习方案不断落地；在现有的计算能力和模型基础上如何挖掘出新的信息进一步的完善系统，既是机遇也是挑战。

\par 我们从现有的系统框架出发，主搜系统召回、海选、精排的三级火箭模式，从一个角度看是通过分层的过滤机制将最核心的计算力尽可能预留给最具价值的商品集合，避免计算资源的浪费，毕竟绝大多数的商品在一次请求中都不会得到有效曝光；而从另一个角度看，三级火箭的模式也是性能和效果的权衡折中，总存在一些优秀的商品候选因上游计算力不足而错失最终展现的机会。现有系统经过长期的优化和技术升级，在精排阶段形成了深厚的技术沉淀并取得了瞩目的业务效果，而本文的工作则将更多精力放到了召回和海选阶段，尝试在系统的不同阶段、从另一个角度提升系统对用户的表征能力，在有限计算力的前提下为用户提供更完备的个性化服务。

\subsection{技术路线}

基于业界已有的研究成果和主搜自身的系统框架，我们延续了将用户和商品Embedding到潜层空间的表征学习思路，逐步建立了以用户和商品向量为基础，通过大规模图结构搜索技术实现的个性化召回、海选方案。该方案面临的挑战主要有如下两点：
\begin{enumerate}
\item 如何通过有限的向量操作准确刻画出用户与不同商品间的关联关系？
\par 受限的向量操作是为了满足对海量候选商品计算的性能需求，因此向量自身需要能够通过Cosine、Dot Prodcut等简单计算准确描绘出用户的行为偏好、即时兴趣与不同商品自然属性、历史销量等信息间的关联关系和关联程度。此外更值得考虑的是系统整体信息的有效增益，避免不同模型之间的相互覆盖，许多尝试都验证了对线上已覆盖信息做重复的刻画最终都难以实现业务指标的有效提升。
\item 如何在召回、海选阶段对大规模的商品候选集合进行高效地排序和筛选？
\par 受限于候选规模，召回和海选阶段使用大规模深层网络带来的密集计算会给引擎造成较大的系统延迟，所以传统方案往往采用少量静态指标的简单排序，导致在召回、海选阶段缺失了对用户即时行为和个性化信息的充分考量，暴露出不同用户的召回结果类似等问题。因为即便只是进行简单的向量内积，系统也不能对每个用户遍历全部的商品候选，如何通过近似计算和启发式算法实现大规模地个性化召回在许多业务场景下一直都是亟待突破的系统瓶颈。
\end{enumerate}
\par 本文更多的围绕第一个问题展开讨论，主要解决如何在受限的向量操作下通过表征学习实现对用户和商品关联关系的准确刻画，进而在个性化召回与海选阶段提供准确的度量标准，而基于大规模图结构的启发式搜索算法，参见[《基于辐射伸展图（Navigating Spreading-out Graph）近似最近邻检索算法》](https://www.atatech.org/articles/95738)。针对用户和商品的向量表示，我们参照信息互补的原则调研发现现有的模型更多的还是基于用户在主搜场景下的历史行为进行学习，如果可以更多的引入用户在全网其他场景的行为信息、同时强调对用户即时兴趣的刻画，应该会是对现有系统的一个有效补充。基于此，我们以用户全网的实时点击序列为基础利用深度学习对用户和商品的向量表示进行建模，寄期望于从用户行为的丰富性和即时性上对系统进行有效补充。

\subsection{用户行为}

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/seq0.png"}
	\caption{}
	\label{fig:seq0}
\end{figure}
上图是从训练样本中随机抽取的一条数据记录，可以看出用户在连续的点击商品间有着清晰的行为模式，在即时兴趣生效的范围内，用户所表现的价格、款式属性存在着相对稳定的个人倾向，而商品序列的颜色变化又体现了用户兴趣的短暂停留与演化迁移。用户的实时行为往往透漏着丰富的个人特征，却又难以用固定的指标进行准确的量化。

\subsection{模型结构}
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/seq1.png"}
	\caption{}
	\label{fig:seq1}
\end{figure}

模型上我们针对点击序列部分对比了Full Connection、LSTM、CNN、CNN with Attention等多种网络结构，其中全连接方案的效果最弱，LSTM稍弱于CNN方案，但起训练速度却远远落后于CNN，Attention部分我们基于Item向量进行Self-Attention处理，再接入CNN网络，不过实验发现提升并不明显，最终线上采用了效果和性能比较理想的CNN方案，具体实现主要参考了Facebook的《Convolutional Sequence to Sequence Learning》。CNN方案除了利用卷积核可以在不同商品向量间实现跨区块的交叉学习以外，通过Linear Gated Unit的开关控制，还能有效降低用户点击序列中的噪声信息，同时彼此独立的卷积操作天然支持并行化的数据处理。当然我们也对比了不同的激活函数、优化方法及正则化手段，目前深度学习模型依然需要针对特定的场景做大量的参数调优工作，这里不做赘述，不过整体上网络结构和与特征工程对模型最终的效果起着决定性的作用；

\par 受限于召回、海选阶段的计算性能，模型结构上用户和商品的向量只进行了一层内积操作，同时为了控制特征分的值域范围，用户和商品网络结构最后一层的激活函数从ReLU替换为Tanh。在特征层面，除了用户的点击序列外，还包括了浏览、加购、收藏等历史统计信息，点击序列在经过卷积层和Linear Gated Unit处理后和统计信息拼接到一起再接入后续的全连接层。


\subsection{目标函数}

主搜系统的优化目标除了大盘的GMV外，还希望提高用户品质，尤其对部分高价优质的商品希望可以得到更多的曝光展现，因此在目标函数的选择上，我们以交叉熵损失为基础，为不同商品引入了价格因子： 

$$Loss = - \frac{1}{N} \sum\limits_{i=1}^{N} { price_{i}^{\alpha} \left[ y_i\log{p_i} + (1 - y_i)\log{(1-p_i)} \right] }$$

同时在模型评估指标上，我们希望高价优质的商品排序能够更靠前，所以在标准AUC的基础上也融入了商品的价格因素，其中 $m_{i}$指排名低于正样本`i`的负样本个数，$K$是负样本的总个数，对于分数相等的情况也和标准AUC类似需要对价格权重做折半处理，本质就是希望打破原来所有正样本权重相同的情况。

$$Metric_{price} = \frac{\sum_{i \in positive} {m_{i} * price_{i}}}{K * \sum_{j \in positive} {price_{j}}}$$


\par 整体而言，对于主搜现有业务的优化，如何构建目标函数以及使用怎样的度量指标进行离线评估并不是件容易的事情。一来我们要解决的不再是基于点击率、转化率、笔单价等任何单一指标的排序问题，甚至很难落脚到由哪个单一指标主导、或几个指标分批次优化，而是需要同时结合成交额、货单价、人群分层等多个指标联合求解，这就导致模型很难按照某个单一的目标函数进行优化求解；二来现有的线上系统包含了一系列独立的模型，任何一个新增的特征或一批候选宝贝的替换，最终效果都是线上全体模型的复合输出，因此诸如AUC等单一离线评估指标很可能出现线上线下的效果不一致，即便我们对原始排序做了针对性的调权，依然碰到离线评估良好的模型上线不凑效的情况。因此，在问题切入、数据选择、目标构建阶段我们要做的就是方向上保证模型求解的目标与我们的愿景尽可能一致，而后便是冗长的尝试与调参工作。

\subsection{线上流程}
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/seq2.png"}
	\caption{}
	\label{fig:seq2}
\end{figure}

上线时依托Porsche的实时数据流，模型对用户在全网范围内的每次点击进行实时更新，通过IGraph实时反映到用户下一次的搜索结果中，而对于商品向量则是每天进行预测，按天Build到索引中。召回和海选时，基于实时的用户向量在商品构成的相似图谱中进行启发式搜索，召回用户感兴趣的商品集合。值得一提的是，在召回阶段，我们在商品和用户向量内积的基础上又补充了价格指数 $price_{i}^{\beta}$ ，超参 $\beta$ 负责在转化率与货单价之间斡旋，间接寻求一个较为理想的成交金额和货单价。

\par 不过用户的点击序列也会包含一些噪声或不适当的行为模式，比如观察用户的实时点击会发现，部分场景下用户会对同一个商品进行连续性的点击，如用户从搜索页点击进入详情页，再点击进行加购、收藏等行为，这会在有限长度的点击序列中连续多次出现相同的商品。少量的重复会强化用户某一部分的即时兴趣，但过多的相同商品也会挤压点击序列的有效存储空间，使得用户特征变得单一，不利于对用户后续行为的预测。针对该问题，一方面可以适当的延长点击序列，另一方面也可以对点击商品做适当的去重处理。


\section{商品簇模型} 

整个淘宝平台有数十亿的商品，商品与商品之间的推荐关系和用户与用户之间的关系都是非常稀疏的，而且这些关系不管是在离线模型训练还是在线预测偏好，考虑到性能和存储空间的问题，都是要做阶段的，所以对于商品的聚类，压缩到一个比较小的空间上，还是比较有必要的。对于如此大规模商品进行聚类有很高的性能要求，本节将介绍一下如何通过启发式的方法寻找商品簇中心，从而快速的对商品进行聚类，有点类似于[7]。我们用这个启发式的算法最后聚出来的商品簇在一定程度上满足两个特性，商品簇内的商品要足够相似，并且商品簇与商品簇之间的商品要有足够的区分度。

\subsection{商品与商品之间的相似性计算}
所谓的商品聚类，就是将相似的商品聚合在同一个商品簇中，而且簇与簇之间还要有保证一定的距离。所以商品与商品之间的相似关系的计算对于商品聚类是非常重要的。淘宝上商品之间的相似度分数计算一般是根据用户点击购买收藏等行为计算出来的，两个商品之间相似分数越高代表着两个商品越相似，具体如何计算会在下面的章节进行介绍，本节主要介绍如何用给定商品与商品之间的相似数据给商品聚类。

\subsection{相似商品数据预处理}
在同一个商品簇内的所有商品之间需要都需要保证有一定的相似性，所以我们首先需要构造出一个商品与商品之间的Graph结构数据，如果商品与商品之间有边相连接，那么认为这两个商品是相似的，否则就是不相似的。而且这些商品与商品之间的边需要满足下面两个特性。
\begin{enumerate}
\item 商品与商品之间的边是无向边的：如果商品a能够推荐出b，那么b也能够推荐出a。 
\item 商品与与商品之间的边石可以传递的：如果a与b是相似的，并且b和C也是相似的，那么a和C也是相似的。 
\end{enumerate}
根据上面两个特性，我们对商品的相似数据进行一些预处理。处理后保留下来的商品与商品的关系，能够在一定程度上满足上面两个特性就可以了。
\begin{enumerate}
\item 对于每一个商品a，保留top K个最相似的商品。
\item 对于每一个商品a，假设商品b在a的top k个相似商品之中，如果a也在b的top k个相似商品中，那么保留a和b之间的边，否则将a和b之间的边去掉。
\item 在第二步之后，对于每条边ab，统计商品a和商品b的共同邻居的个数，如果商品a和商品b的共同邻居个数大于等于一定的个数M，那么保留这条边，否则去掉这条边。
\end{enumerate}

\subsection{商品聚类过程}
在对相似商品数据进行与处理之后，得到一个比较高置信度的商品与商品之间的图关系数据，那么就可以根据这个图来对商品进行聚类了。我们聚类的基本思想是，首先从这个图中启发式的找出最靠谱的簇中心，然后其他商品根据与哪个簇中心相连接，并且权重最高，决定属于哪个簇。

商品簇的中心需要满足这两个条件，1. 商品簇中心必须与商品簇内所有其他商品都相似。2. 簇中心与簇中心必须是不相似的。根据这两个条件，我们制定了两个快速决定簇中心的两个策略：1. 簇中心的度越大越好；2. 簇中心之间不能有边相连接。具体寻找簇中心有下面几个步骤

\begin{enumerate}
\item 根据前面构造的图数据，统计每一个商品的度，也就是这个商品对应边度条数。
\item 根据度从高到低的顺序遍历所有的商品
\begin{enumerate}
\item 如果该商品的所有相似商品都不是簇中心，那么将该商品设为簇中心, 否则就不将这个商品设为簇中心。
\end{enumerate}
\end{enumerate}

在根据启发式方法找出所有的簇中心之后，就要对所有的其他非簇中心的商品进行处理了，决定每一个商品归属于哪个商品簇。
\begin{enumerate}
\item 根据商品与所有簇中心商品是否有连接的边，来决定归属哪个簇中心。
\item 由于数据做了很多截断，有些商品不一定和簇中心有直接。所以在上一步的基础上，用knn算法，看该商品的相似商品中属于哪个簇的相似商品最多。
\item 如果还归属不到任何一个簇的话，拿就不对这个商品进行聚类了，属于比较冷门的商品，没有与其他的商品比较相似，不能归属于任何一个簇。
\end{enumerate}

整个聚类过程基本上都是对商品与商品之间的关系进行统计，排序，截断等操作，特别适合于利用mapreduce进行大规模数据处理，能够快速的对大规模商品进行聚类。
 
根据前面的数据处理后，平均每一个商品簇能够有差不多100个商品左右，而且每个簇的商品个数比较平均，不会有特别大。将商品簇数据利用于搜索，原本推荐出商品，现在可以推荐出商品簇，极大的扩大了推荐的覆盖率而且也没有耗费很大的存储空间和计算性能。也可以根据商品簇来计算商品簇与商品之间的关系，扩大推荐的范围，大大的提高推荐召回率。

\section{实时计算}
相比传统的网页搜索引擎，淘宝搜索由于以下几个原因对实时性的要求非常高：

首先，众所周知，淘宝具有很强的动态性，宝贝的循环搁置，新卖家加入，卖家新商品的推出，价格的调整，标题的更新，旧商品的下架，换季商品的促销，宝贝图片的更新，销量的变化，卖家等级的提升，等等，都需要搜索引擎在第一时间捕捉到这些变化，并在最终的排序环节，把这些变化及时地融入匹配和排序，带来结果的动态调整。

其次，从2013年起，淘宝搜索就进入千人千面的个性化时代，搜索框背后的查询逻辑，已经从基于原始Query演变为【Query+用户上下文+地域+时间】，搜索不仅仅是一个简单根据输入而返回内容的不聪明的“机器”，而是一个能够自动理解、甚至提前猜测用户意图（比如用户浏览了一些女士牛仔裤商品，然后进入搜索输入查询词“衬衫”，系统分析用户当前的意图是找女性相关的商品，所以会展现更多的女士衬衫，而不是男生衬衫），并能将这种意图准确地体现在返回结果中的聪明系统，这个系统在面对不同的用户输入相同的查询词时，能够根据用户的差异，展现用户最希望看到的结果。变化是时刻发生的，商品在变化，用户个体在变化，群体、环境在变化。在搜索的个性化体系中合理地捕捉变化，正是实时个性化要去解决的课题。

最后，电商平台也完成了从PC时代到移动时代的转变，随着移动时代的到来，人机交互的便捷、碎片化使用的普遍性、业务切换的串行化，要求我们的系统能够对变化莫测的用户行为以及瞬息万变的外部环境进行完整的建模。

\section{在线学习系统架构}
早先的搜索学习能力，主要是基于批处理的离线机器学习。每天离线训练模型，然后将训练得到的模型推送到线上系统做打分预测，线上预测阶段模型不会变化。这种离线模型+在线预测也是工业界常用的模式，但如上节说过，淘宝搜索因为其自身的特征，这种模式有很大弊端。在离线批量学习中，一般会假设样本独立服从一个未知的分布，但如果分布变化，模型效果会明显降低。而在淘宝搜索业务中，很多情况下，一个模型生效后，样本的分布会发生大幅变化，因此离线学到的模型已经不能很好地匹配线上数据了。所以需要通过在线学习，不断地实时调整模型，拟合最新的线上数据，特别是在大促这种数据分布变化很大的场景下。

为了满足在线学习的需求，搜索技术团队自主开发了基于parameter server的在线学习框架，如下图所示，目前已经实现了FTRL，矩阵分解，深度学习等多种在线学习模型，模型更新后会实时推送到线上打分引擎。

	
\section{在线FTRL}
本小节以FTRL为例，说明在线学习的简单应用。其他在线学习的模型，可以再个性化等章节找到。

逻辑斯蒂回归（LogisticRegrssion）应该是工业界最经常使用的一个模型，能处理超大规模的样本量和特征量。为了防止学习算法过拟合（overfitting），通常会在算法中加入正则项（regularization）。在逻辑斯蒂回归模型中，优化目标一般如下式：

上式中的第一项是模型loss，第二项为正则项。最常见的正则是使用L2-norm，这是由于L2-norm是smooth and strong convex，导数比较好计算。另外一种常见的是L1-norm，相对L2-norm，L1-norm产生的解容易落在坐标轴上，落在坐标轴也就意味着对应的w为0，从而得到稀疏解。L1-norm的好处在于可以使模型得到更多的稀疏解。稀疏解不仅能提升模型的泛化能力，而且在线部署阶段也能节省模型存储空间。

但传统的在线优化算法，比如随机梯度下降（SGD），并不能有效得到稀疏解。如何onlinelearning得到稀疏解也是一个研究的课题。

\subsection{Truncated Gradient}
为了得到稀疏解，最简单粗暴的方式就是设定一个阈值，当权重小于这个阈值时将其设置为0，如下面的伪代码。这种方法实现起来很简单，也容易理解。但实际中应用中，简单进行截断会造成这部分特征的丢失。
上述的截断法太过简单粗暴，因此TG在此基础上进行了改进，如下：
其中𝜆(𝑡)∈ℝ且𝜆(𝑡)≥0。TG同样是以𝑘为窗口，每𝑘步进行一次截断。当𝑡/𝑘不为整数时𝜆(𝑡)=0，当𝑡/𝑘为整数时𝜆(𝑡)=𝑘𝜆。从公式(3-1-3)可以看出，𝜆和𝜃决定了𝑊的稀疏程度，这两个值越大，则稀疏性越强。尤其令𝜆=𝜃时，只需要通过调节一个参数就能控制稀疏性。

\subsection{FOBOS}
先前向后切分（FOBOS，Forward-Backward Splitting）是由John Duchi 和Yoram Singer提出，在FOBOS中，将权重的更新分为两个步骤：
前一个步骤就是一个标准的梯度下降过程，后一步是对前一步下降的结果进行微调。观察第二个步骤发现对W的微调也分两部分，第一部分保证微调不要偏离第一步找到的梯度下降方向太远，第二部分则用于处理正则化，产生稀疏解。

\subsection{RDA}
前面提到的TG、FOBOS都还是建立在SGD的基础上，属于梯度下降类型的方法，这类型方法的优点就是精度比较高，并且TG和FOBOS也都能产生稀疏解。正则对偶平均（RDA，Regularized Dual Average）是从另一个方面来求解Online Optimization。RDA算法中优化的是前T轮所有loss的平均，可以达到平均效果较好。

\subsection{FTRL: Follow The Regularized Leader}
FTRL是google McMahan提出的算法，它综合考虑了FOBOS和RDA的优点，兼具FOBOS的精确性和RDA优良的稀疏性，其特征权重更新公式为：

该优化公式分为3部分，第一部分表示累计梯度和，就是让损失函数下降的方向；第二部分是表示新的迭代结果不要偏离已经产生的迭代结果太远；第三部分是正则项，有用于产生低遗憾的强凸二范数和产生稀疏解的一范数。另外值得一提的是FTRL采用针对每个特征不同的自适配的学习速率，直观的解释是如果特征出现的次数多，对这个这个特征的权重比较置信，学习速率就比较小，对于很少出现的特征学习速率就比较大。


\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{\protect\numberline{}{\hspace{-1.5em}参考文献}}
\markboth{参考文献}{参考文献}
\bibitem{1} C. Burges, T. Shaked, etc.., Learning to rank 
using gradient descent. In Proceedings of the 22nd international 
conference on machine learning, ACM
\bibitem{2} 流量个性化v.s商业化 - 双11珠峰项目中控算法, http://www.atatech.org/articles/67132
\bibitem{3} 确定性保证下流量分配在线全局优化策略, http://www.atatech.org/articles/55983
\bibitem{4} 搜索流量确定性项目总结, http://www.atatech.org/articles/59651
\bibitem{5} 网络效应分介绍, https://www.atatech.org/articles/52962
\bibitem{6} Unbiased Learning-to-Rank with Biased Feedback, http://weibo.com/ttarticle/p/show?id=2309404077533346815648
\bibitem{7} A. Rodriguez and A. Laio, “Clustering by fast search and find of density peaks”, Science, Vol.344, No.6191, pp.1492–1496, 2014.

\end{thebibliography}

 
