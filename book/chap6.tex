
\chapter{搜索与商业}
\thispagestyle{empty}

\setlength{\fboxrule}{0pt}\setlength{\fboxsep}{0cm}
\noindent\shadowbox{
\begin{tcolorbox}[arc=0mm,colback=lightblue,colframe=darkblue,title=学习目标与要求]
%\kai\textcolor{darkblue}{1.~~带约束优化问题} \\ 

\end{tcolorbox}}
\setlength{\fboxrule}{1pt}\setlength{\fboxsep}{4pt} 

\section{搜索与淘宝} 
在淘宝的环境讲到商业化，一般都会指对卖家进行收费的广告部门的业务，卖家通过付费获取额外的流量。搜索和推荐作为巨大的免费流量的入口，任何一个策略的变动都会极大的影响到卖家的生存，很合理去帮助淘宝实现自身的商业的诉求，同时也可以通过流量来影响到卖家，往我们期望的方向发展。除CPC，CPM这类的收费模式以外，如何帮助卖家更好的在淘宝经营，例如：如何备货，如何优化卖家的供应链，如何定价，怎么管理商品的生命周期等。是我们需要长期研究的话题，我们从16年初开始流量确定性的项目，尝试帮助卖家来更好的在淘宝经营。这个方向我们不称其为商业化，而称之为商业赋能。
\newline 本章包括商业赋能的几个方向，以下逐个介绍
\begin{itemize}
\item 流量确定性-珠峰项目
\item 供应链优化-Manhantten项目
\item 冷启动-第五大道项目
\item 机制设计-RL分层流量调控项目
\item 其他玩法，红包等
\end{itemize}

\section{流量确定性-珠峰项目}
长久以来，淘宝都是一个自由竞争的市场经济的环境，和真实的世界很像，他是一个小社会，也是一个巨大的经济体。它存在并遵守一定的社会经济学规律。做个也许不太合适的类比，自由民主引导了前几十年整个人类发展，在欣欣向荣的时候，一切都向好，自由竞争带来了发展，带来了进步。而近几年整个世界局势的转变，我们看到的是中国的崛起与美国社会的撕裂。有好多人开始怀疑自由民主。同样的在淘宝我们也看到纯自由竞争带来的问题，自由竞争并不常常往最好的方向发展，有买家为了获取更多的利益，通过低价爆款来进行竞争，曾经也有过劣币驱逐良币的苗头。我们也看到其中的要照顾到所有人的低效。在这样的大环境中，我们过去做了很多，如提升客单价来达到品质升级。我们一直找自由竞争与宏观调控的平衡，并且希望把它系统化。这样就具体到珠峰这个项目，我们一直在追求个性化与确定性上的平衡，或者说自由市场经济与计划经济的平衡点。
\newline 商业模式的本质是各利益相关方获得公平可预期的确定性，以推动商业活动的持续。尤其电商的运营，需要以一定的确定性为前提，商家才能有计划的开展商品生产、市场和运营等工作。对于大淘系平台来说，随着全站个性化的不断深入，消费者端的效率持续提升，但问题是在个性化的世界里并没有商家的目标，商家也不知道从何努力，商家的参与度在持续下降。更颠覆的问题是，作为平台方，今天不是我们渠道的效率最大化就可以成就平台的，供给驱动消费，需要商家进来，大家都All in才能成就平台。
\newline 珠峰项目是在自由市场经济中，加入了科学的计划经济的宏观调控。将各种渠道资源进行整合，并提供对触达用户进行提前预估和宏观调控的能力，最终实现商家的商业确定性和全渠道的整体效率最优。它分为几个部分，科学的计划，高效的执行，多方的参与。

珠峰项目的核心逻辑是，
\begin{itemize}
\item 平台给到商家确定性，商家给到消费者优质商品。
\item 通过给到卖家连续时间的确定性，来优化整个供应链。
\end{itemize}
这里的确定性，来自对整个淘宝流量的调节与分配。通过最前端的流量的优化，来驱动后端的升级。

\subsection{宏观计划}
对未来的预估，精确的计划

每年的双11，消费者看来是愉快的购物的节日，在卖家眼里，确是一个极大的挑战。备货的风险是极大的，如果备货了，卖不掉，轻则是双11之后大量的库存需要销掉，重则是资金链存在问题，有倾家荡产的可能，所以每次1111对卖家都是生死的考验。且不说每个卖家从自己单点，看不到整个行业的趋势，无法做一个准确的预判，即使有了一个比较准确的预期，也不能保证中间不会出任何的差错。
我们需要一个极为准确的销量预测，除了需要知道预测结果，我们同时还需要知道预测误差率，所以在常规的xgboost，DNN等，还对GPR进行了研究。
\begin{itemize}
\item GMV 预估：https://www.atatech.org/articles/94517
\item 销量预测：https://www.atatech.org/articles/94520
\newline 和选品，

\item 主推款：https://www.atatech.org/articles/94518
\end{itemize}

通过这样的预测，我们可以做到的是，供应链的优化，商家预期的管理。有良好的预期，今年1111珠峰共计BD货值783亿，整体备货货值同比去年提升75\%。同时在双11预热期，卖家提前进行了补货，建立起相互的信任，也为以后的合作打下良好的基础。

\subsection{立体调控}
\begin{itemize}
\item 从一维到高维，效率的最优
\end{itemize}

对于大淘系平台来说，平台有着大量的触达用户渠道，如搜索、推荐、营销、会场、PUSH等。这些渠道相对独立，在算法目标上，每个渠道都分别在优化自己的流量，保持着各自效率的最大化、展现内容的多样性。但是，在这些渠道构成的整体平台之上，并没有一个通盘的系统的解决方案做全局的最优。所以需要有一个大淘系的流量中控来整体统筹所有流量渠道，实时分析各自渠道用户的差异性，将合适的商家优先在合适的渠道做调控，渠道间做流量的腾挪，实现全局效率的最优。

从技术层面上讲，效率的优化到卖家是远远不够的，很快就到了优化的瓶颈，这也是之前珠峰1.0及珠峰2.0的瓶颈所在，所以在调控上，向下扩展到了商品粒度，向上扩展到了商品分层的粒度。
通俗的解释，熟悉三体的同学都应该知道，一维的生物，他的世界里面很难看清也很难找到其他维度的通路，怎么分配也达不到一个更优的效果，但如果我们扩到更高的维度，对于一维的生物来说，就打开了一个虫洞，可以直接连接不同的效率最优的点。跨越维度的调控带来了30\%以上的效率提升。
\begin{itemize}
\item Hierarchical中控系统：https://www.atatech.org/articles/94707
\item 其中使用的带约束连续空间优化算法：https://www.atatech.org/articles/89894
\end{itemize}

从单侧到双侧，卖家也需要努力

去年的情况，卖家商品效率存在问题时，卖家并不知道该做什么可以提升了。只能躺着数钱，我们不断的给他补流量，但卖家并不需要再付出。这样是极其低效的。卖家其实很乐于知道哪里不好，并一起来优化。今年的珠峰3.0我们开了一个头，让卖家可以判断，什么时候该发优惠券，会有多少的收益。预期之后会有更多手段，让卖家努力来自我提升。
\begin{itemize}
\item 店铺购物券效果预估：https://www.atatech.org/articles/94770
\end{itemize}

从单侧到双侧，行业运营赋能

运营也一直很困扰，每个行业，需要往高品质，新品方向发展，年初做了很宏大的规划，但在执行的时候，发现根本没法落地，因为过去的选品，加权，加坑位等，方法间接，且存在不同纬度间各种各样的矛盾，当多个维度都需要的时候（既要又要的时候），常常无能为力，必须是更有效的算法来解决流量的问题。
同时，我们又是一个动态变化的环境，静态的Plan算法，是没办法最优化的应对，我们在其中的一些部分，升级到了RL，直接优化结果，动态的求最优解。
\begin{itemize}
\item 尝试引入强化学习来解决分层次流量调控：https://www.atatech.org/articles/94327
\end{itemize}


\section{销量预测}


\subsection{业务简介}

销量预测是现代电子商务行为中控制缺货和滞销风险、控制供应链成本的重要手段，同时也是商家制定销售计划的重要参考。但是由于市场行为具有很大不确定性。从纵向看来，销量预测可以分为市场整体销量预测、行业整体销量预测、商家整体销量预测、商品粒度销量预测和SKU粒度商品销量预测，粒度越细，销量预测的难度也越高；从横向看来，商品的销量行为在不同行业，不同季节，不同年份，大促与日常之间都有可能发生较大变化，其中时间间隔越长销量越难预估，行业内商品越杂乱销量越难预估，大促商品销量受促销活动影响较之日常也更难预估。因此销量预测精确度有限，提高销量预测的准确率具有很大挑战性。

2017年双11期间，珠峰项目和智能商业化项目提出了卖家GMV预估和商品粒度销量预测的要求，卖家双11的销量预估问题是一个基础但是相当重要的环节，其在指导卖家指定销售计划以及资源配置等方面具有较高的参考价值，主要包括双11准备前期珠峰卖家GMV目标的预估，预热期珠峰卖家GMV预估以及提供珠峰预热期加购目标的工作；商品粒度销量预测商品粒度的大促销量预测此前还未有相关的尝试，商品粒度销量预估可以给出符合商品自然行为的销量目标提供给珠峰中控，同时可以预计缺货风险提供给供应链平台并提前通知卖家备货，主要包括主推款预测和商品销量预估两部分工作。

由于销量预测对接的业务较多，珠峰、供应链等平台都需要销量预测产出的数据，综合不同业务需求后我们设计了如下的技术路线。主体思想是将销量预测过程按照临近双11的时间分解为四个阶段，分别是选品阶段、准备阶段、预热期、双11，其中选品阶段与准备阶段指预热期之前。首先预测主推款的商品集合，然后再预测主推款商品的销量，并在预热期之前提供给行业指导商家备货。遴选主推款使得商家可以提前预知爆款商品，对指导商家备货有较大意义，在选定的主推款集合上进行销量预测确保了样本分布的一致性，使得销量预测模型不致于受低质量商品影响。 预热期时珠峰流量调控发挥巨大作用，我们根据销量预测的结果为商品分配了合理的加购目标，使得珠峰商家在趋近自然销量的情况下完成整体目标，有利于提高珠峰效率。双11当天我们将销量预测目标转化成为销售额目标，并进行小时级实时销量预测, 为双11当天整体目标完成情况提供参考，并为珠峰提供合适的销售额目标。


\begin{figure}[!h]
	\centering
	\includegraphics[width=0.8\linewidth]{"fig/salesforecast6.png"}
	\caption{销量预测整体框图}
	\label{fig:sf6}
\end{figure}

其中部分指标如下
\begin{itemize}
\item 小时级预测在11.11当天中午12:00时预测精度（1-MAE）达到90\%以上
\item 双11销量预测在准备阶段完成时预测精度(1-MAE）达到50\%~80\%
\item 主推款预测在准备阶段完成时命中率达到80\%以上
\item 服饰主推款缺货影响成交占比下降了4.6\%，相当于增加GMV约**18.9亿**
\item 卖家GMV预测误差在5\%以内，并提供给行业参考最终确定双11成交金额目标
\item 卖家GMV总体预测分业务组合模型11.08日总误差达在0.4\%以内
\end{itemize}
这里MAE（mean absolute error）指的是如下的误差衡量指标

$$MAE=\frac{\sum{|y-\hat{y}|}}{\sum{y}}$$

$y, \hat{y}$分别为真实销量和预测值，在样本固定时，$\sum{y}$是固定的常量。

\subsection{特征工程}
卖家GMV预测采用层次化结构进行特征处理与问题定义。将卖家第$t_k$年在淘宝的店铺经营用树状结构进行层次化描述，其中树的根节点$M_{n}$表示卖家$n$店铺维度的属性（包括开店时间、卖家星级、DSR、大促/日常相关总成交金额等卖家维度属性），叶子节点$G_{j}$为卖家在$P_k|M_n \rightarrow G_{j}$路径下的属性节点，其中$j \in S_{category}$。具体的说，若将路径实例化为类目结构，则$G_{j}$即为卖家$n$在叶子类目$j$上的属性节点，包括成交金额、同比/环比增长率、类目排名等卖家在叶子类目维度的相关信息以及叶子类目自身在大盘上的相关属性信息。$P_k$为从根节点到叶子节点的路径，描述淘宝卖家在淘系类目中的经营分布（例如卖家可能在男鞋、女鞋等多个类目下经营），$i=p(j)$表示节点$i$为节点$j$的父节点（上一层结构），$s_{j}$为卖家在叶子类目上的GMV金额，是节点$G_{j}$的属性之一，故整个结构可以如下所示：

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/salesforecast0.png"}
	\caption{}
	\label{fig:sf0}
\end{figure}

其中，$T_{n,t_k}$表示卖家$n$在$t_k$时间的大盘成交结构树。将结构树沿着时间轴横向展开记得到不同时间上的结构树，描述卖家在不同时间段下的经营情况。于是卖家总GMV预测的问题便拆解为基于卖家当前以及历史相关信息预测未来卖家各叶子类目上金额$s_{n,t_{k},j}$预测的问题，

\begin{align}
s_{n,t_k} &= \sum_{j \in S_c}s_{n,t_k,j} \\
&= \sum_{j \in S_c}f(G_{n,t_{k-1}},...,G_{n,t_1})
\end{align}

在时序结构树中，同一颗树中的子节点的GMV属性值受到父节点以及更上层相关属性的影响，即细维度节点销量属性的值除了该维度本身的相关特征之外还受到其父节点中相关聚和信息的影响，即$G_{n,t_{k},j} \sim G_{n,t_{k},p(j)}$。 相关聚合信息可以采用简单的统计的方式得到也可以基于深度学习的Embedding方式获取到，从而在父节点下的各个子节点之间共享。将时序特征引入到结构中后，每个节点除了依赖其父节点信息外，还受到在时序结构中前序结构树中所有节点属性的影响，即$G_{n,t_{k},j} \sim G_{n,t_{k-1}}$，$T_{n,t_k}$中的节点受到$T_{n,t\le t_{k-1}}$中节点的影响。在预测模型中，$f$为基于节点特征信息的相关回归算法，例如Lasso，XGB，DNN等回归算法，或者是各类算法的assemble。

商品销量预测通过数据分析挖掘对销量影响较大的特征。通过数据分析发现，预热期前表现越好的商品就越容易成为主推款；增长率越大的商品也越容易成为主推款；同时不同卖家、类目、品牌下的商品成为主推款的概率会有很大区别。根据数据规律重点处理了以下类型特征。
* 绝对值排名特征：分别统计每个商品在所属卖家、品牌、一级类目、叶子类目、以及卖家+品牌、卖家+类目、品牌+类目等各种不同维度下的点击、成交、加购、收藏等绝对值信息，并且根据绝对值信息在这些维度下进行排名，特别的，对排名邻近的商品之间的特征进行了高斯卷积处理。
* 增长率特征：分别统计每个商品在所属卖家、品牌、一级类目、叶子类目、以及卖家+品牌、卖家+类目、品牌+类目等各种不同维度下的点击、成交、加购、收藏等绝对值信息，按天或者周计算出环比增长率特征。
* 增长率排名特征：根据上面抽取的增长率特征，再在不同维度下进行排名，并进行高斯卷积处理。
* ID类特征：由于不同维度下的商品数量差异较大，因此只提取商品数量较多的维度的ID，统一进行one-hot编码，保留成有统计意义的特征。

商品、类目、店铺、品牌、销量、加购、IPV、PV、 UV等数据的绝对值作为特征相当于细分特征空间拟合样本，如果只使用这类绝对值特征而不进行特征组合可能很难训练出大促期间销量爆发的本质规律。同时，这类特征2015年，2016年和2017年间数据分布已经发生较大变化，使用绝对值作为特征并不适合。我们分析了部分商品在双11期间的爆发系数与其排名的关系，发现商品历年爆发系数与其所处的排名存在极大关系。商品之间的销量、点击、加购等特征的竞争排位很大程度上反映了商品在其所处行业、叶子类目、一级类目以及店铺等维度下的表现情况，可以反映出大促期间商品的爆发情况，因此我们提出依据商品的各类特征在不同维度下的排名信息组合出新的特征——同位次商品爆发系数，并使用高斯卷积核对同位次商品爆发系数进行了处理
$$f_i=\frac{\sum^{m}_{t=0}{k_te^{\frac{-(t-i)^2}{2\sigma^2}}}}{\sum^{m}_{t=0}{e^{\frac{-(t-i)^2}{2\sigma^2}}}} $$
其中$f_i$表示排名$i$的最终爆发系数，$k_t$是排名$t$的商品原始爆发系数，$\sigma$为预定义的窗口大小，$m$为该维度下商品的数量，该式表明某一个位次下的商品的爆发系数可能与其邻近排位的商品的爆发系数相关，排位越紧邻爆发系数之间的影响就越强烈。同时环比、占比、同比等特征也在模型中进行了尝试，通过逐个增减特征并进行A/B Test遴选出对提高指标有效的特征。

市场自然增长使得2016年相比于2015年整体销售额增加了30\%, 2017年整体销售额相比于16年增加了近30\%(2015年，2016年，2017年双11销售额分别为900亿，1200亿，1600亿)，样本空间发生了很大偏置。直接使用销量的绝对值作为目标进行训练，将会使得模型拟合历史销量信息而导致预测值偏低。因此我们提出使用爆发系数(双十一期间销量相对于历史平均销量的比值)作为label来避免样本空间迁移带来的影响，预测商品在大促期间可能的爆发系数。考虑到大促期间在预热期之前、预热期、双十一当天商品的行为有很大差异，其中商品的加购行为在预热期尤其明显，而预售类商品从预售期开始就只接受订金直到双11当天才可成交，因此我们特别的定义爆发系数在不同的情景下为， 预热期之前:双十一销量相对于历史平均销量的比值；预热期： 双十一销量相对于预热期平均加购笔数的比值，双十一当天：历史双十一当天的总销量比上当前时刻的销量；预售类商品：双十一销量相对订金预计引导销量的比值。

\subsection{卖家GMV预测之参数化模型}

考虑到项目初期时间、资源、超结构模型求解的复杂性以及模型的可解释性等问题，在今年双11的预测问题中，我们采用了一个参数化的模型。

假设卖家$ i$在叶子类目$c$下的双11成交金额$s_{c,i}$可拆解为基准值$ \nu$与增长率$\alpha$两部分。其中，时序相关的信息采用特征的同比、环比等相关特征描述，将不同时序上的特征压缩到同一层次的单个节点中，并将不同层次的节点属性压缩到统一层次，其中子节点与其聚合父节点的相关特征采用attention相关机制描述，虽然模型的泛化能力衰减很多，但是问题得到简化。于是单卖家的GMV预测模型可以由如下所示的参数化模型近似表示：

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/salesforecast7.png"}
	\caption{}
	\label{fig:sf7}
\end{figure}

模型底层输入为卖家、叶子类目、行业相关特征，沿着模型自下而上得到卖家在某个叶子类目上的GMV预估值。其中，紫色部分为卖家以及卖家与在叶子类目下的相关特征，黄色部分为叶子类目相关特征，蓝色部分为一级类目、行业相关特征。图中左半部分为模型基准值部分，描述卖家去年双11的GMV情况，其除了取决于卖家历年双11的成交GMV，活动日、平常日等成交GMV等卖家自身的经营情况之外，还受到该类目以及该行业的平均经营水平等。

此外，由于卖家在不同叶子类目下的经营有偏重。例如，有些大卖家可能只在个别几个类目上重点经营，在其余类目下鲜有经营，若统一采用类目均值则可能带来系统性的偏高。于是我们采用简单的线性网络结合激活函数的方式拟合其在该叶子类目或一级类目下的占比情况，以便修正类目均值带来的偏移。换一个角度，考虑到卖家每年的经营分布不同，在卖家历史主营类目下需要侧重使用卖家在该叶子类目下的信息；反之，在卖家信息缺失的情况下（例如，卖家今年首次在该类目中经营），更倾向于使用一级类目以及行业相关信息去估计。因此，我们采用一个attention网络估计其不同的权重。图中右半部分为卖家双11的成交相对于基准值的增长率，其取决于卖家在该类目下同比去年同期的活动日增量、平常日增量、月增量、年增量等相关特征以及该类目/行业的历年增长情况等。类似的，我们也通过attention网络确定不同的权重占比。

基于特征以及参数化模型，求解如下优化问题得到预估模型：

\begin{align}
min \quad L &= \sum_{i \in S_s}{\sum_{c \in S_c}\gamma_{c,i}(s_{c,i} - y_{c,s})^2 } + \gamma_w \lVert W \rVert^2 \\
\alpha_{c,i} &= \beta_s\sum_j{w_{s,j}x_{s,j}} + \beta_l\sum_j{w_{l,j}x_{l,j}} + \beta_r\sum_j{w_{r,j}x_{r,j}} \\
\nu_{c,i} &= \beta_k\sum_j{w_{k,j}x_{k,j}} + (\sigma(\sum_j{w_{a,j}x_{a,j}}))\beta_m\sum_j{w_{m,j}x_{m,j}} \\
&+ (\sigma(\sum_j{w_{b,j}x_{b,j}}))\beta_n\sum_j{w_{n,j}x_{n,j}} \\
s_{c,i} &= (1+\alpha_{c,i})\nu_{c,i} \\
0 &\le \beta_{s,l,r,k,m,n} \le 1
\end{align}

采用NMAE与TMAE两个指标评估预测偏差度。其中，NMAE用于评估单个卖家的平均偏差，TMAE则评估整体总偏差，两个指标均是越小越好，其计算公式如下所示：
$$NMAE=\frac{\sum_{i \in S}{|\hat{y_i} - y_i|}}{\sum_{i \in S}{y_i}}=\frac{MAE}{\sum_{i \in S}{y_i}/|S|}$$ $$TMAE=\frac{|\sum_{i \in S}{\hat{y_i} - \sum_{i \in S}{y_i}}|}{\sum_{i \in S}{y_i}}$$
基于2015年的数据训练与校验模型，2016年的数据进行测试，预测2017年珠峰卖家双11成交金额，该模型在2017年9月28日给出卖家双11成交金额，在没有预售期、预热期相关特征的情况下基于卖家历史特征进行预估，总体误差在5\%以内，该模型预估值提供BI、产品、行业参考最终确定2017年珠峰商家的双11成交金额目标。

\subsection{卖家GMV预测之分业务组合模型}

双11分为预售期、预售+预热期以及双11成交日三部分，预热期模型实际预测的是双11当天的成交金额$ S^r$，该成交金额由预售期支付定金的商品在双11当天支付尾款转化、预热期加购的商品双11当天下单支付转化以及双11当天的成交转化三部分组成，

\begin{align}
S^r &= S^p+S^{\tilde p} \\
&= \gamma_pS_{1:N}^p+\gamma_hS_{1:N}^h+S_N^l
\end{align}

其中，$S^p$为双11成交金额中预售的部分，$S^{\tilde p}$ 为双11成交中非预售的部分，$N$为预热期的活动周期，$ \gamma_pS_{1:N}^p$为活动期的有效预售交易在双11当天转化的成交金额，$\gamma_p$为预售GMV转化率，$\gamma_hS_{1:N}^h$为预热期积累的有效加购在双11当天转化的成交金额，$\gamma_h$为预热期加购转化系数，$S_N^l$为双11当天其余部分带来的成交。

预热期模型需要在预热期每天预估双11卖家的成交金额，即预热期的第$i$天产出双11当天的GMV预估值$S_{i,i \le N}^r$，因此预热期模型预测问题转化为如下问题。已知从预热期的第1天开始累积到当前第$i$天的点击、加购、收藏、预售等特征$x_{1:i}$，预测卖家双11当天的GMV值$S^r = f_i(x_{1:i})$，特征$x_{1:i}=\{ x_1, x_2,...,x_i \}$随着预热期的进行不断扩展，也可以将预热期模型特设计为统一的$x_{1:i}= \{ x_1,...,x_i,0_{i+1},...,0_{N} \}$，尚未获取到的特征用零向量扩展。考虑到预热期特征中相对稳定的两个特征，截止预热期低$i$日的预售金额$S_{1:i}^p$与加购笔数$S_{1:i}^h$，这两个特征具有相对较为稳定的转化系数，其中基于往年的数据分析与经验预售金额的转化率最高。考虑到预售金额的重要性与特殊性将目标拆解为预售部分金额与非预售部分金额，基于模型分别预测预售成交GMV与非预售成交GMV，
$$ S^r \simeq S^r_i=f_i(x_{1:i})+g_i(x_{1:i}) $$
其中， $ f_i$为 截止预热期$ i$日双11总预售金额预估模型，$ g_i$为截止预热期 $ i$日双11非预售部分金额预估模型。上述模型包括卖家双11成交的预售与非预售两部分的预测，若$f_i$与$g_i$均存在预估偏差，则可能存在误差累计的问题。此处我们将该问题简化为
$$  S^r_i=S_{1:i}^p+q_i(x_{1:i}) $$
即采用模型$q_i$基于截止预热期第$i$日的预售$S_{1:i}^p$以及加购、点击、收藏等卖家、类目以及行业相关特征，预测除该部分之外的双11当天成交金额。于是多目标预测问题即转化为单目标预测问题，此处模型$q_i$需要预测预售金额$S_{1:i}^p$这部分最终没有转化的缺失金额部分、未来$N-i-1$日的预售最终的转化金额部分、加购转化部分金额（包括截止第$i$日的加购转化部分$S_{1:i}^h$以及未来的加购转化部分$S_{i+1:N}^h$）以及双11当天其余途径的转化。经数据分析与特征工程提取相关特征之后，采用XGB模型预估这部分包含多重转化的金额，最终得到卖家双11成交金额的预估值。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/salesforecast2.png"}
	\caption{}
	\label{fig:sf2}
\end{figure}

由于随着预热期的不断进行，特征的不断扩展，以及不同天预测双11的非线性关系，训练一个统一模型变得极为困难。因此从预热期11.1~11.10我们基于历史同期的特征数据分别训练了模型，采用不同模型$q_i$进行预测。

我们对比了拆解与非拆解预售两种模型的精度，拆解版本的偏差度相对于非拆解版本得到较为明显的降低，拆解模型在11.9之后NMAE能减小到0.3\%以内，11.8日总偏差达到0.4\%以内。

\subsection{双11主推预测之DNN模型}

整个天猫平台上大部分的GMV集中在少部分的商品上，到了双十一的时候这种情况就更为明显。同时在卖家维度，大部分的GMV也集中在部分的几个商品上。如果能购预测出哪些商品能够在双十一成为爆款，那么对卖家备货和运营的资源分配、以及珠峰调控都会有较大的帮助。

服饰主推款定义：将天猫服饰行业（十几个一级类目）下所有商品按照成交金额从大到小排序，顺序取到占比前50\%GMV的商品称为是主推款。根据去年双十一的成交分布，2016年服饰主推款的个数是3.2w，行业圈定的一千多个重点卖家中有2.2w的主推款商品数。 根据预测的主推款，
\begin{itemize}
\item 行业或者卖家可以根据预测出来的主推款来分配每个商品该投入多少资源（推广、备货等），成为主推款商品概率高的可以相应多投入更多资源。
\item 种草：有些商品行为比较低的也有可能成为主推款，特别是服饰经常会有很多新品，主推款预测指导行业和卖家进行适当的流量探测、投放付费流量、投放外网资源等种草操作。同时可以根据探测积累的用户行为数据，对主推款数据进行迭代优化。
\item 销量预测：主推款有一定的行为之后，结合销量预测可以帮助卖家更好的备货。
\item 预热期商品加购目标分配和调控：结合销量预测和加购分配算法，将主推款数据应用于珠峰流量调控中，使调控针对卖家主推款商品，而不是卖家下所有商品，提高了珠峰调控效率。
\item 双十一当天小时销量预测：双十一当天如果预测到商品有可能缺货的话，运营通过闪电平台或者单独通知卖家及时补货，如果及时限流避免流量的浪费。
\item 主推款预测分数参与排序：将主推款预测出来的分数，作为一个商品的静态分在双十一当天参与排序，通过OnlineLtr自动学习排序权重，可以得到正向权重。
\end{itemize}
在模型预测的过程中，抽取出来的既有稀疏的ID特征，也有稠密的排名类特征和增长率特征。如果直接用线性模型可能表达不了不同类目或不同卖家下不同主推款的分布情况；同时树模型也不适合大规模稀疏的id类特征。因此决定使用DNN模型。具体dnn模型结构如图所示，不同组的特征分别经过不同的DNN网络和多层全联接网络，使用ReLU作为激活函数以增加非线性，鉴于主推款预测是一个二分类问题，最后输出的激活函数使用的是Sigmoid函数。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/salesforecast1.png"}
	\caption{}
	\label{fig:sf1}
\end{figure}



对比去年服饰行业核心卖家中有主推款个数是2.2w个，行业打标了4w款商品，到双十一真正成为主推款的有7k个商品。今年这些核心卖家中主推款有2.6w个商品，通过算法预测的top4w款商品中有2.2w个商品成为主推款，说明通过主推款模型预测的主推款数据还是有一定参考意义的。今年行业采纳了部分算法推荐的主推款预测结果，打标了4w款商品，到今年双十一命中了大约1.6w个商品；并且用这4w款商品去BD卖家，资源相比去年得到了更合理的使用。行业也针对这些服饰的主推款数据配合上销量预测进行相应的补货，根据bi统计，去年服饰主推款缺货影响成交占比15.7\%左右，今年分析出来只占了11.1\%，缺货占比下降了4.6\%。运营整理了四千多个核心的卖家，这些卖家主推款数据进入闪电平台。运营可以通过这个平台，根据销量预测的结果和库存 识别缺货风险的商品，通知商家进行补货，双十一期间总计补货了22亿货值的商品。四千多个核心商家总共大约160w商品，通过主推款预测使得销量预测和补货更加具有针对性。

\subsection{商品销量预测之LightGBM模型}

商品销量预测基于Microsoft所提出的LightGBM模型。该模型是一种梯度提升决策树模型，与xGBoost不同的是，该模型分裂叶子节点不是基于Level-Wise的层级优先策略，而是采用了一种带有深度限制的Leaf-Wise叶子分裂策略，通过每次在树节点中找到分裂增益最大的一个节点进行分裂优化树的节点生长。其中分裂增益定义为
$$\mathcal{L}=\frac{1}{2}\left[\frac{(\sum_{i\in I_L}{g_i})^2}{\sum_{i\in I_L}{h_i+\lambda}}+\frac{(\sum_{i\in I_R}{g_i})^2}{\sum_{i\in I_R}{h_i+\lambda}}-\frac{(\sum_{i\in I}{g_i})^2}{\sum_{i\in I}{h_i+\lambda}}\right]-\gamma $$
这里$I_L,I_R,I$分别为单次分裂中左右节点和当前节点中的候选样本集，$\lambda,\gamma$为正则项的超参，$g_i,h_i$分别为loss function的Gradient矩阵与Hessian矩阵。相比于Level-Wise每次不加区分的分裂同一层所有叶子节点的算法，这种策略减少了不必要的叶子节点分裂，在相同的分裂次数下可以降低更多的误差，获得更好的精度。同时，lightGBM模型相比于xGBoost模型在Cache命中率，作差法提高直方图计算效率等方面也有一定的优化。如示意图所示，lightGBM模型每次选择具有最大熵增益的节点分裂，可能导致最终生成的不是完全二叉树。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/salesforecast4.png"}
	\caption{lightGBM模型Leaf-wise的分裂过程示意图}
	\label{fig:sf4}
\end{figure}

同时我们发现，集团PAI平台上的xGBoost模型、PS-SMART模型与lightGBM模型类似，但是PAI平台上的这两个模型都不支持MAE的loss function，原因是MAE loss在原点附近Hessian矩阵不存在，因此以往的研究都是使用MSE(mean square error)近似MAE，与业务目标存在一定的偏差。参考lightGBM源码中的实现和相关文献资料，我们为集团PS-SMART平台的同学提供了MAE loss Heat Kernel形式的海森矩阵，使得模型可以支持MAE objective。其中Gradient矩阵与Hessian矩阵如下
Gradient
$$g_{i} = \begin{cases}
w_i, &  y_{i} - y >=0\\\\ 
-w_i, &  y_{i} - y <0
\end{cases}$$

Hessian
$$h_{i} = \frac{a}{c\sqrt{2\pi}}e^{-\frac{(y_i-y)^2}{2c^2}}
$$

其中 $a=2|g|w_i$, $c$是充分小的正数。
我们在相同的数据集上进行了对比实验，发现直接使用MAE loss训练模型和相比于用MSE loss近似训练模型，可以提高指标2\%~6\%。此外，我们也尝试了重采样和蒙特卡洛随机化参数寻优等技巧，可以在人工参数的基础上提升0.5\%~1.5\%。
复盘分析发现小时级销量预测与预售类商品预测有较高的预测精度，如图所示给出了小时级预测与预售类商品预测的误差曲线，

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.7\linewidth]{"fig/salesforecast3.png"}
	\caption{小时级销量预测MAE（左图）和预售类商品销量预测MAE（右图)}
	\label{fig:sf3}
\end{figure}


而主推款集合预测在10.31时命中率已经达到80\%以上, 强烈推荐主推款命中率达到73\%，并随着临近双11覆盖率逐步提升。图中浅灰色代表推荐主推款命中率，深灰色代表强烈推荐主推款命中率。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.7\linewidth]{"fig/salesforecast5.png"}
	\caption{主推款预测覆盖率（左图)和部分三个行业商品销量预测MAE（右图）}
	\label{fig:sf5}
\end{figure}

同时商品销量预测在预热期之前准确度已经接近50\%，预热期间误差逐步下降。图中的三条曲线分别代表服饰（红），天猫国际（绿），电器城（蓝）。

\subsection{总结分析}

销量预测在双11期间为珠峰，供应链，行业决策发挥了很大作用，其中部分指标如下：

\begin{itemize}
\item 小时级预测在11.11当天中午12:00时预测精度（1-MAE）达到90\%以上
\item 双11销量预测在准备阶段完成时预测精度(1-MAE）达到50\%~80\%
\item 主推款预测在准备阶段完成时命中率达到80\%以上
\item 服饰主推款缺货影响成交占比下降了4.6\%，相当于增加GMV约**18.9亿**
\item 卖家GMV预测误差在5\%以内，并提供给行业参考最终确定双11成交金额目标
\item 卖家GMV总体预测分业务组合模型11.08日总误差达在0.4\%以内
\end{itemize}

销量预测是一个相对基础但是非常重要的项目，特别是在对指导卖家或运营指定营销计划、规划物流、备货等方面是一个不可或缺的环节。今年我们团队刚开始触及销量预测等商业化项目，在销量预测这个研究方向上也只是刚迈出一小步，未来还有相当多深挖的地方，包括更加细粒度的特征分析与特征工程、基于深度学习神经网络、复杂时序模型的优化求解以及实时GMV预测等，商业化项目的道路任重而道远。

\section{珠峰中控}

\subsection{背景}

“珠峰”项目致力于打造一个公域渠道下的流量管理平台：
(1)在个性化背景下用柔性精准的算法调控保障商家的流量确定性；
(2)与供应链深度打通，将行业核心入仓货品基于销售计划做前后端流量协同；
(3)商家参与闭环建立，由单侧珠峰升级成双侧珠峰，充分调动商家的主观能动性。

\subsection{珠峰算法框架}
在介绍中控系统之前，首先介绍一下珠峰算法框架：

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/zhufeng.jpg"}
	\caption{珠峰系统框架}
	\label{fig:zhufeng}
\end{figure}

今年珠峰第一个突破是将珠峰选品和供应链系统深度融合，并且引入了销售计划的概念，将双11当天的目标拆解到预售、预热和售卖期三个阶段，极大程度缓解了双十一当天的压力。首先卖家GMV预估和目标计划模型给卖家中控系统提供了可靠的信号输入，对双11珠峰大盘节奏把控起到了至关重要的作用[（Manhattan商业化项目之卖家双十一GMV预估）](https://www.atatech.org/articles/94517)；今年新引入的主推款商品挖掘与供应链系统打通，不仅为商品中控系统和商品调控系统奠定了基础，同时还影响到了行业决策和商家备货，是珠峰商业闭环模式下不可或缺的一部分[（Manhattan商业化项目之双十一主推款预测）](https://www.atatech.org/articles/94518)；商品销量预测在主推款挖掘的基础上实现了选品、目标计划、缺货限流等功能，大大提高了商品调控Plan和货+仓调控Plan的完成率和整体效率，是珠峰高维立体调控体系中的核心决策系统之一[（Manhattan商业化项目之双十一销量预测）](https://www.atatech.org/articles/94520)。
今年珠峰第二个突破是Hierarchical中控体系的设计。在珠峰卖家中控层上游增加了主推款商品中控层，既保证了卖家整体目标的最优化分配和珠峰大盘目标的过程控制，又能够对核心货品流量进行差异化管理；在珠峰卖家+商品的精准计划的基础上，又增加了KA以上层次的柔性信号输入，形成了从珠峰核心商品层到珠峰卖家层再到KA-SKA-GSKA层的Hierarchical分层中控框架。
今年珠峰第三个突破是Plan与RL结合的高维立体调控体系。今年双11的Plan系统在TPP平台实现了基于抗积分饱和PID控制器的多线程并发框架，支持了卖家和商品调控Plan的过程控制，并且采用了基于Druid引擎的实时数据查询接口，将卖家Plan的一个PID采样周期从开始的10分钟缩短到了30秒以内，大大提升了控制精度[（实时交互式大数据服务双11总结）](https://www.atatech.org/articles/94619)；而今年在基于Plan的精准调控的基础上，引入了基于强化学习的柔性调控，减小了基于Plan调控带来的瞬时损失，同时能够更快的收敛到新的局部最优解[（基于强化学习的分层流量调控）](https://www.atatech.org/articles/94327)。
今年第四个突破是从单侧珠峰到双侧珠峰。在算法上的双侧指的是整个珠峰的反馈系统采用了新的正交AB分桶算法，使得搜索和推荐能够在统一的正交分层上进行AB测试；在商业上的双侧指的是优惠券权益联动、货品供应链融合、工具中枢到行业指导再到卖家参与的商业闭环机制等等。

珠峰系统中，卖家调控计划的框架图如下：

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.6\linewidth]{"fig/zhufengseller.jpg"}
	\caption{卖家调控框架}
	\label{fig:zhufengseller}
\end{figure}

其中中控系统是整个框架的中转站，上游承接了基于销量预测和目标计划的决策系统，中间和工具中枢系统进行交互和Plan传递[（2017双十一珠峰技术大练兵之工程篇）](https://www.atatech.org/articles/94362)，在下游对接调控系统，实现各个渠道的流量调控。

\subsection{中控算法}
珠峰是一个商业价值与流量价值相辅相成的项目，虽然公域流量下调控渠道占比有限，但是控制的都是全网效率较高的核心流量，通过这些渠道下的用户行为间接影响着全网大大小小的场景、同时还将流量直接或间接引导到了私域渠道，更重要的是通过这些核心流量对商家形成激励，带动更多的商业信号注入和权益资源倾斜，形成商业闭环模式下的双侧珠峰。因此珠峰更像是一种杠杆效应，以有限的流量作为撬动大盘的钥匙。

中央控制算法是对商家和核心商品的销售计划、流量承接能力（IPV价值）进行预测，提前判断商家和核心商品的目标规划是否合理，完成整体目标是否有风险，同时将商家和核心商品的目标在各个渠道进行全局效率最优的动态规划，在兼顾珠峰整体目标、商家目标、核心商品目标的同时，给予部分商家和商品流量激励。

中控系统的主要算法模块包括流量进度控制算法、实时IPV价值预估算法、中控分配算法、流量收敛控制算法、流量止损控制算法，下面将会对中控主要算法进行详细介绍。
\subsubsection{流量进度控制算法}
流量进度控制算法分为渠道流量进度控制和小时流量进度控制两部分，其中卖家和商品的流量进度控制算法相似，这里以卖家算法为例：

第一部分渠道流量进度控制。因为珠峰撬动的只是公域流量，而接收到的目标则为各个卖家的大盘整体目标，因此在珠峰卖家整体目标到渠道目标需要设计一个函数来映射：

\begin{align}
G_{t+1,c}(i)=\frac{g_{t,c}(i) + M}{g_{t,n}(i) + N}\times G_{t+1,n}(i) + p_c(i)\times \frac{grad(g_{t,c}(i))}{R_{t,c}(i)} \\
+ p_n(i) \times \frac{grad(g_{t,n}(i))}{R_{t,n}(i)}
\end{align}

其中$G_{t+1,c}(i)$为t+1时刻卖家i的渠道全天目标，$G_{t+1,n}(i)$为t+1时刻卖家i的整体全天目标，$g_{t,c}(i)$为t时刻卖家i的渠道当前真实值，$g_{t,n}(i)$为t时刻卖家i的整体当前真实值，M、N为调控占比平滑因子，$p_c(i)$、$p_n(i)$分别为卖家i在渠道梯度累计值和大盘梯度累计值的背负系数函数，$R_{t,c}(i)$为卖家i在t时刻的渠道目标完成量累计占比，$R_{t,n}(i)$为卖家i在t时刻的大盘目标完成量累计占比。该式第一项通过计算卖家调控渠道和大盘实时数据的比值得到渠道占比，然后通过整体全天目标得到了当前时刻下估算出来的渠道全天目标初始值，第二、第三项分别先计算了渠道和大盘的实时数据梯度累计值，然后通过目标完成量累计占比预估出全天梯度累计值，最后通过背负系数函数得到卖家在渠道内需要完成的全天目标增量。

第一部分小时流量进度控制。在得到卖家调控渠道全天目标之后，需要把目标分拆到每个小时，通过分析猜你喜欢、手淘搜索、大盘等各个维度下卖家在2016年预热期和双11当天的流量进度曲线，最终卖家在各自渠道下分别采用了渠道珠峰大盘的IPV小时占比，在计算卖家全网流量进度时采用了全网珠峰大盘的IPV小时占比。但是考虑到调控期间风险前置的需要，在全网珠峰大盘小时占比计算时将最后一小时的流量按照分布比例累加到了前23小时，因此在最后一个小时开始前的累计完成占比提前达到了100%。

计算出了卖家在调控渠道大盘下的全天目标目标之后，通过实时IPV价值预估和和实时数据回流，方可通过中控分配算法来进行目标分配。

\subsubsection{卖家中控分配算法}
卖家中控分配算法是中控系统中最核心的算法，通过卖家 IPV 价值、原生流量和目标流量，进行多卖家、多渠道重新分配，保证珠峰整体 GMV 最大化、卖家目标的完成率、同时防止分配比例不会偏离原生流量过多。

卖家中控分配算法目标函数如下：
\begin{align}
\min_x - \gamma \sum_jS_j \sum_{i\in N_j,k} c_{i,k} x_{i,k}  + \eta \sum_j \sum_{i \in N_j} c_i w_i  \left [g_i - S_j \sum_k x_{i,k} \right]_{+} \\
+ \frac{\lambda}{2} \sum_j S_j \sum_{i \in N_j,k}(x_{i,k}-p_{i,k})^2 \\
\leftline{s.t.} \\
\frac{\delta_{i,k}^{0}}{S_j} \leq x_{i,k} \leq \frac{\delta_{i,k}^0 + (u_{j,k} + v_{i,k}) \delta_{i,k}^1}{S_j} \\
\sum_{i \in N_j,k} x_{i,k}=1 \\
\leftline{where} \\
S_j=\sum_{i \in N_j,k} \delta_{i,k}^{0} + u_{j,k}(\delta_{i,k}^1-\delta_{i,k}^0) \\
[z]_+= \begin{cases}  
z \quad z>0 \\
0 \quad z \leq 0
\end{cases}
\end{align}

\begin{align}
x_{i,k}: &the\ proportion\ of\ the\ i-th\ seller\ in\ the\ industry\ of\ the\ k-th\ channel. \\
c_{i,k}: &the\ IPV\ value\ of\ the\ i-th\ seller\ in\ the\ k-th\ channel. \\
c_i: &the\ averaged\ IPV\ value\ of\ the\ i-th\ seller. \\
w_i: &the\ weight\ of\ the\ i-th\ seller. \\
g_i: &the\ required\ IPV\ from\ the\ i-th\ seller. \\
p_{i,k}: &the\ natural\ IPV\ of\ the\ i-th\ seller\ through\ the\ k-th\ channel. \\
u_{j,k}: &up-bound’s\ magnification\ factor\ for\ the\ j-th\ industry\ from\ the\ k-th\ channel. \\
v_{i,k}: &additional\ up-bound’s\ magification\ factor\ for\ the\ sellers\ from\ the\ k-th\ channel. \\
\delta_{i,k}^0: &the\ organic\ IPV\ of\ the\ i-th\ seller\ through\ the\ k-th\ channel. \\
\delta_{i,k}^1: &the\ up-bound\ IPV\ of\ the\ i-th\ seller\ through\ the\ k-th\ channel. \\
N_j: &the\ set\ of\ sellers\ belonging\ to\ the\ j-th\ industry. \\
S_j: &the\ limitation\ of\ IPV\ for\ the\ j-th\ industry.
\end{align}

目标函数三个loss项之所以这么设计，主要为了分别解决以下三个核心问题：
（1）珠峰卖家整体GMV最大化，得到全局效率最优的分配解。
（2）对于不同卖家的流量需求能够差异化的达成。
（3）控制分配占比和原始流量占比的偏离程度，减小调控振幅。

很显然，目标函数将$\sum_jS_j$项提出来之后可以分解为N个独立子问题，形式如下：
\begin{align}
\min_x - \gamma s\sum_{i,k} c_{i,k} x_{i,k}  + \eta \sum_i w_i  \left [g_i - s\sum_k x_{i,k} \right]_{+} \\
+ \frac{\lambda}{2} s \sum_k(x_{i,k}-p_{i,k})^2 
\end{align}
\leftline{s.t. }
\begin{align}
l_{i,k} \leq x_{i,k} \leq h_{i,k} \\
\sum_k x_{i,k}=1 
\end{align}

这里为了简化，用$s$表示$S_j$，$l_{i,k}$和$h_{i,k}$分别表示$x_{i,k}$的下确界和上确界，上式的向量化表示如下：
\begin{align}
\min_x x^T\frac{\lambda}{2}x - \left (\gamma c^T + \lambda p^T \right )x + w^T \left [g-Hx \right ]_+ \\
\leftline{s.t. }
l \leq x \leq h \\
d^Tx=1 
\end{align}
其中：
$$
\begin{aligned}
&x=\left (x_{1,1},\cdots,x_{1,K},x_{2,1},\cdots,x_{|N_j|,K}\right )^T \\
&c=\left (c_{1,1},\cdots,c_{1,K},c_{2,1},\cdots,c_{|N_j|,K}\right )^T \\
&p=\left (p_{1,1},\cdots,p_{1,K},p_{2,1},\cdots,p_{|N_j|,K}\right )^T \\
&w=\eta\left (c_1w_1,c_2w_2,\cdots,c_{|N_j|}w_{|N_j|}\right )^T \\
&g=\left (\frac{g_1}{s},\frac{g_2}{s},\frac{g_{|N_j|}}{s} \right )^T \\
&H=\left(
\begin{matrix}
\overbrace{1,\cdots,1}^{{}K}, &0, \cdots,  0      \\
\vdots       \\
0,\cdots,0, &\underbrace{1,\cdots,1}_{{}K} \\
\end{matrix}
\right) \in R^{|N_j|\times|N_j|K}  \\
&l=\left(l_{1,1},\cdots,l_{1,K},l_{2,1},\cdots,l_{|N_j|,K}\right)^T  \\
&h=\left(h_{1,1},\cdots,h_{1,K},h_{2,1},\cdots,h_{|N_j|,K}\right)^T  \\
&d=\left(1,1,\cdots,1\right)^T\in R^{|N_j|K}
\end{aligned}
$$

定义如下增广拉格朗日函数（Augmented Lagrangian Function）：
\begin{align}
L_{\beta}(x,\alpha)=x^T\frac{\lambda}{2}x - (\lambda p^T + \gamma c^T)x + w^T[g-Hx]_+ \\
\- \alpha(d^Tx-1) + \frac{\beta}{2}(d^Tx-1)^2
\leftline{s.t. }
l \leq x \leq h 
\end{align}

原始问题可以写为：
\begin{align}
\min_x\max_{\alpha}L_{\beta}(x,\alpha)
\end{align}
对偶问题可以写为：
\begin{align}
\max_{\alpha}\min_xL_{\beta}(x,\alpha)
\end{align}
转化为求解如下迭代公式：
\begin{align}
x^t= \begin{cases}  
\prod_{[l,h]}arg\min_xL_{\beta}(x,\alpha^t) \quad (1) \\
\alpha^{t+1}=\alpha^t-\beta(d^Tx^t-1)
\end{cases}
\end{align}
对于这种非光滑凸函数（1），可以用投影梯度法来求解，具体求解方式可以参考
[一种求解带约束的非光滑凸优化问题的通用算法](https://www.atatech.org/articles/89894)。

\subsubsection{商品中控分配算法}
买家中控保证了卖家流量的最优分配，但是并没有体现同一个卖家不同商品之间的差异。对于同一个卖家，可能出现流量过度集中在头部商品而导致加购过剩，也可能出现低效商品被加权后影响卖家整体 GMV 效率，同时还有部分卖家仓储维度的商品需要通过调控满足业务目标。


\begin{figure}[!h]
	\centering
	\includegraphics[width=0.6\linewidth]{"fig/zhufeng360.png"}
	\caption{流量分配}
	\label{fig:zhufeng360}
\end{figure}

例如，C1 为大促时卖家流量分布情况，绝大多数流量都集中在头部爆款商品；通过优化后的C2曲线，能够通过主推款预测挖掘出更多的潜爆款，提高珠峰卖家被调控商品的丰富度，同时在爆款断货之前提前将流量分配给更多潜力商品，从更高维度优化整体效率和体验。为了解决上述问题，保证卖家主推款整体 GMV 最大化、主推款商品和仓储货品目标完成度、加购过热的商品提前减小调控力度，给出目标函数如下:
\begin{align}
\min_x - \gamma \sum_jS_j \sum_{i\in N_j,k} c_{i,k} x_{i,k}  + \eta \sum_j \sum_{i\in N_j} c_i w_i  \left [g_i - S_j \sum_k x_{i,k} \right]_{+} \\
+ \beta \sum_j \sum_{i \in N_j} cot \left ( \frac{\pi}{2d_i}\left[d_i-a_i,0\right]_+\right )\sum_k x_{i,k} \\
\leftline{s.t.} \\
\frac{\delta_{i,k}^{0}}{S_j} \leq x_{i,k} \leq \frac{\delta_{i,k}^0 + (u_{j,k} + v_{i,k}) \delta_{i,k}^1}{S_j} \\
\sum_{i \in N_j,k} x_{i,k}=1 \\
\leftline{where} \\
S_j=\sum_{i \in N_j,k} \delta_{i,k}^{0} + u_{j,k}(\delta_{i,k}^1-\delta_{i,k}^0) \\
[z]_+= \begin{cases}  
z \quad z>0 \\
0 \quad z \leq 0
\end{cases}
\end{align}

\begin{align}
x_{i,k}: &the\ proportion\ of\ the\ i-th\ item\ in\ the\ category\ of\ the\ k-th\ channel. \\
c_{i,k}: &the\ IPV\ value\ of\ the\ i-th\ item\ in\ the\ k-th\ channel. \\
c_i: &the\ averaged\ IPV\ value\ of\ the\ i-th\ item. \\
w_i: &the\ weight\ of\ the\ i-th\ item. \\
g_i: &the\ required\ IPV\ from\ the\ i-th\ item. \\
u_{j,k}: &up-bound’s\ magnification\ factor\ for\ the\ j-th\ category\ from\ the\ k-th\ channel. \\
v_{i,k}: &additional\ up-bound’s\ magification\ factor\ for\ the\ items\ from\ the\ k-th\ channel. \\
\delta_{i,k}^0: &the\ organic\ IPV\ of\ the\ i-th\ item\ through\ the\ k-th\ channel. \\
\delta_{i,k}^1: &the\ up-bound\ IPV\ of\ the\ i-th\ item\ through\ the\ k-th\ channel. \\
N_j: &the\ set\ of\ items\ belonging\ to\ the\ j-th\ category. \\
S_j: &the\ limitation\ of\ IPV\ for\ the\ j-th\ category. \\
d_i: &the\ add-cart\ or\ pay\ number\ for\ the\ i-th\ item. \\
a_i: &the\ stock\ for\ the\ i-th\ item
\end{align}


由于上式出现了第三项hinge loss项，并且该项在库存趋于0时为无穷大，因此可以定义可售商品集合L来改写上式：
\begin{align}
\min_x - \gamma \sum_jS_j \sum_{i\in N_j\cap L,k} c_{i,k} x_{i,k}  + \eta \sum_j \sum_{i\in N_j\cap L} c_i w_i  \left [g_i - S_j \sum_k x_{i,k} \right]_{+} \\
+ \beta \sum_j \sum_{i \in N_j\cap L} cot \left ( \frac{\pi}{2d_i}(d_i-a_i)\right )\sum_k x_{i,k} \\
\leftline{s.t. }\\
\frac{\delta_{i,k}^{0}}{S_j} \leq x_{i,k} \leq \frac{\delta_{i,k}^0 + (u_{j,k} + v_{i,k}) \delta_{i,k}^1}{S_j} \\
\sum_{i \in N_j,k} x_{i,k}=1 
\end{align}
至此第三项变为单调光滑项，可用类似卖家中控分配算法的解法求解。

在商品中控目标函数设计的时候和卖家中控有三点不同，一是减少了调控振幅的loss项，这是因为商品流量的不确定性和波动幅度相比卖家来说要大很多，这一项在商品中控的作用不明显，反而可能会抑制潜爆款的流量空间；二是增加了库存的loss项，主要是为了防止卖家商品头部过热现象，这里的loss项其实是一种广义约束，可以推广到商品过度曝光、效率止损等等场景，只要定义好自己的函数形式和区间范围即可；三是子问题空间（sub-problem space）定义从行业升维到一级类目，主要考虑到大部分情况下商品在一级类目即可达到流量隔离，因此只需要在一级类目内做目标分配和腾挪。

\subsubsection{流量收敛控制算法}
中控系统在预售期运转过程中，发现部分流量承接能力良好的卖家每个小时都能够超预期完成当前目标，甚至下午就能完成全天目标，这些卖家或是通过参与活动提高了当天的爆发系数，亦或是通过站内外广告拿到了较大的流量增量，再或是货品竞争力较强，总之在这部分超调卖家的流量挤压之下，导致部分弱势卖家成为了风险卖家，这是业务上不希望看到的。基于此，中控系统在分配算法下游设计了流量收敛控制算法，用于超调卖家的目标腾挪，给风险卖家创造更大的提升空间。
首先定义收敛算子$F_{t+1,c}(i)$：
\begin{align}
F_{t+1,c}(i) = \frac{1}{\exp\left(\beta_c(i) \cdot (\frac{g_{t,c}(i)}{G_{t+1,c}(i) \cdot R_{t,c}(i)} - 1)\right )}
\end{align}
式中$g_{t,c}(i)$表示t时刻c渠道下卖家i的当前真实值，$G_{t+1,c}(i)$表示t+1时刻c渠道下卖家i的全天目标值，$R_{t,c}(i)$表示t时刻c渠道下卖家i的目标完成量累计占比，$\beta_c(i)$为卖家在渠道下的收敛系数，后期主要通过调整该参数来控制收敛速度。
定义好收敛算子之后，我们可以得到收敛函数：
\begin{align}
G_{t+1,c}(i)= \begin{cases}  
0 & g_{t,c}(i)>G_{t+1,c}(i) \\
F_{t+1,c}(i) \cdot G_{t+1,c}(i) & G_{t+1,c}(i)\cdot R_{t,c}(i) \leq g_{t,c}(i) \leq G_{t+1,c}(i) \\
G_{t+1,c}(i) & g_{t,c}(i)<G_{t+1,c}(i) \cdot R_{t,c}(i)
\end{cases}
\end{align}
对于第一个分段区间，主要考虑到如果卖家在某一时刻提前完成了全天目标，则停止调控；对于第二个分段区间，表示卖家在当前时刻完成度超出预期，但是并没有达成全天目标，因此按照收敛算子的结果进行目标收敛；第三个分段区间表示卖家在当前时刻完成度没有达到预期，则仍然沿用中控分配算法的计算结果进行调控。


\subsubsection{流量止损控制算法}
对于一个卖家来说，流量承接效率会随着流量的增加而下降，如下图所示：

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/zhufeng1.png"}
	\caption{}
	\label{fig:zhufeng1}
\end{figure}

尽管中控分配算法能够让整体效率最大化，但是对于同一个卖家来说，如果效率下降过多，不仅会造成流量浪费，还会对竞争卖家造成流量挤压，加剧高危卖家增多的风险，甚至造成渠道大盘指标下跌。因此中控系统在最末端增加了IPV价值的止损环节，实时监控卖家的效率波动情况，对效率下降的卖家提前作出预判和止损控制，这也是中控系统在保证渠道效率的最后一道关卡。首先定义止损算子$H_{t+1,c}(i)$：
\begin{align}
H_{t+1,c}(i) = \frac{1}{\exp\left(\alpha_c(i) \cdot (\frac{v_{t,c}(i)}{v_{t,c}^{'}(i)} - 1)\right )}
\end{align}
式中$v_{t,c}(i)$表示t时刻c渠道卖家i在基准桶的IPV价值，$v_{t,c}^{'}(i)$表示t时刻c渠道卖家i在测试桶的IPV价值，$\alpha_c(i)$为卖家在渠道下的止损系数，控制止损速度。
因此，止损函数如下：
\begin{align}
G_{t+1,c}(i)= \min{ G_{t+1,c}(i), H_{t+1,c}(i) \cdot G_{t+1,c}(i) }
\end{align}

\subsubsection{数据分析}
2017双十一珠峰整体目标完成率102\%，同比增长58\%，在达成目标的卖家数量上和分布的合理性上都较去年有明显提升。其中手淘搜索渠道成交金额同比增长151\%，猫客和mall tab同比分别增长70\%和125\%，统一搜索\&推荐珠峰调控正交分层之后，在相同分层调控AB下，全渠道GMV微跌基本无损。
双十一当天各个渠道下珠峰商家整体指标增幅如下：

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/zhufengzengliang.jpg"}
	\caption{珠峰增量}
	\label{fig:zhufengzengliang}
\end{figure}

\subsubsection{流量进度控制}
下图为11.4手淘搜索流量进度控制曲线，可以看到由于小时流量进度控制算法，使得$R_{t,n}(i)$在前几个小时较自然流量占比偏大，再加上渠道流量进度控制算法的梯度累积算子，使得计算出来的渠道占比被进一步放大；随着时间的推移，渠道占比逐渐收敛到真实比例；最后由于完成目标的卖家数量逐渐增多，分配的流量比例会逐渐下降。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/zhufeng2.png"}
	\caption{手淘搜索流量进度控制曲线}
	\label{fig:zhufeng2}
\end{figure}

流量进度控制算法不仅担负着调控流量渠道占比的计算，还需要控制全天的调控节奏，尽量让效率高的卖家尽早达成目标，将风险卖家留在后面几个小时进行补救，将整体风险控制在最小。另外今年与往年不同的是，预售+预热期的引导成交首次超过了双11当天的直接引导成交，因此当天的流量进度控制策略从0点开始就不断地调整来适应当天的流量变化。

\subsubsection{中控分配算法}
下图为基于目标函数的卖家中控分配算法较基础版本分配算法的增幅曲线，横坐标为1-24小时整点，纵坐标为每个小时将全天目标更新之后重新计算的目标增幅，其中红色曲线为11.4预热期的效果，在1\%至4\%之间波动，11.11当天的增幅在4\%至12\%之间波动。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/zhufeng3.png"}
	\caption{中控分配算法}
	\label{fig:zhufeng3}
\end{figure}

下图为中控分配算法IPV目标相比自然流量的变化幅度，蓝色曲线为预热期11.4的效果，整体流量波动幅度控制在10\%以内。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/zhufeng4.png"}
	\caption{中控分配算法IPV变化幅度}
	\label{fig:zhufeng4}
\end{figure}

预热期第一天只有卖家中控生效，第二天上线了商品中控，大概6w商品被覆盖，调控目标总量占到了卖家中控50\%左右，相比只有卖家中控的版本，在搜索渠道的曝光增量增加69\%，整体效率保持平稳，一定程度上缓解了卖家商品头部过热的现象。

\subsubsection{流量收敛控制}
下图为每个小时流量收敛算法腾挪出来的目标流量占渠道总流量的比值，可以看到随着时间的推移，完成目标的卖家数量增多，流量腾挪比例逐渐升高。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/zhufeng5.png"}
	\caption{流量收敛}
	\label{fig:zhufeng5}
\end{figure}

\subsubsection{流量止损控制}
下面两张图分别为11.4和11.11当天的流量止损控制曲线，图中横坐标为止损区间，定义为（卖家基准桶效率-卖家测试桶效率）/卖家基准桶效率，纵坐标为落在止损区间的卖家数量占珠峰卖家总数的比例，可以看到随着时间推移，低效卖家数量占比逐渐降低，卖家效率的损失值逐渐控制在10\%~30\%。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/zhufeng6.png"}
	\caption{11.4止损曲线}
	\label{fig:zhufeng6}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/zhufeng7.png"}
	\caption{11.11止损曲线}
	\label{fig:zhufeng7}
\end{figure}

\subsubsection{结尾}
转眼间珠峰项目已经陪伴双11走过了两个年头，去年IDST团队作为珠峰项目的开山鼻祖，留下了大量的技术沉淀和业务思考，是我们至今还在学习的宝贵财富，而今年的业务目标压力更大，业务约束也更多。刚开始拿到目标的时候，甚至整个项目室都觉得遥不可及，然而经过三个月的鏖战，转战了四个项目室，从日常到直营到预售到预热再到双11当天，经历了五个阶段的目标切换、七个版本的迭代更新、两套系统的开发维护以及双11期间大量的策略调整，终于在11.11当天24点前夕，把目标变成了现实。

在商业化大背景下，珠峰未来的路还很长，需要探索和优化的领域还有很多，如何能够将计划经济与市场经济更好地融合，是我们未来需要探索的方向。



\section{冷启动}
\subsection{背景}
在电商平台中，新商品总是不间断的出现，新商品因为缺乏用户行为，因此缺乏各项统计数据，而线上的各种机器学习模型都是建立在商品的丰富统计特征上对商品的转化率进行的预估，因此新商品很难获得曝光机会。


目前的新商品的冷启动主要依赖卖家行为，例如营销、活动以及广告等，通过外部流量增加新商品的曝光，从而逐渐丰富商品的统计属性，使其可以正常参与进搜索排序的效率模型。但不同的卖家营销能力也各不相同，卖家对于新商品的效率预判也很有限，所以存在大量的资源浪费在不精准的营销上，这就迫使我们思考，如何从平台的角度出发，设计一种针对新商品的冷激动机制。

\subsection{已有工作}
从平台角度对新商品进行冷启动，目前已有两大类方案：
\begin{itemize}  
\item \textbf{新品加权}，这类方案假设新商品是用户更需要的，所以强制通过加权，将新商品展示给用户，从而积累用户行为，使该商品可以后期在没有新品加权的作用下，可以通过自身属性参与排序。这个方案的最大问题在于会严重损害平台的利益，并不是所有用户都偏好新商品，而且也并不是所有新商品都是优质商品，因此强制加权必然会导致整体的转化率下降，平台收益下降。
\item \textbf{协同过滤中的冷启动}，这类方案重点关注的是“新用户冷启动”，优化的是无行为用户的推荐体验，通常是通过推荐热门来实现，而对“新商品启动”的处理较为简单，主要依赖商品现有的有限属性，例如卖家在发布商品的时候填写的描述（包含文字和图片），进行人物匹配。这类方案的缺点在于，商品的描述和商品本身的转化率并无较大的因果关系。
\end{itemize}

与已有的工作不同，我们设计了一种基于强化学习的新商品冷启动智能方案，通过小流量探测，提前发现新品中的优质商品，加速其成长的过程，加速整个平台优胜劣汰的进程。

\subsection{基于强化学习的新商品冷启动方案}

本方法通过对新商品一系列的流程进行迭代，从新商品中发现优质商品，加速其成长。因为新商品数量较大，同时较多的线上探索流量会损害平台的当前利益，所以我们设计了2阶段的过滤，将有可能成为优质商品的新商品进行启动，主要的流程如下（见图\ref{fig_problem})：
\begin{figure}[!h]
\centering
%\includegraphics[height=8em]{problem2}\hspace{1ex}
\includegraphics[width=1\linewidth]{fig/fig.pdf}
\caption{冷启动之算法流程}
\label{fig_problem}
\end{figure}

\begin{enumerate}  
\item \textbf{离线评估}: 我们通过建立在自然状态下，新商品中不同属性到一段时间后其自然启动完成率的机器学习预测模型$F_1(x)$，粗粒度筛选一批较大概率快速成长的新商品进入下一流程。
\item \textbf{在线探测}: 这一阶段，我们将在小流量上对新商品进行尝试投放，并收集因此获得的探测属性，包含但不仅限于新商品在投放之后，分阶段分力度分人群的各项统计数据。
\item \textbf{劣品过滤}: 经过阶段2之后，使用得到的探测特征以及使用后续流程训练得到的机器学习模型$F_2(x)$将大概率无法启动的新商品提前过滤。
\item \textbf{强化学习投放}: 我们将用户信息$u$，搜索关键词信息$q$，以及新商品当前的属性特征$x$（这里包含三部分：已有属性、探测属性、投放期间的实时属性）当作策略的输入，学习一个投放策略$G(u,q,x)->R$，表示以多大概率对该商品进行投放。当投放产生一次有效曝光后，即可产生一次有效奖赏，奖赏设计为：成交>点击>展示。在这里，我们设计使用目前最优的连续动作的强化学习算法TRPO作为我们的实现。
\item \textbf{断投测试}: 停止进行新商品的投放，测试其在自然状态下的流量情况，统计算法的启动成功率，一方面可以当作整个流程有效性评价的指标，另一方面可以提供训练标签给F2，使其与探测属性之间建立关联，帮我们提前过滤掉很难被启动的新商品
\end{enumerate}

\subsection{强化学习投放}
我们将平台对新商品的启动过程，抽象为一个MDP：平台作为一个需要进行决策的智能体，在每一次决策前，观测到一个新商品，将该新商品目前的所有阶段性的属性
$x$，结合当前流量中的上下文信息，即用户$u$和关键词$q$作为状态$s=(u,q,x)$，并通过当前的决策模型$\pi(s) \to a$，输出此时需要给该新商品启动的力度，同步作用到线上。商品在线上投放后，会根据用户的反馈（点击购买等），获得一个瞬时奖赏$r$，用于评价动作的好坏，同时由于自身属性发生了变化，转移到下一个状态$s'$。

学习算法我们采用了state-of-the-art的连续动作强化学习算法，具体来说，通过优化下面的式子，去优化策略$\pi$的参数$\theta$:

\begin{align}
\max & \quad \quad E_{s \sim \rho_{\theta_{old}},a \sim q} \frac{\pi_{\theta}(a|s)}{q(a|s)} Q_{\theta_{old}}(s,a) \nonumber \\
s.t. & \quad \quad E_{s \sim \rho_{\theta_{old}}} D_{KL} \big( \pi_{\theta_{old}}(\cdot|s) || \pi_{\theta(\cdot|s)} \big) \le \delta \nonumber
\end{align}

\subsection{总结}
新品加权通过暴力加权，协同过滤通过固有属性关联，从而给所有新品一定的曝光机会，都会浪费大量平台的流量资源，展示了低效的商品，而本方案中通过设计了多层的过滤系统，可以提前发现低效商品并将其排除在冷启动流程之外，另一方面，启动的过程中，因为采用了强化学习算法，优化的是整个过程的累积奖赏，只有真正高效的新商品才会被整个机制进行投放，从而可以做到在保证流量利用率的前提下，对新商品进行冷启动。




\section{供应链效率优化探索}
\subsection{前言}
供应链的定义是，产品生产和流通过程中所涉及的原材料供应商、生产商、分销商、零售商以及最终消费者等成员通过与上游、下游成员的连接 (linkage) 组成的网络结构。供应链各主体通过物流、商流、信息流和资金流连接，它的协调运行建立在主体间高质量的信息传递与共享的基础之上。
随着电子商务的发展，获取商品及其交易相关信息变得非常便捷，借助这些信息提升供应链效率也是很自然的做法，比如根据销量预测进行仓储规划，回溯到上游甚至可以影响生产计划、原材料采购等。
尽管供给端的优化能带来效率提升，但其中的局限性也不容置否，举个真实的例子，2016年女装羽绒服的备货量远超市场需求，造成了极大的资源浪费和利润亏损。
\subsection{优化探索}
为了进一步提升效率，我们开始尝试基于供给和需求双向影响的供应链优化方法，一方面，通过销量预测收集需求，再结合电商平台的业务目标生成销量计划，最后根据销量计划制定供给计划；另一方面，电商平台统筹全渠道流量配合销量计划的执行，并保证平台效率最大化。我们的优化流程架构图如下所示，其中，双向的影响通过销量计划体现，平台给出销量计划，商家按销量计划备货并向平台确认（平台也可通过库存来确认卖家反馈），平台执行销量计划。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/gyl1.png"}
	\caption{供应链流程}
	\label{fig:gyl1}
\end{figure}

\subsection{销量预测}
销量预测是典型的回归问题。基于电商平台的海量日志和大数据计算平台，可以很方便的获取商品的浏览/成交等行为记录，对这些数据进行一系列加工便可得到回归问题需要的样本特征和标签，其中，样本标签是商品的销量值，样本特征是包含绝对值和相对值的属性描述。有了样本之后可以选择一种或多种回归模型来进行拟合，可以是树模型，也可以是深度神经网络DNN等其他模型，模型的参数可通过交叉验证的方式来确定。销量预测的详细介绍可参考3.3章节。
\subsection{销量计划}
由于销量预测只是对历史规律的拟合，无法捕捉未来变化对销量的影响，这使得用销量预测来指导备货就有些不合理。为了加入未来变化的影响，我们引入了销量计划的概念。
销量计划是对销量预测的修正，修正的依据有销售平台的行业容量、平台的商业目标等。举个例子，某款899的洗衣机，月平均销量一百台，商家一下定了1000台。适逢该洗衣机的销售平台开始走品质升级线路，899的洗衣机明显不在品质洗衣机的行列，获得的流量资源也就相应的减少，库存的消耗速度变慢，商家的成本提升。这就是商家未根据平台变化制定备货计划的后果，所以销量计划必须是商家和平台共同制定并一起努力完成的。
我们将N个商品的销量计划抽象为带约束的优化问题，优化目标是这N个商品的GMV最大化，约束有多个维度，其中一类表示销量计划值要尽量靠近销量预测值，一类是商品所在行业的市场容量约束，另一类是平台期望的品类结构的分布约束。

\begin{align}
\min \max\left \{ s-\sum_{i=1}^{N}price_{i}x_{i},0 \right \}  +\alpha \sum_{i=1}^{N}\frac{1}{mae_{i}}\left ( x_{i}-a_{i} \right ) ^{2}  + \beta \sum_{i=1}^{N}\frac{1}{b_{i}^{2}}\left ( x_{i}-b_{i} \right ) ^{2} \\
\leftline{s.t.} \\\sum_{i=1}^{N}I_{\left ( industry_{i}=j \right )} x_{i} <= capacity_{j}, \forall j \in \left \{ 1,2,..,K \right \} \\
\sum_{i=1}^{N}I_{\left ( industry_{i}=j \right )} x_{i} score_{i}/\sum_{i=1}^{N}I_{\left ( industry_{i}=j \right )} x_{i}>= threshold_{j}, \forall j \in \left \{ 1,2,..,K \right \}
\end{align}

相关符合说明如下：
$N,K$：$N$表示商品总数，$K$表示行业总数\\
$\mathbf{x} = \left (x_{1},x_{2},...,x_{N} \right )$：所有商品的销量计划\\
$s$：$N$个商品的GMV目标\\
$price_{i}$：第$i$个商品的价格\\
$a_{i}$：第$i$个商品的销量预测值\\
$mae_{i}$：第$i$个商品销量预测的平均相对误差\\
$b_{i}$：第$i$个商品过去一周的平均销量\\
$industry_{i}$：商品i所属的行业\\
$score_{i}$：第$i$个商品在其所在行业的某个分数，比如，平台的目标是品质化提升，可以用品牌调性分来表示\\
$threshold_{j}$：行业$j$下$score$的阈值\\
$capacity_{j}$：行业$j$的市场容量\\

目标函数中的第一项可表示为$\max \left \{1-z,0  \right \} $，用如下可导函数来替代
\begin{align}
h\left ( z \right )=\left \{ 
\begin{matrix} 
\begin{split}
&1/2-z, z < 0\\
&1/2*\left ( z-1 \right )^{2},0 \leq z\leq 1\\
&0, z > 1
  \end{split}
\end{matrix}
\right.
\end{align}
之后可用Projected Gradient Method求解。

\subsection{计划执行}
我们将供应链的整体调控分为两部分，限流模块和调控模块，其中限流模块是对缺货和即将缺货的商品进行流量管控，细化到分仓维度；调控部分是保障销量计划的执行。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.7\linewidth]{"fig/gyl2.png"}
	\caption{计划执行}
	\label{fig:gyl2}
\end{figure}

\subsection{总结}
在2017双十一期间，通过实时及离线大数据技术获取22万商品的实时库存和销售数据，提前预估缺货风险，在此基础上承接上游天猫过热5万商品，天猫国际近1万商品，支持全国库存及分仓库存实时数据及销售数据，并通过天猫营销平台最终帮助商家及时补了价值22亿的库存，大量减少了因缺货带来的成交损失。
日常供应链的效果待补充：周转天数的减小

\section{基于强化学习的分层流量调控}
\subsection{背景}
福利经济学告诉我们，市场可以解决两大问题，效率和公平。在满足一定的条件情况下，通过市场机制可以实现帕累托最优，达到单独改变任何一个个体都不能实现更优的状态，以此实现效率的最优化。但效率最优往往是不够的，一个贫富差距巨大的社会仍然有可能是帕累托最优的，但是是一个极不稳定的状态，一个稳定的社会结构还需要考虑公平，福利经济学第二定理因此指出，通过改变个体之间禀赋的初始分配状态，仍然可以通过竞争性市场来达到帕累托有效配置，从而兼顾公平。

事实上，今天的淘宝俨然已经成为了一个规模不小的经济体，因此，社会经济学里面讨论的问题，在我们这几乎无不例外的出现了。早期的淘宝多数是通过效率优先的方式去优化商品展示的模式，从而产生了给消费者最初的刻板印象：低价爆款，这在当时是有一定的历史局限性而产生的结果，但肯定不是我们长期希望看到的情形。因为社会大环境在变化，人们的消费意识也在变化，如果我们不能同步跟上，甚至是超前布局的话，就有可能被竞争对手赶上，错失良机。因此有了我们近几年对品牌的经营，对客单的优化，以至于现在再搜索“连衣裙”这样的词，也很难看到十几块包邮的商品，而这个在2,3年之前仍然是常态。而这里的品牌和客单等因素，是通过一系列的计划经济手段来进行干预的，类似于上文福利经济学第二定理中的禀赋分配，依据的是全局的的观察和思考，很难而且也不可能通过一个局部的封闭系统（例如搜索的排序优化器）来实现。

因此，越来越多的运营和产品同学，鉴于以上的思考，提出了很多干预的分层，这里的分层指的是商品/商家类型的划分，可以从不同的维度来划分，比如，按照对平台重要性将天猫商家划分成gska、ska、ka和非ka商家；按照品牌影响力将商品划分为高调性和普通商品；按照价格将商品划分为高端、中等、低端商品等。而早期的算法同学对这些可能也不够重视，一个经典的做法即简单加权，这通常往往会带来效率上的损失，因此结果大多也是不了了之。但当我们认真审视这个问题的时候，我们其实可以预料，损失是必然的，因为一个纯粹的市场竞争会在当前的供需关系下逐步优化，达到一个局部最优，所以一旦这个局部最优点被一个大的扰动打破，其打破的瞬间必然是有效率损失的，但是其之后是有机会达到比之前的稳定点更优的地方。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/rllc0.png"}
	\caption{}
	\label{fig:rllc0}
\end{figure}



所以，这其实给我们算法同学带来2个问题：
1. 如果尽可能的减少瞬时损失？
2. 如何尽快的到达新的有可能更优的局部最优点？

对应的解决方案也很自然：
1. 进行个性化的干预，减少不必要的损失，例如干预的分层为物流时效，那么当时对物流不敏感而对销量更看重的那些用户，则没有必要进行很强的干预；
2. 通过更广泛，更smart的exploration，仍然以上面的例子，因为当前的整体排序没有考虑物流时效，所以我们的数据中就没有这样的属性，所以我们无法从监督学习来学习到类似更多次日达这样的商品被排到首页的效率会如何变化，这只能逐渐的“试”出来，再从之后的用户反馈中总结经验，是一个典型的“trial and error”的过程。
所以当我们进一步抽象时，会发现这自然的定义了一个强化学习问题：个性化的干预可以看做针对不同的状态，所采取的动作不一样，而更广泛，更smart的exploration则对应着要将强化学习的搜索学习过程。

\subsection{问题建模}
我们把搜索行为看成是用户与搜索引擎交互的MDP，搜索引擎作为agent、观察到的用户和搜索词信息作为state、排序策略作为action（流量调控feature只是众多action中的一员）、用户反馈（pv/click/pay）作为reward，排序参数优化问题也可通过RL来求解。为了引入流量结构变化的影响， 我们将分层流量占比的变化和用户行为反馈一起作为reward，具体地

1. 搜索场景下的上下文通常包括query profile和user profile，其中query profile由query的物理属性（词性、词长度等）和淘宝属性（类目、行业等）组成，user profile由user长期的行为偏好、实时的状态和行为序列表示，因此我们将这些表示为state，记为$s \in R^d$。
2. 假设需要进行干预的信号有m个，把每个分层抽象成一个rank feature，如果商品属于该分层则score为1，否则为0；每个分层对应的weight组成action。一个常用的trick是，不直接输出action的绝对值，而是在神经网络的最后一个输出层，使用sigmoid（亦可使用tanh，二者是可以相互表示的），将actor网络的输出每一维限定在$[0,1]$之内，即$o \in [0,1]^m$，然后在经过一个变换进行生效：
$$
a^k = L^k + (U^k-L_k)o^k, \forall{k} \in \{1,2...,m\}
$$
这里$U^k$和$L_k$是第k维分层rank feature的权重的upper bound和low bound，一般来自于领域知识，但通常受限于经验的局限，因此我们尝试了一种新的方法进行自动赋值，将在下一节进行阐述。
3. reward设计的第一要素即分层比例，即展示商品中属于分层商品占总商品的比例$p_i(\pi)$。于此同时，由于在流量调控的同时需要兼顾效率，用户的行为反馈必须作为reward考虑的因素，反馈中考虑click、pay和cart行为，每种行为的影响因子不同，pay>cart>click，这里统一表示为每个PV中用户click、cart、pay的数量$n_{click},n_{cart},n_{buy}$的一个函数，即$ \text{GMV}(n_{click},n_{cart},n_{buy})$。此外，分层比例需要设定对照组，举个例子，羊绒衫的搜索结果中高价商品比例明显高于毛衣，因为query本身已经体现出了价格差异，与流量调控的action并无关系，所以在计算实际的分层比例时，我们会将其原值减去同query在基准桶的分层比例$p_i(\pi_{basic})$，即
$$
r(s,a) = \text{GMV}(n_{click},n_{cart},n_{buy}) + \sum_i^m \lambda_i \big(p_i(\pi)-p_i(\pi_{basic})\big)
$$

\subsection{Dynamic Action Boundary by CEM}
上文的建模建立在PV粒度的奖赏，但是由于用户的行为的不确定性（这个不确定性一方面来自于用户的点击购买行为具有随机性，另一方面来自于我们对用户建模的不确定性），所以瞬时奖赏会有很大的variance，会对学习带来很大的影响，所以此时如果在整个实数空间进行搜索的话，很有可能收敛不了。因此我们设计了upper bound和low bound，使得RL算法只需要在局部进行搜索，降低了学习的难度，但这又带来了2个新的问题：
1. 如何确保upper bound和low bound的合理性？
2. 如何防止选取了一个局部的最优区间？

针对以上2个问题，我们设计了一个通过Cross Entropy Method（CEM）的方法来实时的动态更新action的upper bound和low bound，具体而言，我们不考虑state，考虑一个全局最优action$a_k$，我们假设其符合一个高斯分布，在
$$
a^{k*} \in N(\mu_k, \sigma_k^2)
$$
每次迭代的开始，我们从这个分布上采样s个样本，即$\Omega_1,\Omega_2,...,\Omega_s$，然后对这些action进行充分的投放，得到对应的action的一个充分置信的reward值，即
$$
R(\Omega_1)= \frac{1}{N_1} \sum_i^{N_1} r_i(\Omega_1) \\
R(\Omega_2)= \frac{1}{N_2} \sum_i^{N_2} r_i(\Omega_2) \\
\cdot \cdot \cdot \\
R(\Omega_s)= \frac{1}{N_s} \sum_i^{N_s} r_i(\Omega_s)
$$
然后我们对$R(\Omega_1),R(\Omega_2),...,R(\Omega_s)$进行排序，选取出top p的子集D，以最大化高斯分布产生这些样本的概率，即
$$
\max_{\mu_k^*, \sigma_k^{2*}} \;\;\; f(\mu_k^*, \sigma_k^{2*}) = \sum_{i \in D} \log N(\Omega_i|\mu_k^*, \sigma_k^{2*})
$$
实际上，上面的式子是有最优解的，$\mu_k^*$即D中所有样本的均值，$ \sigma_k^{2*}$则是所有样本的方差，但如果直接求解，则模型则会迭代过快，一方面会完全忘记之前迭代的信息，另一方面，因为这个会直接输出给上面的RL学习的actor使用，所以bound不能变化多块，否则RL很有可能不能及时跟上变化，因此，我们采用了缓慢更新的方法，即
$$
\mu_k \leftarrow \mu_k + \alpha \frac{\partial f}{\partial  \mu_k} \\
\sigma_k \leftarrow \sigma_k + \alpha \frac{\partial f}{\partial  \sigma_k }
$$
在更新之后，我们使用下面的方法赋值第k维action的upper bound和low bound，确保RL调节的action在一个全局较优的空间内
$$
L^k = \mu_k - 2\sigma_k \\
U^k = \mu_k + 2\sigma_k \\
$$

我们的RL实现选择了我们自己在AI4B中实现的DDPG，整体流程如下：
1. 使用CEM选取初始upper bound和low bound
2. 启动RL进行学习，于此同时，使用CEM动态调节upper bound和low bound

\subsection{实验效果}
双11期间在gmv损失可控（1\%）的情况下，ka及以上商家流量占比提升20\%+。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/rllc1.png"}
	\caption{}
	\label{fig:rllc1}
\end{figure}

\subsection{总结与展望}
本文的主要工作是基于强化学习的分层流量调控框架实现，在一小部分流量上探索分层调控策略对指标的影响，再结合探索策略的收益在剩余流量上精细化投放。作为流量结构调整的实施部分，框架本身还有很多需要改进的地方，在reward设计方面，不同分层流量的reward融合、分层流量reward与行为反馈reward的融合都是需要深入的方向；在探索策略设计方面，目前还是单个维度explore，效率较低，后面会尝试多个维度同时explore。另外，文章开头提到的如何评估流量结构变化的长期影响是一个更有价值的课题。


\section{应用实例：红包智能化发放算法} 

\subsection{概述}
今年的双11红包有了很多不同于往年的新鲜玩法，其中的关键词红包项目，作为首个在搜索进行发放的红包项目之一（另一个是密令红包），也是首个使用算法进行发放的红包项目，在这次的红包大战中独树一帜，充分展现了在搜索链路探索新型互动性产品的潜在空间，也充分体现了算法在红包发放中的作用。

\subsection{一石三鸟}
关键词红包通过在搜索自然流量上，将一些关键词搜索引流到与之相关的招商商家店铺中，同时对进入店铺的买家发放由商家提供的红包，刺激买家的消费需求以及增加自己店铺和商品在这批潜在买家中的曝光。上个王道先：

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/hongbao1.png"}
	\caption{红包}
	\label{fig:hongbao1}
\end{figure}

Step 1 搜索招商关键词，出现小猫浮层;
Step 2 点击小猫拆红包 ;
Step 3 结果显示在商家店铺承接页;

其具体形式为：招商的商家按合同支付一定费用，购买双十一预热期（11月5日至11月10日）通过自然搜索流量的总进店UV数。平台将使用收取的费用作为红包奖池用于买家进店后的红包发放。关键词红包不同于其他红包或其他引流方式的显著特点有：
- 给搜索了对应的关键词用户发红包，受众非常广，不需要特意传播
- 用户有比较相关的需求，所以商家拿到的是相对来说较为优质的流量
- 用户也有愿意去点击领取红包，点击率远高于插入广告
- 平台也可以从中获取收益

总结而言，通过商家红包进行关键词引流进店，是一个 **一石三鸟** 的模式：商家获得了UV和曝光；用户有了购买需求后获得了折扣（红包）和店铺推荐；平台也可以从中获益。

\subsection{发放效果}
关键词红包项目11月5日-10日共引导进店UV共计 2900万，引导双11成交额（进店UV在其所进的74家招商店铺中的成交）为 **1.52亿**，5-10号期间引导 **300万**的成交。卖家角度ROI（引导成交/商家费用）为 **2.02**，平台角度ROI（引导成交/商家费用中用于关键词红包发放的部分）为 **8**。红包角度使用率为 **83.96\%**，直接引导ROI为 **93.9**，间接引导ROI为 **1755.5**。跟集团发放的其他红包效果对比如下

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/hongbao2.png"}
	\caption{红包效果}
	\label{fig:hongbao2}
\end{figure}

因为往年双11未使用算法进行红包发放，并且考虑到自然增长和营销力度，所以跟去年的数据比就算法评估而言是不公平的。因此，我们做了分桶AB Test，基准桶使用的是随机发放（考虑到用户是在有了强购买的需求之后才被发放的红包，所以随机策略在我们的场景下并不算太差）。我们比较了2种算法策略，与基准对比的效果如下：（ 控制发放人的概率a，控制中奖面额概率b）
 1. a->引导GMV提升 **23.35\%**；引导进店的流量加购提升 **13.1\%**
 2. b->ROI提升 **10.97\%**；红包使用率提升 **4.75\%**。

\subsection{系统架构}
\subsection{离线：关键词\&定价策略}
- 卖家只能购买和自己店铺相关的query，不可以购买竞品的query
- 这个query必须事先有一定量的到卖家店铺的比例，否则需要经过人工的审核
- 每个uv的价格由自然搜索流量下UV数与同类目p4p引导点击的平均价格共同决定

\subsection{在线：发放控制（算法部分）}
因为整个红包发放系统涉及到范围甚广（前端，支付宝等都有对接的系统），因此我们重点介绍与我们算法相关的发放控制逻辑部分，大致架构如下图所示：

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/hongbao3.png"}
	\caption{}
	\label{fig:hongbao3}
\end{figure}

在用户搜索了某个商家购买的关键词后，是否给用户发红包取决于2个因素，用户概率$x$，发放速度$\gamma$，分别对应下面算法章节的的发放质量优化与发放速度控制：
- **发放质量优化** 在兼顾氛围（中奖UV数）的前提下，优先发放给特定用户，最大化商家和平台收益，这里的收益包括：红包引导的进店加购、收藏和成交；红包角度的使用率，ROI等。
- **发放速度优化** 在双11预热期，UV的分布可能不如我们模型估计的精确，而且还有传播后非自然的搜索（为了红包而来搜索）猛增的风险，为了避免红包很快发完或者发不完（进店UV满足不到），我们对发放速度进行了实时PID自动控制，确保红包在6天内平稳发放。

其详细算法将在下节阐述。最后判断中奖时，随机产生一个0~1之间的数$r$，当$r<x\gamma$时，给用户发放红包。其中，30\%的流量上，红包的发放面额也使用用户价值模型产出的面额分配$w$。

\subsection{核心算法}
\subsection{用户价值模型 }
给用户发放红包的概率计算主要依据：
- 用于控制用户获取红包的概率$x$和获得不同面额的概率$v$，来使得红包的效益最高，这里的效益包括红包得使用率，ROI以及引导的GMV等。
- 兼顾红包发放氛围，即保证一定的公平性。

我们根据不同粒度的用户纬度的属性，将所有的用户分为粗粒度的$G$个人群，和较细粒度的$n$个人群，二者之间可以有不包含的关系，即若2个用户同属于同一个细粒度人群，他们仍然可以属于2个不同的粗粒度的人群。我们为每个细粒度人群i，计算一个获得红包的概率$x_i$，以及获得面额为$j$元的红包的概率$v_{ij}$。具体而言，是通过优化以下目标函数来进行求解最优概率分配：

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/hongbao5.png"}
	\caption{}
	\label{fig:hongbao5}
\end{figure}

这里$\alpha_i$是第$i$个人群在总用户中的占比，$\beta^T g_{ij}$是给人群$i$分配红包面额$j$带来的收益（其中$g_{ij}=[g_{ij}^{usage},g_{ij}^{roi},g_{ij}^{gmv}]$分别对应着人群$i$在面额为$j$的红包上的使用率，roi和gmv的收益，是由历史数据上统计得到；而$\beta=[\beta^{usage},\beta^{roi},\beta^{gmv}]$则对应着这些收益的权重，是由具体目标决定的，例如如果我们侧重优化红包的使用率，那么只需要将对应的$\beta^{usage}$调大即可）。因此，目标函数的主部分，都是通过优化$x_i$和$v_ij$来最大化总收益，除此之外，还包含其他一些模块，对应的逻辑如下所列：
- 考虑到红包发放的另一个作用是活跃氛围，提高用户对大促的关注度，因此对$v$和$x$都增加了一个entropy项，目的是在优化收益的前提下兼顾公平，扩大红包的受众范围。
- 发放的红包总数约束为指定值$D$
- 每个用户获得不同面额红包的概率和为1
- 每个面额j的红包数等于奖池中设定的数量$C_j$
- 每个粗粒度人群g中获得得红包数等于设定值$B_j$

然而，联合求解最优用户概率$x_i$以及获得面额为$j$元的红包的概率$v_{ij}$是一个非凸问题，能否求得最优解很大程度上依赖于解的初始化，稳定性和实用性不足。因此我们转为直接求解用户获得面额为$j$元的红包的概率$x_{ij}$，那么$1-\sum_j x_{ij}$ 即用户不获得任何红包的概率。因此，上述目标可以改写为：

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/hongbao4.png"}
	\caption{}
	\label{fig:hongbao4}
\end{figure}

 
上述方案中是通过一些基本用户信息（购买力）将用户划分为若干人群，为每个人群计算对用的中红包的概率。然而，为了统计信息（这里主要是基于历史数据的红包使用带来的收益$g_{ij}=[g_{ij}^{usage},g_{ij}^{roi},g_{ij}^{gmv}]$）的显著程度，要保证每个人群有充分多的用户，所以会存在个性化不足的问题，即落到同一个人群的2个用户，他们对红包的消费能力和偏好也会因人而异，而不应该是用同一个值。因此，我们进一步引入了用户标签数据：


\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/hongbao6.png"}
	\caption{}
	\label{fig:hongbao6}
\end{figure}


相对于通过单一属性（购买力）确定人群红包使用收益，这里我们认为红包的使用收益与更多的用户属性相关，因此，对于每一个单独的用户个体i，其在面额$j$上的收益，是由一个预测模型计算得到：

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/hongbao7.png"}
	\caption{}
	\label{fig:hongbao7}
\end{figure}
 
这里的$u$即表征用户标签信息的特征向量，而$w=[w_{usage},w_{roi},w_{gmv}]$则是对应的三个线性预测器，分别预测了该用户使用了面额为j元的红包后在使用率，ROI和GMV上的收益。

\subsection{潜客模型}
关键词红包与普通红包的不同在于：红包需要起到额外的引流作用——用户在进入店铺领红包的同时，希望能对店铺带来一定收益。因此用户与店铺之间的匹配尤为重要：店铺给一个不会在自己店铺购物的人发红包，只有用户有收益；而店铺给容易在自己店铺成交的人发红包，对用户、店铺、平台都是有收益的。基于上述问题，我们提出了“潜客模型”。
潜客模型可以抽象成一个one-class matrix completion with implicit feedback的问题，我们只需要预测一个user-shop矩阵中，哪些位置是1。定义User对Shop有偏好的概率是$f(u_{i},s_{j})=\sigma(U_{i}^{T}S_{j}+a_{i}+b_{j})$，其中$ \sigma $表示sigmoid函数，$ U_{i}$表示用户向量，$ S_{j}$表示店铺向量，$ a_{i}$和$ b_{j}$分别表示用户和店铺自身的Bias，我们可以用下图表示上述公式（$ a_{i} $这里被略去了）。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/hongbao8.png"}
	\caption{}
	\label{fig:hongbao8}
\end{figure}

图1，用户对店铺偏好示意
	图中，我们可以看到向量均被虚线分为4部分，从左往右依次是隐空间、用户属性空间、店铺属性空间和偏差空间。用户和店铺均由这4部分组成，在店铺上第3部分为店铺本身属性，第4部分为店铺热度；在用户上第2部分为用户属性，第4部分这里取0；其他部分均为模型参数。于是$U_{i}=lu_{i}\bowtie fu_{i}\bowtie wu_{i}$，$U_{i}=ls_{i}\bowtie ws_{i}\bowtie fs_{i}$。我们使用似然作为模型的loss：

$\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;J(U,S)=-\Sigma_{I,j}r_{I,j}*In(f(u_{i},s_{j}))+(1-r_{I,j})*In(1-f(u_{i},s_{j}))+regularzation\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;$ 

$\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;regularzation =\lambda/2*(\Sigma_{i}||lu_{i}||_{2}^{2}+||ls_{j}||_{2}^{2})+\mu/2*\Sigma_{i}||wu_{i}||_{2}^{2}+\upsilon/2*||ws_{j}||_{2}^{2}\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;$ 
	通过上述公式，我们不难求解模型各参数的梯度。在已知梯度的情况下，使用AO（alternating optimization）算法，和SGD（stochastic gradient decent）求解。AO依次固定用户和店铺向量，在固定一个的同时更新另一个，依次进行;SGD算法全部更新在SHOP端，更新自己并将梯度发送给USER进行更新。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/hongbao9.png"}
	\caption{}
	\label{fig:hongbao9}
\end{figure}

图2，左图表示AO，右图表示SGD。
SGD只需要存储一个方向的边，内存使用会比AO方法小。但SGD存在参数更新延迟的情况，而且延迟的步数不存在固定上界，故算法的收敛可能会很慢。而且，此SGD方法依然采用基于BSP模型（Bulk Synchronous Parallel）的图计算模型（即进行全局同步），虽然参数更新存在延迟，但没有应用异步的计算模型，故效率并没有明显的提升。
离线实验对比了本文提出方法（FBMF）、无特征的SVD方法、集团内实现的MPI-PSVD方法和推荐热门商家方法，对比准确率实验结果如下表所示：

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/hongbao10.png"}
	\caption{}
	\label{fig:hongbao10}
\end{figure}

\subsection{发放速度控制}
\subsection{控制目标}
一方面，需要履行与商家签订的合同，完成承诺给商家的到店 uv 数量，另一方面，要求完成的过程是平稳可控的。在 uv 资源充分的情况下，只要设置较大的发放概率，就能完成第一个目标。 然而发放概率过大容易导致很快就会将一天的目标完成了， 达不到平稳发放的目的。 在这里，我们采用 PID 控制器。
\subsection{控制器介绍}
 在控制理论和实践中，PID 是一类广泛使用的控制方法。PID 是“比例-积分-微分”的简写， PID 控制器根据控制原理，对偏差进行比例、积分、微分的调节，从而使被控变量的实际值与既定目标保持一致。PID 有大量的实际应用，例如热水器温度控制，流量控制，汽车的定速巡航等。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/hongbao11.png"}
	\caption{}
	\label{fig:hongbao11}
\end{figure}

上图是PID控制系统的图示，其中 e(t) 是误差信号，u(t) 是控制量，Kp, Ki, Kd 分别是 P、I、D 的系数。
比例（P）控制：直接针对误差进行比例调节，误差越大，比例信号输出越强。举个例子，热水器温度调节系统，当前温度离设定温度差异较大时，就会开启较强的加热功率，等到离设定温度很近时，加热就会缓一些了。
积分（I）控制：对累积误差进行控制，其功能就是消除累积误差。
微分（D）控制：以误差的变化率作为控制因素，例如温度上升较快时，虽然没有达到设定温度，微分控制此时会适当降低加热功率，而单纯的比例控制器则可能导致超调现象。
\subsection{发放速度的控制过程}
有了前面两个小节的介绍，这里可以联系实际，介绍双十一关键词红包发放过程中我们是怎么进行发放速度的控制的。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/hongbao12.png"}
	\caption{}
	\label{fig:hongbao12}
\end{figure}

控制粒度细化到 $(q， s)$ 粒度，其中 q 是商家 s 购买的关键词。
控制器参数相关的信息存放在 $controller\_info$ 这个 ups 表中，该 ups 表支持增量，这种做法提供了运行时改变控制器参数的灵活性。
系统运行起来后，前端能准实时（2分钟同步一次）记录商家的到店 uv 情况， 分别记录在 $q\_s\_arrive\_uv$ 和 $s\_arrive\_uv $这两张 ups 表中。
而控制目标分别存放在 $q\_s\_target\_uv$ 和 $s\_target\_uv$ 这两张表中，为了方便调节，这两张表也是增量表，其中 $q\_s\_target\_uv$ 记录了 $(q, s)$ 粒度的阶段目标，以 $T_s = 6$ 分钟为一段，将一天的时间分成 240 段。 控制系统以 $T_r = 3$ 分钟为周期进行控制， 这样每个目标段内，有两次机会调整控制量 $ \gamma $.

红包发放过程中，目标都是阶段性的变动的，在某个阶段，目标值是不变的，而阶段发生变化时，目标值也随之变化，因而我们需要在普通的 PID 系统的基础上加上一些额外的控制量来适应这种阶段目标的变化。 实际中，输出的控制量由如下三部分组成：
(1) (q,s)段内控制
(q, s)-段内控制由如下的 PID 系统执行
$$\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;u_k = K_p e_k + K_i \sum_{j=0}^k e_j + K_d (e_k - e_{k-1}) $$
其中 $e_j = b_k -  a_k \frac{T_s}{T_r} $ ， $b_k$ 是分段目标， $a_k$ 是 $T_r$ 这段时间内实际到店 uv 数，需要乘以  $\frac{T_s}{T_r}$ 折算到 $T_s$ 时间段. 这种折算的另一个解释是到达速度，即单位时间内的到店情况，这里的单位时间就是 $T_s$
对pid输出幅度进行一些限制，
$$\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;output_1 =  \max(0, \min(\beta\; u_k,\; \delta)) $$
(2) (q,s)累计未完成量控制
到时间 $k$，累计未完成的到店uv 记为  $acc_k$
针对未完成这一部分设置的控制量为
 $$\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;output_3 = min(\eta \; acc_k, \;\alpha)$$
(3) s 未完成度控制
卖家的到店uv未完成度按如下式子进行计算：
$$\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;r_k = \max(0, 1 - \frac{c_k}{o} \frac{1440}{(k+1) T_s} )$$
其中 $o$ 是卖家 $s$ 的当天的目标到店 uv，而 $c_{k}$ 是截至时间 $k$，该卖家 $s$ 的已经获得的到店 uv 

针对卖家未完成情况的控制量为 
$$\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;output_2 = \tau \;r_k  $$
其中 $\tau$ 是预设参数，放在 $controller\_info$ 这张表里面。

最终的控制量 
$$\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\gamma_k = output_1 + output_2 + output_3$$
这个输出将会写入 UPS 表中，供在线系统使用。

\subsection{参数调节}
控制系统参数列表 $\theta=(K_p, K_i, K_d, \beta, \delta, \eta, \alpha, \tau)$
而在双十一方法过程中，由于细化到 (q,s)-粒度进行控制，参数空间很大。
实际操作中，根据初期运行情况，整定一组参数作为公共参数，所有的 (q, s) 共享，在实际过程中，大部分(q, s) 是可控的，而少量控制不好的case 将会设置特有的 $\theta $。

\subsection{实时效果}
下图是预热期间速度控制的一个实时效果图，其中蓝色的线是当天到每个时刻计划的发放的UV数，灰色的线是通过我们实际发放的UV数，可以看到，通过在系统中增加PID控制器，使得红包的发放节奏完全掌握在我们的预期之中。

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/hongbao13.png"}
	\caption{}
	\label{fig:hongbao13}
\end{figure}




\section{附录} 

\subsection{一种求解带约束的非光滑凸优化问题的通用算法}


\subsubsection{一类常见的优化问题}

在许多业务场景和机器学习模型中，都会遇到最优化问题。其中一类常见的问题类型是带约束的非光滑凸优化问题，可以用如下形式表示，

\begin{align}
\min f(x) + g(x) \\
s.t.\\
ce(x) = 0\\
ci(x) \ge 0 \\
lb \le x \le ub
\end{align}

式中，f(x)表示目标函数中的可微函数，g(x)表示目标函数中的不可微函数。

ce(x)表示等式约束；

ci(x)表示不等式约束；

lb和ub分别表示下界和上界。

接下来介绍一种基于Augmented Lagrangian Method和Proximal Gradient Method的通用求解方法。

\subsubsection{求解带约束的凸优化问题}

\subsubsection{等式约束}

考虑如下形式的优化问题，

$$
\min_x f(x) s.t. c_i(x) = 0 for \forall i = 1, 2, ...
$$


Augmented Lagrangian Method(以下简称ALM)在原目标函数后加上约束条件的二次惩罚项及拉格朗日乘子项，将约束优化问题转化为一系列无约束优化问题后迭代求解。

首先，定义Augmented Lagrangian Function，

$$
L_A(x, \lambda; \mu)\overset{def}{=}f(x) - \sum_i \lambda_i c_i(x)+\frac{1}{2\mu}\sum_i c_i^2(x)
$$

之后，通过交替更新拉格朗日乘子和带目标变量迭代求解。第k轮的更新过程如下，

\begin{align}
\left\{
\begin{matrix}
x^k&=\underset{x}{argmin} L_A(x, \lambda^(k-1);\mu) \\
\lambda_i^k&=\lambda_i^{k-1}-c_i(x^k)/\mu
\end{matrix}
\right.
\end{align}

\subsubsection{不等式约束}

考虑如下形式的优化问题，

$$
\min_x f(x) s.t. c_i(x) \ge 0 for \forall i = 1, 2, ...
$$

我们可以通过引入松弛变量将该问题转化为等式约束优化问题，

$$
\min_x f(x) s.t. c_i(x) -s_i = 0, s_i \ge 0 for \forall i = 1, 2, ...
$$

此时，在第k轮我们需要求解的子问题变为

\begin{align}
\min_x f(x)-\sum_i \lambda_i^k(c_i(x)-s_i)+\frac{1}{2\mu}\sum_i (c_i(x)-s_i)^2 \\
s.t. \\
s_i \ge 0 for \forall i = 1, 2, ...
\end{align}

显然，这是一个关于每个松弛变量的二次函数。因此，可以得到松弛变量的闭式解
$$
s_i = \max {c_i(x)-\mu\lambda_i^k, 0} \forall i=1,2,..
$$

将上式带回原问题中，如果定义如下函数

$$
\psi (t, \sigma; \mu) \overset{def}= \left\{ 
\begin{matrix}
-\sigma t + \frac{1}{2\mu} t^2 if t-\mu \sigma \le 0\\
-\frac{\mu}{2}\sigma^2 otherwise
\end{matrix}
\right.
$$

则第k轮的更新过程如下
\begin{align}
\left\{
\begin{matrix}
x^k=\underset{x}{argmin}f(x)+\sum_i \psi(c_i(x), \lambda_i^{k-1};\mu) \\
\lambda_i^k=max{\lambda_i^{k-1}-c_i(x)/\mu, 0} \forall i=1,2,...
\end{matrix}
\right.
\end{align}



\subsubsection{求解无约束的凸优化问题}

对于无约束优化问题，如果目标函数可微，可以直接使用梯度下降法求解。

如果目标函数不可微，但可以表示为如下形式

$$
\underset{x}{min} g(x)+h(x)
$$

其中，g表示可微凸函数，h表示不可微凸函数并且已知其proximal mapping，即
$$
prox_h(x)=\underset{u}{argmin} (h(u)+\frac{1}{2}\|u-x\|_2^2)
$$

则可用Proximal Gradient Method(PGD)迭代求解。第k轮的求解方式如下
$$
x_k=prox_{t_kh}(x^{k-1}-t_k\bigtriangledown g(x^{k-1}))
$$

式中，$t_k$表示步长。

\subsubsection{通用求解方法}

基于ALM和PGD的通用求解方法如下

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/alm.jpg"}
	\caption{}
	\label{fig:alm}
\end{figure}

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.9\linewidth]{"fig/pgd.jpg"}
	\caption{}
	\label{fig:pgd}
\end{figure}

目前实现了python版本，已发布到[gitlab](http://gitlab.alibaba-inc.com/xuanran/constraint\_convex\_optimization/)上。

\subsubsection{性能对比}

我们在SVM(线性核)中的优化问题上对比了scipy和cvxpy中的优化工具，使用的数据集为scipy.dataset.load\_digits，结果如下。

|Tool|Train Time(s)|Test Accuracy(\%)|
|:----- |:-------|:-----|
| mine | 0.054 | 56.48 |
| scipy.minimize | 1.969 | 56.48 |
| cvxpy | 0.028 | 56.48 |

目前，该方法已应用在珠峰中控系统中。


\subsection{结束语} 
What is a good example of combining machine learning with operation research to solve a major problem? 


Controlling incoming and outgoing traffic in an airport is a very good Operations Research problem. This can be coupled with say, machine learning algorithm for weather prediction to make best use of the facilities available in an airport. The OR algorithm would solve the existing problem, while the ML idea would keep track of unexpected emergency landings by predicting based on suitable metrics.


Internet congestion control:

Sequencing problems are generally looked at as Operations Research areas. One of the first examples that are cited as an application of Operations Research is assembly line scheduling. If we look at internet congestion control as a similar model, we can apply an Operations Research based sequencing model coupled with ML algorithms for predicting sudden rise in traffic, virality etc.

Like I mentioned in the beginning, any problem under any domain can be modeled using Machine Learning and Operations research concepts. The efficiency of the same might be debatable.




\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{\protect\numberline{}{\hspace{-1.5em}参考文献}}
\markboth{参考文献}{参考文献}
\bibitem{1} http://www.atatech.org/articles/66486, 双11搜索关键词红包：商家、用户与平台的三方共赢
\bibitem{2} 双11关键词红包：搜索链路新型互动性产品探索, http://www.atatech.org/articles/44778
\bibitem{3} 淘宝外卖智能补贴算法, http://www.atatech.org/articles/72599 
\bibitem{4} 大数据下线性最优化问题solver介绍, https://www.atatech.org/articles/69242?commentId=115358

\end{thebibliography}

 
