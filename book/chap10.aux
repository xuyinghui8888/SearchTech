\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {第六章\hspace  {.3em}} 智能决策体系的建立 }{181}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10.0pt}}
\@writefile{lot}{\addvspace {10.0pt}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1} 基于MAB的排序策略优化 }{181}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}MAB}{181}{section.6.2}\protected@file@percent }
\citation{mab1}
\citation{mab2}
\citation{mab3}
\citation{mab4}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Multi-armed bandit problem\relax }}{183}{algorithm.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}一种改进的bandit策略}{183}{subsection.6.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Zero-order optimization}{184}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Extra Gradient Algorithm}{184}{subsection.6.3.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces The Extra Gradient Method for Bandit Learning\relax }}{185}{algorithm.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}应用}{186}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}算法流程}{186}{subsection.6.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces 算法流程\relax }}{187}{figure.caption.115}\protected@file@percent }
\newlabel{fig:mab}{{6.1}{187}{算法流程\relax }{figure.caption.115}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.2}计算收益用到的累积时间}{188}{subsection.6.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces 成交笔数随时间分布\relax }}{188}{figure.caption.116}\protected@file@percent }
\newlabel{fig:reward}{{6.2}{188}{成交笔数随时间分布\relax }{figure.caption.116}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.3}收益的计算}{189}{subsection.6.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.4}Zero-order optimization}{189}{subsection.6.4.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces 高斯归一化函数\relax }}{190}{figure.caption.117}\protected@file@percent }
\newlabel{fig:gaussion}{{6.3}{190}{高斯归一化函数\relax }{figure.caption.117}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}强化学习简介}{190}{section.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5.1}背景}{191}{subsection.6.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.6}基于强化学习的实时搜索排序调控}{191}{section.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.1}背景}{191}{subsection.6.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces 搜索的序列决策模型\relax }}{193}{figure.caption.118}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.2}问题建模}{193}{subsection.6.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.2.1}强化学习简介}{193}{subsubsection.6.6.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces 强化学习agent和环境交互\relax }}{194}{figure.caption.119}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.2.2}状态定义}{195}{subsubsection.6.6.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.2.3}奖赏函数设定}{196}{subsubsection.6.6.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.3}算法设计}{196}{subsection.6.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.3.1}策略函数}{196}{subsubsection.6.6.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.3.2}策略梯度}{197}{subsubsection.6.6.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.6.3.3}值函数的学习}{199}{subsubsection.6.6.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.4}奖赏塑形}{200}{subsection.6.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.5}实验效果}{202}{subsection.6.6.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Norm of the Expected TD Update\relax }}{203}{figure.caption.120}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces 每个维度的排序权重分在一天内的变化（iphone）\relax }}{204}{figure.caption.121}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces 每个维度的排序权重分在一天内的变化（android）\relax }}{204}{figure.caption.122}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6.6}总结与展望}{205}{subsection.6.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.7}强化学习为何有用？——延迟奖赏在搜索排序场景中的作用分析}{206}{section.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.1}背景}{206}{subsection.6.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces 监督学习和强化学习的多任务学习网络\relax }}{207}{figure.caption.123}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.2}搜索排序问题回顾}{208}{subsection.6.7.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.10}{\ignorespaces 搜索引擎与用户交互示意图\relax }}{208}{figure.caption.124}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.11}{\ignorespaces 搜索引擎Agent决策过程示意图\relax }}{209}{figure.caption.125}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.3}数据统计分析}{209}{subsection.6.7.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.12}{\ignorespaces 全类目数据下所有成交Episode的长度分布情况\relax }}{210}{figure.caption.126}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.13}{\ignorespaces 连衣裙类目下所有成交Episode的长度分布情况\relax }}{210}{figure.caption.127}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.14}{\ignorespaces 女鞋类目下所有成交Episode的长度分布情况\relax }}{211}{figure.caption.128}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.15}{\ignorespaces 婴幼儿服饰类目下所有成交Episode的长度分布情况\relax }}{211}{figure.caption.129}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.16}{\ignorespaces 仅考虑成交和翻页的搜索会话图示\relax }}{212}{figure.caption.130}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.17}{\ignorespaces 考虑成交、翻页和用户离开的搜索会话图示\relax }}{212}{figure.caption.131}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.4}搜索排序问题形式化}{212}{subsection.6.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.5}理论分析}{215}{subsection.6.7.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.7.5.1}马尔可夫性质}{215}{subsubsection.6.7.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.7.5.2}折扣率}{217}{subsubsection.6.7.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.18}{\ignorespaces  Agent策略$\pi $下能够访问SSMDP中的所有状态\relax }}{217}{figure.caption.132}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7.6}实验分析}{219}{subsection.6.7.6}\protected@file@percent }
